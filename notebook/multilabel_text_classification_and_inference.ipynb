{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1093f2852c7f4ceeb8f3e7a8a70fc7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0fb21f8b9db410383e8efa43c980f6c",
              "IPY_MODEL_f96847ae66bb4022bfc331f859e977bf",
              "IPY_MODEL_3ed61402134b4f5bb4d6483dc57dc42b"
            ],
            "layout": "IPY_MODEL_82fec06996f64b9586bdbb60952c08fe"
          }
        },
        "c0fb21f8b9db410383e8efa43c980f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbe57a14a8a4ecdb670818151ce611e",
            "placeholder": "​",
            "style": "IPY_MODEL_7479fb54cb9e4391ad07099597dac190",
            "value": "config.json: "
          }
        },
        "f96847ae66bb4022bfc331f859e977bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5997f136e3444431b7a15c99f68c72b0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a1159a5213d448991c5cc1c64388e9c",
            "value": 1
          }
        },
        "3ed61402134b4f5bb4d6483dc57dc42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a58b0ff9bdf14eb28d43e024c3aa9b5d",
            "placeholder": "​",
            "style": "IPY_MODEL_f37dc31a8871418b983c4f8534fda668",
            "value": " 1.19k/? [00:00&lt;00:00, 139kB/s]"
          }
        },
        "82fec06996f64b9586bdbb60952c08fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbe57a14a8a4ecdb670818151ce611e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7479fb54cb9e4391ad07099597dac190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5997f136e3444431b7a15c99f68c72b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2a1159a5213d448991c5cc1c64388e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a58b0ff9bdf14eb28d43e024c3aa9b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37dc31a8871418b983c4f8534fda668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1da4488eece846b887235bac0fa9f68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9066927a63ca4400b574e9ddd5b4fdb4",
              "IPY_MODEL_91ecbe9f23b1432b86e3dfab9b12993d",
              "IPY_MODEL_bf8c6d994dba456e8cb89c626beb34d3"
            ],
            "layout": "IPY_MODEL_760a601fadfc404c8fb516500283476d"
          }
        },
        "9066927a63ca4400b574e9ddd5b4fdb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d090aa99c9b47448a2ae8803574db06",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a003c4ce2642e2bbcfb346b4522d77",
            "value": "tokenizer_config.json: "
          }
        },
        "91ecbe9f23b1432b86e3dfab9b12993d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23538f544e6244e797aa50f930d0737a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c29300d7e3f43fbada91584e7421646",
            "value": 1
          }
        },
        "bf8c6d994dba456e8cb89c626beb34d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85fe1c7665404621831839bf84bc8df3",
            "placeholder": "​",
            "style": "IPY_MODEL_f981664e1701492693019575de3150f8",
            "value": " 20.8k/? [00:00&lt;00:00, 1.11MB/s]"
          }
        },
        "760a601fadfc404c8fb516500283476d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d090aa99c9b47448a2ae8803574db06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a003c4ce2642e2bbcfb346b4522d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23538f544e6244e797aa50f930d0737a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1c29300d7e3f43fbada91584e7421646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85fe1c7665404621831839bf84bc8df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f981664e1701492693019575de3150f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db8b3538453541ff8cae3b1d1f1af71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c078a3c6f10b41e29c862ca6176351e2",
              "IPY_MODEL_ce9a0fb69adf4af680f68b23a41ed923",
              "IPY_MODEL_157e8020a1964e40a60a2885f9ec937d"
            ],
            "layout": "IPY_MODEL_d5ddd821f58341f1b4611c24a75b5c09"
          }
        },
        "c078a3c6f10b41e29c862ca6176351e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99df24864b2f40b8a076f3e65fdd06c0",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd863e3c641457ebc1f86abda743cfa",
            "value": "tokenizer.json: "
          }
        },
        "ce9a0fb69adf4af680f68b23a41ed923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5ccb965122142c9b28da36d69970068",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_711cb1bcf7af42bf99b586e893b9238f",
            "value": 1
          }
        },
        "157e8020a1964e40a60a2885f9ec937d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9528e76188d34ceaa385345c26d9e447",
            "placeholder": "​",
            "style": "IPY_MODEL_5c324ed35a404e868f603923130819db",
            "value": " 2.13M/? [00:00&lt;00:00, 51.0MB/s]"
          }
        },
        "d5ddd821f58341f1b4611c24a75b5c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99df24864b2f40b8a076f3e65fdd06c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd863e3c641457ebc1f86abda743cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5ccb965122142c9b28da36d69970068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "711cb1bcf7af42bf99b586e893b9238f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9528e76188d34ceaa385345c26d9e447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c324ed35a404e868f603923130819db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f743e24f91c24470bfece71c0fe9d981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c91f87e0fc1d4aa8b745f3e447b222f7",
              "IPY_MODEL_c1af3917b40e49a48cc4b68787be6027",
              "IPY_MODEL_1ece1341f2f749ada326f23b54b48471"
            ],
            "layout": "IPY_MODEL_9f571431d9a647eab3aec4f467a52806"
          }
        },
        "c91f87e0fc1d4aa8b745f3e447b222f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0792986b22ee4e48b6177349e156c015",
            "placeholder": "​",
            "style": "IPY_MODEL_236055f31c874871b704d70c3d5d3c60",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c1af3917b40e49a48cc4b68787be6027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f11b856dac4750889965e8ec9c06ee",
            "max": 694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1eaa6a34c2499d8f7fbc45063a32c1",
            "value": 694
          }
        },
        "1ece1341f2f749ada326f23b54b48471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d641e08677246b68cec36d0cbea299d",
            "placeholder": "​",
            "style": "IPY_MODEL_fed47c1a3efd4eb980f2fe07a73bb43c",
            "value": " 694/694 [00:00&lt;00:00, 47.3kB/s]"
          }
        },
        "9f571431d9a647eab3aec4f467a52806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0792986b22ee4e48b6177349e156c015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236055f31c874871b704d70c3d5d3c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f11b856dac4750889965e8ec9c06ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea1eaa6a34c2499d8f7fbc45063a32c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d641e08677246b68cec36d0cbea299d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fed47c1a3efd4eb980f2fe07a73bb43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8e2718948294d119ad0542d65714652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56d9c17d614846d5a1d7b692632a1342",
              "IPY_MODEL_3997b3ca318342ff8be3c94d1c7e0ffe",
              "IPY_MODEL_ca131ca9c0dd4e2099cdf88470bd709b"
            ],
            "layout": "IPY_MODEL_c582ded0f4a049dda09cdc328cefa1cf"
          }
        },
        "56d9c17d614846d5a1d7b692632a1342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ebb167761534b429cf192c6408ef791",
            "placeholder": "​",
            "style": "IPY_MODEL_02fc7e21334b452a94352afe20cde81f",
            "value": "model.safetensors: 100%"
          }
        },
        "3997b3ca318342ff8be3c94d1c7e0ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f79b175c0bfb4904a3ee416330b9893c",
            "max": 598635032,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80a2fb91b5284a51882bdd37c7b026a1",
            "value": 598635032
          }
        },
        "ca131ca9c0dd4e2099cdf88470bd709b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4690a23f03214068ad5ba98847e97132",
            "placeholder": "​",
            "style": "IPY_MODEL_7c779f18f009428cb162f34ae6c6995f",
            "value": " 599M/599M [00:12&lt;00:00, 52.5MB/s]"
          }
        },
        "c582ded0f4a049dda09cdc328cefa1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ebb167761534b429cf192c6408ef791": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02fc7e21334b452a94352afe20cde81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f79b175c0bfb4904a3ee416330b9893c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a2fb91b5284a51882bdd37c7b026a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4690a23f03214068ad5ba98847e97132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c779f18f009428cb162f34ae6c6995f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaeb52f1bcc64e18a709c1c04fb5d023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f88dca7cd7014cba905f860c17ad67a0",
              "IPY_MODEL_31fbe29a0e3844cf881f7e6a140ab77e",
              "IPY_MODEL_f374daed1ed34703bd04a599e2a9f4c9"
            ],
            "layout": "IPY_MODEL_2ab896710dd9424ebace4859ebfe2043"
          }
        },
        "f88dca7cd7014cba905f860c17ad67a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d4b01941884bf38d01113d8f62f4b9",
            "placeholder": "​",
            "style": "IPY_MODEL_4abf8f29a8994b369578dee85f07a1d7",
            "value": "config.json: 100%"
          }
        },
        "31fbe29a0e3844cf881f7e6a140ab77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb04de70c4514131ba24c476d7e79ed7",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecad1cc52dbf44d090a6bc4c61a573fb",
            "value": 612
          }
        },
        "f374daed1ed34703bd04a599e2a9f4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_555b167348ba41dfb162e3ea6efccbcd",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d43930a06b44728710cf2bc53787b4",
            "value": " 612/612 [00:00&lt;00:00, 24.4kB/s]"
          }
        },
        "2ab896710dd9424ebace4859ebfe2043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d4b01941884bf38d01113d8f62f4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4abf8f29a8994b369578dee85f07a1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb04de70c4514131ba24c476d7e79ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecad1cc52dbf44d090a6bc4c61a573fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "555b167348ba41dfb162e3ea6efccbcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d43930a06b44728710cf2bc53787b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2be75241914946c496a90d9fc9f5eb74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9592de9322e6471da8d51ce190a94241",
              "IPY_MODEL_7b11cb4a28d94ae8ad681372d8cd0f6f",
              "IPY_MODEL_91b4c9d5ad4c4064a9e82300ec2a9ae9"
            ],
            "layout": "IPY_MODEL_9053c83c592c407bb9a11f4b82e7a0ab"
          }
        },
        "9592de9322e6471da8d51ce190a94241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfc07d71aeef460ea93286ab67d16c4e",
            "placeholder": "​",
            "style": "IPY_MODEL_d528cb2a24c84ff6905a46c228571ebd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7b11cb4a28d94ae8ad681372d8cd0f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa3969e53af43fe87b0f9c87d46da74",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd91526b4ece4dbe97b488c55bb4613c",
            "value": 350
          }
        },
        "91b4c9d5ad4c4064a9e82300ec2a9ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a1afe467f24f919c026555f8a1339e",
            "placeholder": "​",
            "style": "IPY_MODEL_c89918c5897a40dea9c937b94f8b58c6",
            "value": " 350/350 [00:00&lt;00:00, 8.73kB/s]"
          }
        },
        "9053c83c592c407bb9a11f4b82e7a0ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc07d71aeef460ea93286ab67d16c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d528cb2a24c84ff6905a46c228571ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aa3969e53af43fe87b0f9c87d46da74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd91526b4ece4dbe97b488c55bb4613c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4a1afe467f24f919c026555f8a1339e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89918c5897a40dea9c937b94f8b58c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79e76a01665d42f797094ea41b7d46aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_451953dda2764169a8555835827f3211",
              "IPY_MODEL_57c2d7cdd95a42b885632da8a4030d74",
              "IPY_MODEL_57583e2caca14e169b36e5e95aeb95e9"
            ],
            "layout": "IPY_MODEL_79032bc77845484f95ac82ed04721ed7"
          }
        },
        "451953dda2764169a8555835827f3211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595ea48734e7494b9b6ac1707b0f64d1",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ddf86d246d497d9082c5ff2756ed7e",
            "value": "vocab.txt: "
          }
        },
        "57c2d7cdd95a42b885632da8a4030d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e2d043382bf40208d143676638bbe13",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2525a13bc93e460d9be805f469de7738",
            "value": 1
          }
        },
        "57583e2caca14e169b36e5e95aeb95e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e9cfdbdad54a849b7ce502760cf3d5",
            "placeholder": "​",
            "style": "IPY_MODEL_8d62265657eb439294f9dd2415ec4eba",
            "value": " 232k/? [00:00&lt;00:00, 6.05MB/s]"
          }
        },
        "79032bc77845484f95ac82ed04721ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "595ea48734e7494b9b6ac1707b0f64d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ddf86d246d497d9082c5ff2756ed7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e2d043382bf40208d143676638bbe13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2525a13bc93e460d9be805f469de7738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53e9cfdbdad54a849b7ce502760cf3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d62265657eb439294f9dd2415ec4eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56fb63b1871a4f3fbce45fb70722ae7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd38ed700b3543a998c251941f2e36d0",
              "IPY_MODEL_cf3efa4124fd4863b8b5b744e3cc5c21",
              "IPY_MODEL_7be81b52b60f4bafade38de8d47766a2"
            ],
            "layout": "IPY_MODEL_21bd174fef16474e97e942a2650e99ff"
          }
        },
        "bd38ed700b3543a998c251941f2e36d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bce21f9b3d774d238d497bd360b50fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_95104bd3efbb48fdb5d0d44544f0f4be",
            "value": "tokenizer.json: "
          }
        },
        "cf3efa4124fd4863b8b5b744e3cc5c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b92dcaa2c8456eadcc2d5eee69c10a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf02c2b81f4a493f8134c059f9531865",
            "value": 1
          }
        },
        "7be81b52b60f4bafade38de8d47766a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e77e043b03d4830a94bf3521f4123c8",
            "placeholder": "​",
            "style": "IPY_MODEL_44ed91ab5f6a439fb06fd6b5f186a160",
            "value": " 466k/? [00:00&lt;00:00, 23.5MB/s]"
          }
        },
        "21bd174fef16474e97e942a2650e99ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce21f9b3d774d238d497bd360b50fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95104bd3efbb48fdb5d0d44544f0f4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b92dcaa2c8456eadcc2d5eee69c10a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bf02c2b81f4a493f8134c059f9531865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e77e043b03d4830a94bf3521f4123c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ed91ab5f6a439fb06fd6b5f186a160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2671b283a07e46a4b7926cbe15e42063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37bc78236ef14e5f9ddbf42a3fd23558",
              "IPY_MODEL_57c484fbbc684f53a38d41d547be66ca",
              "IPY_MODEL_833d38cf37c3416f8717b2a0fb64b054"
            ],
            "layout": "IPY_MODEL_de185bccd2404b9599476aabf71fe4a9"
          }
        },
        "37bc78236ef14e5f9ddbf42a3fd23558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc98338d55cb4366996c5a91fb689669",
            "placeholder": "​",
            "style": "IPY_MODEL_1340acbcb7ac4598983139d083e0b87d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "57c484fbbc684f53a38d41d547be66ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8bc0ceb0df549e3bf58432041b94ff1",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63902b8f17764dc2bdbd8ada24bf3878",
            "value": 112
          }
        },
        "833d38cf37c3416f8717b2a0fb64b054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e953aeabc3c4db59c5ae5f1eb411a53",
            "placeholder": "​",
            "style": "IPY_MODEL_eb0f3794e8e84122af88062e3454a525",
            "value": " 112/112 [00:00&lt;00:00, 2.87kB/s]"
          }
        },
        "de185bccd2404b9599476aabf71fe4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc98338d55cb4366996c5a91fb689669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1340acbcb7ac4598983139d083e0b87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8bc0ceb0df549e3bf58432041b94ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63902b8f17764dc2bdbd8ada24bf3878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e953aeabc3c4db59c5ae5f1eb411a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb0f3794e8e84122af88062e3454a525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e1bc1a257a2452287f04deba768a0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_039599d09fc2467a9c0b287bcf5014f7",
              "IPY_MODEL_7852e57b4d444560b6c08d130753a834",
              "IPY_MODEL_a0b186dff75e4d51aeaaf8d8e82c1e8b"
            ],
            "layout": "IPY_MODEL_e43179d65b894a99a912729b862b85e6"
          }
        },
        "039599d09fc2467a9c0b287bcf5014f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d7dee7795294f51b4795a4e2be6de01",
            "placeholder": "​",
            "style": "IPY_MODEL_57aa8797bbec402490094f24d3067d69",
            "value": "model.safetensors: 100%"
          }
        },
        "7852e57b4d444560b6c08d130753a834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983d6c1637b4477aa71553e5e68d3f0b",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b554452c309c49598781c7928f8c9773",
            "value": 90868376
          }
        },
        "a0b186dff75e4d51aeaaf8d8e82c1e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70f6d4deb794a14a123f54a624b5812",
            "placeholder": "​",
            "style": "IPY_MODEL_773e659627ce4410bc2bad7cdb7d19bb",
            "value": " 90.9M/90.9M [00:02&lt;00:00, 62.8MB/s]"
          }
        },
        "e43179d65b894a99a912729b862b85e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7dee7795294f51b4795a4e2be6de01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57aa8797bbec402490094f24d3067d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "983d6c1637b4477aa71553e5e68d3f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b554452c309c49598781c7928f8c9773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70f6d4deb794a14a123f54a624b5812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "773e659627ce4410bc2bad7cdb7d19bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9839c06bf6864531bc0a6e557cde5991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f002b99180544d66bad88079dd918c5e",
              "IPY_MODEL_b93306f637eb408c98ea8b57db671d56",
              "IPY_MODEL_74474dae971a42f9a4d94e9c49811d40"
            ],
            "layout": "IPY_MODEL_68e66f944cbd4bfe86e1c9816ec5b6b0"
          }
        },
        "f002b99180544d66bad88079dd918c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ae53b8e308483fbe9ebe39958527f6",
            "placeholder": "​",
            "style": "IPY_MODEL_76862883f1194ea9b9a949c029c9da4f",
            "value": "Downloading builder script: "
          }
        },
        "b93306f637eb408c98ea8b57db671d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf51aca1f9f94231b58330d38ee0c524",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a9e18c6fa394d4d848c927eaeb86e7a",
            "value": 1
          }
        },
        "74474dae971a42f9a4d94e9c49811d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_510fc55dc2f84d2eb2d3affb5445f8e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6f2f6b8eef4e81889d3dc607141fff",
            "value": " 4.53k/? [00:00&lt;00:00, 482kB/s]"
          }
        },
        "68e66f944cbd4bfe86e1c9816ec5b6b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ae53b8e308483fbe9ebe39958527f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76862883f1194ea9b9a949c029c9da4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf51aca1f9f94231b58330d38ee0c524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2a9e18c6fa394d4d848c927eaeb86e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "510fc55dc2f84d2eb2d3affb5445f8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6f2f6b8eef4e81889d3dc607141fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "300f9838c5d9406d9e1fdd3f589b0aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af97a81d6bd14107b6999600a551e21a",
              "IPY_MODEL_bd10919aebe34e78998fe46e686e9c48",
              "IPY_MODEL_9ab95e5fc12b4493b90fc89e867027d8"
            ],
            "layout": "IPY_MODEL_62af41ec67d848cab20ddcebc687bf1d"
          }
        },
        "af97a81d6bd14107b6999600a551e21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc12054d8be4a6aa80e252655959430",
            "placeholder": "​",
            "style": "IPY_MODEL_6647f0e01fec466696080f29e9bfc9e8",
            "value": "Downloading extra modules: "
          }
        },
        "bd10919aebe34e78998fe46e686e9c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53a51ea43a5045ee835df8f3216f6a9c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faf179c036724a12930da2d9aca31e64",
            "value": 1
          }
        },
        "9ab95e5fc12b4493b90fc89e867027d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d09c3d6ff444b72831c90c5b5fbfaa6",
            "placeholder": "​",
            "style": "IPY_MODEL_57cf1655e3174d679e9acbbdc3972dc0",
            "value": " 3.32k/? [00:00&lt;00:00, 300kB/s]"
          }
        },
        "62af41ec67d848cab20ddcebc687bf1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc12054d8be4a6aa80e252655959430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6647f0e01fec466696080f29e9bfc9e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53a51ea43a5045ee835df8f3216f6a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "faf179c036724a12930da2d9aca31e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d09c3d6ff444b72831c90c5b5fbfaa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57cf1655e3174d679e9acbbdc3972dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2038c3c887224198993f63eed399ad71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a70bff99ef840a6b29bc46a867b1b70",
              "IPY_MODEL_57b6a379f0714c42bf1efd1be220d083",
              "IPY_MODEL_c32a47cc1e2d426e9e53f0b8cc150850"
            ],
            "layout": "IPY_MODEL_25ed2b0f89c74e7d92888a53568d55f5"
          }
        },
        "9a70bff99ef840a6b29bc46a867b1b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4268f2b99d744baa6019755e56ad581",
            "placeholder": "​",
            "style": "IPY_MODEL_bf332984343b4bd096ea6f19bb6aae00",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "57b6a379f0714c42bf1efd1be220d083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007a4c99c5ec464d9ab528a0740e1f36",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988bc974a6234671bf86b232cc7173c1",
            "value": 25
          }
        },
        "c32a47cc1e2d426e9e53f0b8cc150850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553894e9f7dd4557b8317048343d0f73",
            "placeholder": "​",
            "style": "IPY_MODEL_51ad6567f4174550ad5b5e00e921a9a0",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.15kB/s]"
          }
        },
        "25ed2b0f89c74e7d92888a53568d55f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4268f2b99d744baa6019755e56ad581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf332984343b4bd096ea6f19bb6aae00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "007a4c99c5ec464d9ab528a0740e1f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988bc974a6234671bf86b232cc7173c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "553894e9f7dd4557b8317048343d0f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ad6567f4174550ad5b5e00e921a9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de06b193669d4bd18f8fe53e750cda0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4739836a19be42f4b7e612f6adf46d31",
              "IPY_MODEL_eb5c1fd6f2294ba5a17be17790ee7a1e",
              "IPY_MODEL_859411ca6c3c465bbeeee9210300e5f9"
            ],
            "layout": "IPY_MODEL_41c10cd5ec414bfb9baf15a467e5d1ef"
          }
        },
        "4739836a19be42f4b7e612f6adf46d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd7ef1670c546f0880e7ad1b48d6e3e",
            "placeholder": "​",
            "style": "IPY_MODEL_fd35abd3c42d461897229131fc1c7830",
            "value": "config.json: 100%"
          }
        },
        "eb5c1fd6f2294ba5a17be17790ee7a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ca7c3a3941f492691123a99bf13f468",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24b6543b09da4239b4982d20f10aeae4",
            "value": 480
          }
        },
        "859411ca6c3c465bbeeee9210300e5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca2f093ad25418aaa113009bfdbc4b9",
            "placeholder": "​",
            "style": "IPY_MODEL_6309efce690340c585e7eb08f1a92c2a",
            "value": " 480/480 [00:00&lt;00:00, 14.4kB/s]"
          }
        },
        "41c10cd5ec414bfb9baf15a467e5d1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd7ef1670c546f0880e7ad1b48d6e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd35abd3c42d461897229131fc1c7830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca7c3a3941f492691123a99bf13f468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b6543b09da4239b4982d20f10aeae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eca2f093ad25418aaa113009bfdbc4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6309efce690340c585e7eb08f1a92c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1a1e1490a8f4cbca0a71bc1c33ab1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdf2f72223564bba837843f0227c3e35",
              "IPY_MODEL_24e6078e650d480e8f524c8ce2f28236",
              "IPY_MODEL_d6d52f308bb540cb885efcce529ab5c5"
            ],
            "layout": "IPY_MODEL_5a28e1057f4a40af800f0d238c73fffb"
          }
        },
        "cdf2f72223564bba837843f0227c3e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06186f05ebc44439b8e14525a04d114",
            "placeholder": "​",
            "style": "IPY_MODEL_b0442a1f63d843a38c42353aadbff519",
            "value": "vocab.json: 100%"
          }
        },
        "24e6078e650d480e8f524c8ce2f28236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58aa636a5b364c9482a74e61c247ffd2",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d38b9f1c848435db895f1a16b6e074a",
            "value": 898823
          }
        },
        "d6d52f308bb540cb885efcce529ab5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb2cd4d8181849caa809a9056819b921",
            "placeholder": "​",
            "style": "IPY_MODEL_95de334e634b4adf81e9c65903b3fdec",
            "value": " 899k/899k [00:00&lt;00:00, 1.14MB/s]"
          }
        },
        "5a28e1057f4a40af800f0d238c73fffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06186f05ebc44439b8e14525a04d114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0442a1f63d843a38c42353aadbff519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58aa636a5b364c9482a74e61c247ffd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d38b9f1c848435db895f1a16b6e074a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb2cd4d8181849caa809a9056819b921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95de334e634b4adf81e9c65903b3fdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc89c8afb954124b9c840da71f57da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1fd827a91fb4376a274891e363177d4",
              "IPY_MODEL_4a33c6a9490a4024a97e21b5256d178c",
              "IPY_MODEL_75bd03b8265e49a5885edcc944202a21"
            ],
            "layout": "IPY_MODEL_e5a08d79cc654ccd8b1a9914a3ee985e"
          }
        },
        "c1fd827a91fb4376a274891e363177d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e314bce97d4f412fa352711248260f62",
            "placeholder": "​",
            "style": "IPY_MODEL_2016e26a62d94848b1a4ed5cf39b16d0",
            "value": "merges.txt: 100%"
          }
        },
        "4a33c6a9490a4024a97e21b5256d178c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaae81dedc3242d488320687deb50a59",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ddd35cbf648444687390a3c84e4f92f",
            "value": 456318
          }
        },
        "75bd03b8265e49a5885edcc944202a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8b4a773cc248638ae3716ec0bb57a6",
            "placeholder": "​",
            "style": "IPY_MODEL_2ab5c636a29046619f91ecee22cb3c8b",
            "value": " 456k/456k [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "e5a08d79cc654ccd8b1a9914a3ee985e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e314bce97d4f412fa352711248260f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2016e26a62d94848b1a4ed5cf39b16d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaae81dedc3242d488320687deb50a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ddd35cbf648444687390a3c84e4f92f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8b4a773cc248638ae3716ec0bb57a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab5c636a29046619f91ecee22cb3c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cc6d484a4454844ab6cb0c5c3317e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c87c181aa4ea4f4dab6bee4b792f1850",
              "IPY_MODEL_bd5e5cfbfd974e2981ad8ffa069b875f",
              "IPY_MODEL_e668b88c7b1c44e797efc761fe2a786a"
            ],
            "layout": "IPY_MODEL_6ac931ad8a0f4e86b4a5419e64dd31a4"
          }
        },
        "c87c181aa4ea4f4dab6bee4b792f1850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb28ab7ca8744449ad618f1617834b90",
            "placeholder": "​",
            "style": "IPY_MODEL_bdb8fc9bdb814ee18ed55c35774faa16",
            "value": "tokenizer.json: 100%"
          }
        },
        "bd5e5cfbfd974e2981ad8ffa069b875f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42194dc416084edc9f536857e00cfa8f",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09c7ae63f53a44df836b8063f4934369",
            "value": 1355863
          }
        },
        "e668b88c7b1c44e797efc761fe2a786a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f47f9321e71845f7a45880c00cc15f84",
            "placeholder": "​",
            "style": "IPY_MODEL_f441a9c6dc1b430b93476ec08fea9960",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.37MB/s]"
          }
        },
        "6ac931ad8a0f4e86b4a5419e64dd31a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb28ab7ca8744449ad618f1617834b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb8fc9bdb814ee18ed55c35774faa16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42194dc416084edc9f536857e00cfa8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c7ae63f53a44df836b8063f4934369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f47f9321e71845f7a45880c00cc15f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f441a9c6dc1b430b93476ec08fea9960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "qvI0pDcwe0XN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fFYqN7CeVFq",
        "outputId": "ce64c54c-3d0d-4674-bf22-68dabd8e7fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers[sentencepiece] fastbook fastai nbdev plum-dispatch evaluate seqeval onnxruntime onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastprogress==0.2.5 -q"
      ],
      "metadata": {
        "id": "zMGg8gxGk8MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/msi1427/blurr.git\n",
        "%cd blurr"
      ],
      "metadata": {
        "id": "hnM9ot0FemPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ec3ac4-6e9a-401e-a8ee-c74c181fba6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'blurr'...\n",
            "remote: Enumerating objects: 5063, done.\u001b[K\n",
            "remote: Counting objects: 100% (894/894), done.\u001b[K\n",
            "remote: Compressing objects: 100% (311/311), done.\u001b[K\n",
            "remote: Total 5063 (delta 705), reused 702 (delta 576), pack-reused 4169 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5063/5063), 26.85 MiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (3934/3934), done.\n",
            "/content/blurr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "from fastai.text.all import *\n",
        "from blurr.text.data.all import *\n",
        "from blurr.text.modeling.all import *"
      ],
      "metadata": {
        "id": "IUJmQ-SnemuE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9839c06bf6864531bc0a6e557cde5991",
            "f002b99180544d66bad88079dd918c5e",
            "b93306f637eb408c98ea8b57db671d56",
            "74474dae971a42f9a4d94e9c49811d40",
            "68e66f944cbd4bfe86e1c9816ec5b6b0",
            "45ae53b8e308483fbe9ebe39958527f6",
            "76862883f1194ea9b9a949c029c9da4f",
            "bf51aca1f9f94231b58330d38ee0c524",
            "2a9e18c6fa394d4d848c927eaeb86e7a",
            "510fc55dc2f84d2eb2d3affb5445f8e8",
            "ad6f2f6b8eef4e81889d3dc607141fff",
            "300f9838c5d9406d9e1fdd3f589b0aec",
            "af97a81d6bd14107b6999600a551e21a",
            "bd10919aebe34e78998fe46e686e9c48",
            "9ab95e5fc12b4493b90fc89e867027d8",
            "62af41ec67d848cab20ddcebc687bf1d",
            "fdc12054d8be4a6aa80e252655959430",
            "6647f0e01fec466696080f29e9bfc9e8",
            "53a51ea43a5045ee835df8f3216f6a9c",
            "faf179c036724a12930da2d9aca31e64",
            "1d09c3d6ff444b72831c90c5b5fbfaa6",
            "57cf1655e3174d679e9acbbdc3972dc0"
          ]
        },
        "outputId": "ec01c9f0-6fb3-4626-a214-1969c1d43dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9839c06bf6864531bc0a6e557cde5991"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "300f9838c5d9406d9e1fdd3f589b0aec"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RGs4dnvbex2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09524d70-1ae6-4b99-f493-d5b69568a4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/Data Science/CP3_Skill Classifier'"
      ],
      "metadata": {
        "id": "MZTe2pjWezZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "kRfN9Pf1fLPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "EU-O2ZgMfKsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge csv files\n",
        "\n",
        "# files_data_path =  '/content/drive/MyDrive/Data Science/CP3_Skill Classifier/data'\n",
        "# csv_files = [f for f in os.listdir(files_data_path) if f.endswith('.csv')]\n",
        "\n",
        "# data_frame = []\n",
        "\n",
        "# for file in tqdm(csv_files, desc='Loading csv files'):\n",
        "#   file_path = os.path.join(files_data_path, file)\n",
        "#   df = pd.read_csv(file_path)\n",
        "#   data_frame.append(df)\n",
        "\n",
        "# merged_df = pd.concat(data_frame, ignore_index=True)\n",
        "# save_path = os.path.join(files_data_path, 'merged_data.csv')\n",
        "# merged_df.to_csv(save_path, index=False)"
      ],
      "metadata": {
        "id": "jozaEHl1fM_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Science/CP3_Skill Classifier/data/job_description_details_merged.csv')"
      ],
      "metadata": {
        "id": "2YiZ-QI3fXhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKBT8JmVDyI",
        "outputId": "d6e1bbc6-6c36-46df-e562-162ec339ae4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26628, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0Dx0HxSYgwZ"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['company','location','salary','job_type','scraped_at','search_term'], axis=1, errors='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLinzPmgYMqH",
        "outputId": "6751d4a0-0741-4409-f122-fdbd28179333",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                        job_url  \\\n",
              "0        https://www.indeed.com/rc/clk?jk=30004c91028a89fc&bb=mwe0i5XWaAPLfcRuq83t2zcDFYMulFgGJ-OXx1jczyNSQkc-0RGjHF8WtS-4dD0cYuBvYBKdThPawTcDGupUv4vKEXy6ZAtHt13Y0F33zVemRXIJBgkhetaZyv7hqb6sNJfi9XGd4HvmKYQlsOJF6aDmKfEqoawW&xkcb=SoDg67M3rr6gcbyJ5x0ObzkdCdPP&fccid=1bf91941851502d5&cmp=Quadrant-Technologies&ti=Full+Stack+Developer&vjs=3   \n",
              "1                                                          https://www.indeed.com/rc/clk?jk=f157bf1dbeefd084&bb=m9RG7v5lRw2rGszMCeVVyHk7Av-6nmTONcuJySpm1RLmKHqCOAUOTu0ZnrF5mTHBFaTEoAJi_L_Q_9HjbfETD7JmLssENtQhb2HmukiYWYhGAc77slyCzxoyZAB2H215HldyKX11DsNPRcgai6UnCS3_gUqUDVml&xkcb=SoCK67M3rr4wSzSsTJ0GbzkdCdPP&fccid=dd616958bd9ddc12&vjs=3   \n",
              "2                                                          https://www.indeed.com/rc/clk?jk=8f55771c8ec493ed&bb=GiebJ7j60o2dgNvdFhdm6u-UI94O41pCRMncyUB3RnEf8F8swt_jNXo5RQVA5dJbXAJpJu24zOSg-aMuB7tBZyKuCHiTkNGaK_7fBd5eAgmUGXwDVLrlbqHH0AAuOpUgyfzWnfYMi0rv36DpFZX_yGXEa0ouvh9A&xkcb=SoDz67M3rr5U0aSsbh0ObzkdCdPP&fccid=43687eef14e26aa1&vjs=3   \n",
              "3                                                          https://www.indeed.com/rc/clk?jk=40216dabf53625bb&bb=picpFUMdRHYiSWmFzDrkGEsse_AY4NzaAJhEz1sH8TaB648GTPkzSTTUWyAlrQAho1nu7dHSLFgt6qR6yOEqzBR4v5tqbeypt9BznpVObXb63qurzArx3WOZ-v9MOLXkYE2g4N8JrVzU9Y2IEzGzpNJx28y8JnMV&xkcb=SoCP67M3rr5LwxxNTp0ObzkdCdPP&fccid=c9215f77446452bb&vjs=3   \n",
              "4  https://www.indeed.com/rc/clk?jk=c958dedfc005da7b&bb=g_ghKA-AJdCW7e2m2Vn9Kga1lrDPZ7Q8ohnkF4QmJwv5TPPPHTL3a0S088rQR0TsKCKOb5SQh5VL_WyQzwEkwuWFnQ5Jyxfl9tXiy6wpRPt7sp23jlcdm-3Bc6ouD2Vq4bLkmk08DXq7xIMnQO9YdojWvtXhjuOs&xkcb=SoBJ67M3rrn5lKSkFR0FbzkdCdPP&fccid=4e64238c89e14944&cmp=Tangspac-Consulting-Pte-Ltd&ti=Full+Stack+Developer&vjs=3   \n",
              "\n",
              "  title job_description  \n",
              "0   NaN             NaN  \n",
              "1   NaN             NaN  \n",
              "2   NaN             NaN  \n",
              "3   NaN             NaN  \n",
              "4   NaN             NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afdb91cd-bc30-4864-aa29-9fc74d368ab8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_url</th>\n",
              "      <th>title</th>\n",
              "      <th>job_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=30004c91028a89fc&amp;bb=mwe0i5XWaAPLfcRuq83t2zcDFYMulFgGJ-OXx1jczyNSQkc-0RGjHF8WtS-4dD0cYuBvYBKdThPawTcDGupUv4vKEXy6ZAtHt13Y0F33zVemRXIJBgkhetaZyv7hqb6sNJfi9XGd4HvmKYQlsOJF6aDmKfEqoawW&amp;xkcb=SoDg67M3rr6gcbyJ5x0ObzkdCdPP&amp;fccid=1bf91941851502d5&amp;cmp=Quadrant-Technologies&amp;ti=Full+Stack+Developer&amp;vjs=3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=f157bf1dbeefd084&amp;bb=m9RG7v5lRw2rGszMCeVVyHk7Av-6nmTONcuJySpm1RLmKHqCOAUOTu0ZnrF5mTHBFaTEoAJi_L_Q_9HjbfETD7JmLssENtQhb2HmukiYWYhGAc77slyCzxoyZAB2H215HldyKX11DsNPRcgai6UnCS3_gUqUDVml&amp;xkcb=SoCK67M3rr4wSzSsTJ0GbzkdCdPP&amp;fccid=dd616958bd9ddc12&amp;vjs=3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=8f55771c8ec493ed&amp;bb=GiebJ7j60o2dgNvdFhdm6u-UI94O41pCRMncyUB3RnEf8F8swt_jNXo5RQVA5dJbXAJpJu24zOSg-aMuB7tBZyKuCHiTkNGaK_7fBd5eAgmUGXwDVLrlbqHH0AAuOpUgyfzWnfYMi0rv36DpFZX_yGXEa0ouvh9A&amp;xkcb=SoDz67M3rr5U0aSsbh0ObzkdCdPP&amp;fccid=43687eef14e26aa1&amp;vjs=3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=40216dabf53625bb&amp;bb=picpFUMdRHYiSWmFzDrkGEsse_AY4NzaAJhEz1sH8TaB648GTPkzSTTUWyAlrQAho1nu7dHSLFgt6qR6yOEqzBR4v5tqbeypt9BznpVObXb63qurzArx3WOZ-v9MOLXkYE2g4N8JrVzU9Y2IEzGzpNJx28y8JnMV&amp;xkcb=SoCP67M3rr5LwxxNTp0ObzkdCdPP&amp;fccid=c9215f77446452bb&amp;vjs=3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=c958dedfc005da7b&amp;bb=g_ghKA-AJdCW7e2m2Vn9Kga1lrDPZ7Q8ohnkF4QmJwv5TPPPHTL3a0S088rQR0TsKCKOb5SQh5VL_WyQzwEkwuWFnQ5Jyxfl9tXiy6wpRPt7sp23jlcdm-3Bc6ouD2Vq4bLkmk08DXq7xIMnQO9YdojWvtXhjuOs&amp;xkcb=SoBJ67M3rrn5lKSkFR0FbzkdCdPP&amp;fccid=4e64238c89e14944&amp;cmp=Tangspac-Consulting-Pte-Ltd&amp;ti=Full+Stack+Developer&amp;vjs=3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afdb91cd-bc30-4864-aa29-9fc74d368ab8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afdb91cd-bc30-4864-aa29-9fc74d368ab8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afdb91cd-bc30-4864-aa29-9fc74d368ab8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26628,\n  \"fields\": [\n    {\n      \"column\": \"job_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23818,\n        \"samples\": [\n          \"https://www.indeed.com/rc/clk?jk=5c2cf4755d2a052a&bb=QhXjWlOzto6E4W3ymEF871OKhM8X7BuQ7N6s3mM-C2a0wbmgO22Me8DEa1Ru71SAIk41S4EfkW9bYX0VWBZB3l85MTpY1lJD7X5zJt0IJkOusrCwU7vP-aC7lRwZB5Y5aEGwoH7HNHVcaWqxCWpYY9EhvhB9u5YD&xkcb=SoAf67M3rrybtiSkIx0CbzkdCdPP&fccid=36f51bd4e04d587b&vjs=3\",\n          \"https://www.indeed.com/rc/clk?jk=ebe24a43bca30114&bb=32JwTNEqjOUG-TS9TD4s9zNt0gOCeKrs80PWhrcEhfYHzG1dy3maz9gqkzo3_jxbT5DrFUCSNvlO3-uoIeNtiFxXkUjqG3iai1B4QPd0xWd3hq24RB9RO81f_YXgkJHYfivzH7LJWMpq6koVXcsQ-FjCRfCj4ipy&xkcb=SoCA67M3rr31RYQvy50ObzkdCdPP&fccid=6b7cfd09722d2164&vjs=3\",\n          \"https://www.indeed.com/rc/clk?jk=e904de229027083a&bb=yOUXJe5_eFFvQpIcu3NPKk3pjz6nm6J_0c-WIQ_yQTnqEbIpoDucUfjg2fkZ-T9ZtgtToVu_r2PNCMjQMkFllp9BkDDsU9sDtBtFxCiS-0Ggw_MRks6mpSe_CENAdSPGm24vNeqzaxpgfIjC6YjhHA%3D%3D&xkcb=SoCx67M3rr-4rwSsTp0AbzkdCdPP&fccid=345bbea018a307d1&vjs=3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7147,\n        \"samples\": [\n          \"Michigan-barred Litigators\",\n          \"Statistical Programming Manager\",\n          \"LatAm - Senior QA Automation MX\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10053,\n        \"samples\": [\n          \"About Us\\nSwan Island Networks has been developing situational intelligence and alerting software for over a decade. Swan Island's current TX360\\u00ae platform helps companies make faster, better informed decisions in mission critical situations. Our legacy TIES\\u00ae SaaS product was used around the world in situations such as the Egyptian Revolution, the Fukushima nuclear melt-down and the West Africa Ebola crisis. Today our products are right in the middle of helping companies navigate disruptions due to wildfire season, hurricanes, the primaries and more. Founded by 20-year veterans of the cyber security industry, Swan Island Networks began as a software engineering lab working with the US government, focusing on R&D programs. Now our primary focus is on the large enterprise market. A career at Swan Island will give you a prominent role in the development of our flagship product TX360\\u00ae as we take it to market.\\nPosition\\nFull-time Senior Software Engineer\\nResponsibilities\\nThis role requires extensive back-end work using technologies such as Entity Framework and Azure. The ideal candidate is familiar with advanced MS SQL and cloud-based applications. Sprints are short and development is rapid and iterative. Each member of our small team wears many hats and is comfortable testing and increasing our respective skill sets. You should be, too. Easy, no-drama collaboration is crucial to maintaining our fast pace, so affability is a big asset!\\nRequirements\\n.NET/C# 4.5\\nEntity Framework 6 (POCO, Fluent API)\\nMicrosoft Azure (Deployment, Management, Cloud Services, Service Bus, Apps and Storage)\\nMS SQL/SQL Azure\\nBonus Points\\nASP.NET MVC and WebAPI\\nCQRS\\nGIS\\nLeafletJS/Bing Maps/Google Maps/ESRI\\nMachine Learning\\nMCP\\n\\nThis is a remote position.\",\n          \"Data Analyst\\nCommon Sense Media is dedicated to improving the lives of kids and families by providing the trustworthy information, education, and independent voice they need to thrive. Our ratings, research, and resources reach more than 150 million users worldwide and 1.4 million educators every year. Learn more at commonsense.org.\\nJob Overview:\\nWe're looking for a Data Analyst to join our growing data team and help drive product innovation and membership growth at Common Sense. In this role, you'll analyze user behavior and engagement across our website and mobile apps, turning complex data into clear, actionable insights. Your work will directly influence product development, marketing strategy, and the overall user experience for millions of families.\\nYou'll collaborate closely with Product, Marketing, and Engineering teams, helping us measure success, improve decision-making, and expand our self-service analytics capabilities. We're also exploring how AI-powered analytics tools can accelerate insights, automate reporting, and support smarter experimentation, and you'll play a role in shaping that direction.\\nLocation: San Francisco, California\\nReports To: Senior Director, Data & Technology\\nSalary: $85,600\\u2013$101,650 per year\\nType: Full-time, exempt\\nWhat You'll Do\\nData Analysis & Insight Delivery\\nAnalyze user behavior, engagement patterns, and conversion funnels across web and mobile.\\nIdentify opportunities to improve the user experience by mapping cross-platform user journeys.\\nGenerate actionable insights to inform product features, marketing campaigns, and growth strategies.\\nPartner with the Product and Marketing teams to define success metrics and ensure accurate event tracking.\\nExperiment with AI-driven analytics tools to automate analysis, uncover trends, and speed up insight generation.\\nReporting & Communication\\nBuild and maintain dashboards and reports that track KPIs across web and app experiences.\\nCreate compelling visualizations and narratives that make data accessible to stakeholders at all levels.\\nPresent findings and recommendations to leadership, driving data-informed decision-making.\\nContribute to developing best practices in reporting, including AI-assisted data visualization and storytelling.\\nData Quality & Governance\\nEnsure accuracy and consistency in tracking and reporting across analytics platforms.\\nCollaborate with Engineering on event taxonomy, tracking validation, and implementation.\\nSupport the migration from Google Analytics to Amplitude, and help document best practices.\\nStrategic Contribution\\nProvide insight into acquisition channels, retention drivers, and cross-platform engagement.\\nSupport A/B testing and experimentation programs to optimize product and marketing initiatives.\\nAnalyze content performance and usage trends to inform the product road map.\\nExplore how emerging AI analytics solutions can augment experimentation, predictive modeling, and personalization.\\nWhat We're Looking For\\nRequired Qualifications\\n4+ years of experience in data analysis, product analytics, or business intelligence.\\nStrong SQL skills for data extraction and analysis.\\nHands-on experience with a product analytics platform (Amplitude, Mixpanel, Heap, etc.) and the ability to learn new tools quickly.\\nSolid understanding of statistical analysis and A/B testing.\\nProficiency with data visualization tools (Excel/Google Sheets, Tableau, Power BI, or similar).\\nCuriosity about and/or experience with AI-assisted analytics platforms (e.g., ThoughtSpot, Akkio, ChatGPT-powered BI, or similar emerging tools).\\nStrong business acumen, with the ability to translate data into strategic insights.\\nExcellent communication skills, with the ability to tell stories with data and influence non-technical stakeholders.\\nCollaborative approach to working with the Product, Marketing, and Engineering teams.\\nBachelor's degree in a quantitative field (data science, statistics, economics, mathematics, etc.).\\nPreferred Qualifications\\nDirect experience with Amplitude and/or GA4.\\nFamiliarity with email marketing metrics and platforms (e.g., Braze, Salesforce Marketing Cloud).\\nExperience designing and analyzing experiments (A/B testing platforms a plus).\\nKnowledge of ETL pipelines, data warehouses, and SQL databases.\\nExperience with consumer-facing digital products, mobile apps, or membership-based platforms.\\nBackground in content platforms, edtech, or family-focused organizations.\\nPython or R skills for advanced analysis.\\nWhat We Offer:\\nThe chance to work with talented, passionate professionals.\\nA great health and welfare benefits package, including medical, dental, vision, and a matching 401(k).\\nAn organization that offers work/life balance.\\nThe opportunity to really make a difference in the lives of kids and families!\\nCommon Sense Media provides equal employment opportunities to all qualified individuals and prohibits discrimination and harassment of any type without regard to race, color, religion, sex, gender identity, sexual orientation, pregnancy, age, national origin, physical or mental disability, military or veteran status, genetic information, or any other protected classification or characteristic protected by federal, state, or local laws.\\nCommon Sense Media will also consider for employment qualified applicants with arrest and conviction records. However, job offers are made on the condition that the applicant subsequently passes a criminal background check. If the background check indicates a prior criminal conviction, we will conduct an individualized assessment to determine whether the conviction should result in denial of employment. Pursuant to the San Francisco Fair Chance Ordinance, we will consider employment for qualified applicants with arrest and conviction records.\",\n          \"This role is not eligible for visa sponsorship.\\n\\nROLE OVERVIEW:\\nWill be responsible for data collection efforts, including carrying out data collection efforts with internal and external stakeholders. Provides day-to-day support of data quality and data platform management\\n\\nESSENTIAL JOB RESPONSIBILITIES include but are not limited to:\\nSupports and demonstrates IMA's core values.\\nValues and understands the importance of diversity, equity, and inclusion among all IMA associates.\\nData warehousing and benchmarking operational support\\nInteracts with IMA's benefits analytics partners including data feeds to the data analytics partner, ongoing system and IMA user issues.\\nInitiates onboarding requests with data warehousing vendor team\\nTakes lead on communication with data warehousing vendor team\\nConducts audits on current data, detecting potential data quality issues\\nManages day-to-day functioning of users within data warehousing and benchmarking platforms\\nData warehousing subject matter support\\nPeer review of reporting from data warehousing system for service teams\\nObtains a clear understanding of data warehousing systems to assist with general reporting and tool development\\nReporting\\nAssists in updates of tools and content\\nContributes to service team reporting and help teams understand outputs\\nUpdates operational tasks for employee benefits team\\nAssists with completing ad hoc analysis and benchmarking reports for client delivery\\nCollaborates with client delivery teams to collect and summarize book of business data\\nREQUIRED EXPERIENCE AND SKILLS include but are not limited to:\\nUp to 2 years of similar or related experience\\nBachelor's Degree required, degree in analytical subject preferred.\\nExperience with MS Office products required (specifically Excel, PowerPoint, Outlook, and Word).\\nLimited travel required (less than 25%).\\nStrong organizational skills, with ability to manage several data sources or projects simultaneously.\\nAbility to effectively plan and organize work independently.\\nRequired: proficient with MS Office Suites with intermediate skills, emphasis on Excel\\nAnalyzes and interprets data.\\nAbility to execute operational processes.\\nHandles confidential information with tact and discretion.\\nClearly communicates ideas in a concise manner including in presentations and written correspondence.\\nActively listens, shares information, and proposes suggestions and solutions.\\nExpresses oneself effectively both orally and in written form.\\nCuriosity and willingness to research data questions, often from scratch.\\nLearns and utilizes current and new technologies while embracing new technologies.\\nThe anticipated posting timeline for this opportunity is 10/01/2025-11/13/2025.\\n\\n#LI-RH1\\n\\nCompensation & Benefits\\nBeing a part of IMA has its benefits. When you become part of the IMA family, you become eligible to take part in our valuable benefits and rewards package designed to benefit you, your family, and your life. Our plans are cost-effective, convenient and provide progressive ways for staying healthy, protecting loved ones, pursuing financial security and living a full and balanced life. This role is eligible for the following:\\n\\nAnnual Performance Bonus, Stock Purchase, Medical Plans, Prescription Drugs, Dental, Vision, Family Assistance Program, FSA, HSA, Pre-Tax Parking Plan, 401(k), Life/AD&D, Accident, Critical Illness, Hospital Indemnity, Long Term Care, Short-term Disability, Long-term Disability, Business Travel Accident, Identity Theft, Paid Time Off, Flexible Work Options, Paid Holidays, Sabbatical, Gift Matching, Health Club Reimbursement, Personal and Professional Development. In addition to our robust benefits package, the final offer amounts will depend on a variety of factors, including the candidate's geographic location, prior relevant experience, and their knowledge, skills, and abilities.\\nWhy Join IMA?\\nWe've built a reputation for putting our associates first\\nWhat if we told you that you could be an integral part of an entrepreneurial, expanding company, develop lasting relationships, earn competitive benefits, plus claim part ownership? It's this unique ownership business model that makes working at IMA so appealing.\\nWe work in teams. We sell in teams. We win and prosper as a team\\nWe provide support systems and resources that enable each of our associates to focus on what they do best. And as an independent company based in the Midwest, we're big enough to write business all over the world and small enough to implement your ideas quickly.\\nWe are recognized nationally as a leader in our industry\\n2020-2023 Business Insurance Magazine Best Places to Work in Insurance\\n2023 Inc. Magazine's Best Workplaces\\n2023 Denver Business Journal's Best Places to Work\\n2022-2023 Connecticut Top Work Places\\n2021-2023 Inc. 5000's List of Fastest Growing Companies\\n2019-2022 Civic 50 Colorado Honoree Recognizing 50 Most Community-Minded Companies\\n2022-2023 Kansas City Business Journal's Best Places to Work\\n2021-2023 Charlotte Business Journal's Best Places to Work\\n2021-2023 Los Angeles Business Journal's Best Places to Work\\n2021-2023 The Salt Lake City Tribune Top Work Places\\n2021-2022 Puget Sound Business Journal's Washington's Best Workplaces\\n2021-2022 Wichita Business Journal's Best Places to Work, #1 in extra-large category\\n2021 Dallas Business Journal's Best Places to Work\\n2021 Alaska Journal of Commerce's Best Workplaces in Alaska\\nThis Job Description is not a complete statement of all duties and responsibilities comprising this position.\\nThe IMA Financial Group, Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability or genetics. In addition to federal law requirements, The IMA Financial Group, Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcxVEQeY0td",
        "outputId": "8dec134b-e458-4b7c-e253-2e33a93e2073"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "job_url               0\n",
              "title               662\n",
              "job_description    2103\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>job_url</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job_description</th>\n",
              "      <td>2103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bvg5vDinfc9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-CuLgZIY--5"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ecvBF_ZXLE",
        "outputId": "e519efd3-e04e-4533-e8b5-a2531d6553b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "job_url            0\n",
              "title              0\n",
              "job_description    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>job_url</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job_description</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk9zki4AZnRb",
        "outputId": "d6c0fda3-28af-459d-b0cf-04193c5c675b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1667)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# checking for duplicates\n",
        "df['job_url'].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I6_dOxtaTeC"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset='job_url', keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jajt-2dlajZL",
        "outputId": "1753289a-36c1-464f-9006-6fa33eb91785"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4GtCZQaak_o",
        "outputId": "e30eb0fc-c554-4ff5-b9ae-80d8f24af8e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22858, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBDf74iiOwOl"
      },
      "outputs": [],
      "source": [
        "skill_patterns = {\n",
        "    # Programming Languages\n",
        "    'Python': r'\\bpython\\b',\n",
        "    'Java': r'\\bjava\\b(?!script)',\n",
        "    'C/C++': r'\\b(c\\+\\+|cpp|cplusplus|c programming|(?<!\\w)c(?!\\+\\+|\\#|\\w))\\b',\n",
        "    'SQL': r'\\b(sql|structured query language|mysql|postgresql|tsql|pl/sql|mssql)\\b',\n",
        "    'R': r'\\b(r programming|(?<!\\w)r(?!\\w))\\b',\n",
        "    'JavaScript': r'\\b(javascript|js|ecmascript)\\b',\n",
        "\n",
        "    # AI/ML/Data Science\n",
        "    'Machine Learning': r'\\b(machine learning|ml|maching learning)\\b',\n",
        "    'Deep Learning': r'\\b(deep learning|dl|neural networks)\\b',\n",
        "    'Artificial Intelligence': r'\\b(artificial intelligence|ai)\\b',\n",
        "    'Natural Language Processing': r'\\b(natural language processing|nlp|text analytics)\\b',\n",
        "    'Data Analysis': r'\\b(data analysis|data analytics|analyzing data)\\b',\n",
        "    'Data Visualization': r'\\b(data visualization|data viz|dataviz|visualizing data)\\b',\n",
        "    'EDA': r'\\b(eda|exploratory data analysis|exploratory analysis)\\b',\n",
        "    'Data Cleaning & Wrangling': r'\\b(data cleaning|data wrangling|data preprocessing|data preparation)\\b',\n",
        "    'Data Modeling': r'\\b(data modeling|data modelling|dimensional modeling)\\b',\n",
        "    'Big Data Technologies': r'\\b(big data|hadoop|spark|apache spark|hive|kafka|flink)\\b',\n",
        "    'A/B Testing': r'\\b(a/b testing|ab testing|a b testing|split testing)\\b',\n",
        "    'PyTorch': r'\\b(pytorch|torch)\\b',\n",
        "    'LLM': r'\\b(llm|large language model|language model|gpt|bert|transformer)\\b',\n",
        "\n",
        "    # Development\n",
        "    'Web Development': r'\\b(web development|web dev|website development)\\b',\n",
        "    'Front End Development': r'\\b(front[\\s-]?end|frontend|front[\\s-]?end development|client[\\s-]?side|fe development)\\b',\n",
        "    'Back End Development': r'\\b(back[\\s-]?end|backend|back[\\s-]?end development|server[\\s-]?side|be development)\\b',\n",
        "    'Mobile App Development': r'\\b(mobile|mobile app|mobile development|mobile application)\\b',\n",
        "    'Android Development': r'\\b(android|android development|android studio|kotlin)\\b',\n",
        "    'iOS Development': r'\\b(ios|ios development|swift|objective[\\s-]?c)\\b',\n",
        "    'API Development': r'\\b(api|rest api|restful|api development|web services|microservices api)\\b',\n",
        "\n",
        "    # Frameworks & Libraries\n",
        "    'React': r'\\b(react|reactjs|react\\.js)\\b',\n",
        "    'Node.js': r'\\b(node|nodejs|node\\.js)\\b',\n",
        "    'Django': r'\\bdjango\\b',\n",
        "    'Flask': r'\\bflask\\b',\n",
        "\n",
        "    # Cloud & Infrastructure\n",
        "    'Cloud Computing': r'\\b(cloud|cloud computing|cloud services)\\b',\n",
        "    'AWS': r'\\b(aws|amazon web services)\\b',\n",
        "    'Azure': r'\\b(azure|microsoft azure|ms azure)\\b',\n",
        "    'GCP': r'\\b(gcp|google cloud platform|google cloud)\\b',\n",
        "    'DevOps': r'\\b(devops|dev[\\s-]?ops)\\b',\n",
        "    'Docker': r'\\b(docker|containerization)\\b',\n",
        "    'Kubernetes': r'\\b(kubernetes|k8s)\\b',\n",
        "    'CI/CD': r'\\b(ci/cd|ci cd|cicd|continuous integration|continuous deployment|continuous delivery)\\b',\n",
        "    'Containerization': r'\\b(containerization|containers|docker|kubernetes)\\b',\n",
        "    'Microservices': r'\\b(microservices|micro[\\s-]?services|microservice architecture)\\b',\n",
        "    'Site Reliability Engineering': r'\\b(site reliability engineering|sre|reliability engineering)\\b',\n",
        "    'Systems Administration': r'\\b(systems administration|system administration|sysadmin|sys admin)\\b',\n",
        "\n",
        "    # Version Control & Tools\n",
        "    'Git Version Control': r'\\b(git|version control|source control)\\b',\n",
        "    'Git': r'\\bgit\\b',\n",
        "    'GitHub': r'\\b(github|git hub)\\b',\n",
        "    'Excel': r'\\b(excel|ms excel|microsoft excel|spreadsheet)\\b',\n",
        "    'Power BI': r'\\b(power bi|powerbi|power[\\s-]?bi)\\b',\n",
        "    'Tableau': r'\\b(tableau)\\b',\n",
        "\n",
        "    # Database & Data Engineering\n",
        "    'Database Management': r'\\b(database|database management|dbms|rdbms|database administration|dba)\\b',\n",
        "    'ETL': r'\\b(etl|extract transform load|data pipelines)\\b',\n",
        "    'Data Pipelines': r'\\b(data pipelines|data pipeline|pipeline|airflow)\\b',\n",
        "    'Business Intelligence': r'\\b(business intelligence|bi|business analytics)\\b',\n",
        "\n",
        "    # Design & Engineering\n",
        "    'UI/UX Design': r'\\b(ui/ux|ui ux|ux/ui|ui & ux|ux & ui|user interface|user experience|ux design|ui design|ux|ui)\\b',  # Catches UI, UX, or both\n",
        "    'CAD Design': r'\\b(cad|computer aided design|autocad|solidworks)\\b',\n",
        "    'System Design': r'\\b(system design|systems design|architecture design|solution design)\\b',\n",
        "\n",
        "    # Security & Testing\n",
        "    'Cybersecurity': r'\\b(cybersecurity|cyber security|information security|infosec|security)\\b',\n",
        "    'Software Testing': r'\\b(software testing|testing|qa testing|test automation)\\b',\n",
        "    'Quality Assurance': r'\\b(quality assurance|qa|software quality)\\b',\n",
        "    'Automation Testing': r'\\b(automation testing|test automation|automated testing|selenium|cypress)\\b',\n",
        "\n",
        "    # Technical Concepts\n",
        "    'Computer Networking': r'\\b(computer networking|networking|network|tcp/ip|lan/wan)\\b',\n",
        "    'Embedded Systems': r'\\b(embedded systems|embedded|firmware|microcontroller)\\b',\n",
        "    'Internet of Things': r'\\b(internet of things|iot)\\b',\n",
        "    'Robotics': r'\\b(robotics|robot|robotic)\\b',\n",
        "    'Automation': r'\\b(automation|automate|automated)\\b',\n",
        "    'Software Engineering Principles': r'\\b(software engineering|engineering principles|best practices|design patterns|solid principles)\\b',\n",
        "    'Object-Oriented Programming': r'\\b(object[\\s-]?oriented programming|oop|object[\\s-]?oriented)\\b',\n",
        "    'Data Structures & Algorithms': r'\\b(data structures|algorithms|dsa|data structures and algorithms)\\b',\n",
        "    'IT Support': r'\\b(it support|technical support|help desk|tech support)\\b',\n",
        "\n",
        "    # Soft Skills\n",
        "    'Communication': r'\\b(communication|communicate|verbal|written communication|interpersonal)\\b',\n",
        "    'Teamwork': r'\\b(teamwork|team work|team collaboration|working in teams)\\b',\n",
        "    'Leadership': r'\\b(leadership|lead|leading teams|team leadership)\\b',\n",
        "    'Problem Solving': r'\\b(problem solving|problem[\\s-]?solving|troubleshooting)\\b',\n",
        "    'Adaptability': r'\\b(adaptability|adaptable|flexible|flexibility)\\b',\n",
        "    'Creativity': r'\\b(creativity|creative|innovation|innovative)\\b',\n",
        "    'Time Management': r'\\b(time management|time[\\s-]?management|prioritization)\\b',\n",
        "    'Attention to Detail': r'\\b(attention to detail|detail[\\s-]?oriented|meticulous)\\b',\n",
        "    'Critical Thinking': r'\\b(critical thinking|analytical thinking|critical analysis)\\b',\n",
        "    'Decision Making': r'\\b(decision making|decision[\\s-]?making|decisiveness)\\b',\n",
        "    'Collaboration': r'\\b(collaboration|collaborative|collaborate)\\b',\n",
        "    'Work Ethic': r'\\b(work ethic|strong work ethic|dedicated|dedication)\\b',\n",
        "    'Emotional Intelligence': r'\\b(emotional intelligence|eq|empathy|empathetic)\\b',\n",
        "    'Self-Motivation': r'\\b(self[\\s-]?motivation|self[\\s-]?motivated|self[\\s-]?starter|proactive)\\b',\n",
        "    'Flexibility': r'\\b(flexibility|flexible|adaptable)\\b',\n",
        "}\n",
        "\n",
        "\n",
        "for skill, pattern in skill_patterns.items():\n",
        "    df[skill] = df['job_description'].str.contains(\n",
        "        pattern,\n",
        "        case=False,\n",
        "        na=False,\n",
        "        regex=True\n",
        "    ).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R90UPrSTHDpc"
      },
      "outputs": [],
      "source": [
        "skills = [\n",
        "    # Technical Skills\n",
        "    'Python', 'Java', 'C/C++', 'SQL', 'Machine Learning', 'Deep Learning',\n",
        "    'Data Analysis', 'Data Visualization', 'Web Development', 'Front End Development',\n",
        "    'Back End Development', 'Cloud Computing', 'DevOps', 'Cybersecurity',\n",
        "    'Computer Networking', 'Database Management', 'Software Testing',\n",
        "    'UI/UX Design', 'Mobile App Development', 'Artificial Intelligence',\n",
        "    'Natural Language Processing', 'Embedded Systems', 'Internet of Things',\n",
        "    'CAD Design', 'Robotics', 'Automation', 'API Development', 'Excel', 'Power BI',\n",
        "    'Git Version Control', 'R', 'JavaScript', 'Tableau', 'Git', 'GitHub', 'Docker',\n",
        "    'Kubernetes', 'AWS', 'Azure', 'GCP', 'React', 'Node.js',\n",
        "    'Django', 'Flask', 'Android Development', 'iOS Development',\n",
        "    'EDA','PyTorch','' 'Data Cleaning & Wrangling', 'Business Intelligence',\n",
        "    'Data Modeling', 'ETL', 'Data Pipelines', 'Big Data Technologies', 'A/B Testing',\n",
        "    'Microservices', 'System Design', 'Software Engineering Principles',\n",
        "    'Object-Oriented Programming', 'Data Structures & Algorithms', 'CI/CD',\n",
        "    'Containerization', 'Site Reliability Engineering', 'Systems Administration',\n",
        "    'IT Support', 'Quality Assurance', 'Automation Testing', 'LLM',\n",
        "\n",
        "    # Soft Skills\n",
        "    'Communication', 'Teamwork', 'Leadership', 'Problem Solving', 'Adaptability',\n",
        "    'Creativity', 'Time Management', 'Attention to Detail', 'Critical Thinking',\n",
        "    'Decision Making', 'Collaboration', 'Work Ethic', 'Emotional Intelligence',\n",
        "    'Self-Motivation', 'Flexibility'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t8ic5ezQTpg",
        "outputId": "fc95ea7a-6b06-4e2f-bda0-c5f7735aa4b2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                              job_url  \\\n",
              "657  https://www.indeed.com/rc/clk?jk=73b5c238fe0e6303&bb=zZKk4GPd03d9egsQxsn3kO9skDJOM_mvk2M2EWUn-_F5kxJTC_pWEzoI-OeNbUvp7S6QOxAIcqNGyg4R4ItV8SChU9qpEpUhfEKfuD7yF-rM2ON5nqZOnqwuS2TOQ5rlSEm3xO12bnHiyquDWjHiNw%3D%3D&xkcb=SoD367M3rqeC0CSl1R0BbzkdCdPP&fccid=fcca639559bdd82a&vjs=3   \n",
              "658  https://www.indeed.com/rc/clk?jk=ea79974ba1e60c2d&bb=KdZ-UDfEWbelc9dxMB_Pgg2lsrBaV1gUTAFPOSdxIfjHI-UZUu52amClVfvIv6trPtjqyjhMIYB-AgAfXc_hExzMZ-YuzXLgSyVf_8gMCUJNK78N_mCc_kShrxuizQalfJ3Efeh8nn53dsT5HLmi3w%3D%3D&xkcb=SoBD67M3rqd6DVADMD0PbzkdCdPP&fccid=5494ce7371c01502&vjs=3   \n",
              "\n",
              "                           title  \\\n",
              "657  Data Scientist - Product DS   \n",
              "658        Senior Data Scientist   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             job_description  \\\n",
              "657  Best Egg is a market-leading, tech-enabled financial platform helping people build financial confidence through a variety of installment lending solutions and financial health tools. We aim to help customers make smart financial decisions and stay on track, so they can be money confident no matter what life throws at them.\\nWe offer top-tier benefits and growth opportunities in a culture built on our core values:\\n\\nPut People First – We foster an inclusive, flexible, and fun workplace.\\nCreate Clarity – Open communication drives trust and results.\\nGet Things Done – We focus, prioritize, ...   \n",
              "658  Headway's mission is a big one – to build a new mental health care system everyone can access. We've built technology that helps people find great therapists with the first software-enabled national network of providers accepting insurance.\\n1 in 4 people in the US have a treatable mental health condition, but the majority of providers don't accept insurance, making therapy too expensive for most people. Headway is building a new mental healthcare system that everyone can access by making it easy for therapists to accept insurance and scale their practice.\\nHeadway was founded in 2019. Sin...   \n",
              "\n",
              "     Python  Java  C/C++  SQL  R  JavaScript  Machine Learning  ...  \\\n",
              "657       1     0      0    1  0           0                 1  ...   \n",
              "658       1     0      0    1  1           0                 0  ...   \n",
              "\n",
              "     Creativity  Time Management  Attention to Detail  Critical Thinking  \\\n",
              "657           1                0                    0                  0   \n",
              "658           0                0                    0                  0   \n",
              "\n",
              "     Decision Making  Collaboration  Work Ethic  Emotional Intelligence  \\\n",
              "657                0              1           0                       0   \n",
              "658                1              1           0                       0   \n",
              "\n",
              "     Self-Motivation  Flexibility  \n",
              "657                0            1  \n",
              "658                1            1  \n",
              "\n",
              "[2 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1369e45-3e64-44d4-96fb-498e646eadd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_url</th>\n",
              "      <th>title</th>\n",
              "      <th>job_description</th>\n",
              "      <th>Python</th>\n",
              "      <th>Java</th>\n",
              "      <th>C/C++</th>\n",
              "      <th>SQL</th>\n",
              "      <th>R</th>\n",
              "      <th>JavaScript</th>\n",
              "      <th>Machine Learning</th>\n",
              "      <th>...</th>\n",
              "      <th>Creativity</th>\n",
              "      <th>Time Management</th>\n",
              "      <th>Attention to Detail</th>\n",
              "      <th>Critical Thinking</th>\n",
              "      <th>Decision Making</th>\n",
              "      <th>Collaboration</th>\n",
              "      <th>Work Ethic</th>\n",
              "      <th>Emotional Intelligence</th>\n",
              "      <th>Self-Motivation</th>\n",
              "      <th>Flexibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>657</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=73b5c238fe0e6303&amp;bb=zZKk4GPd03d9egsQxsn3kO9skDJOM_mvk2M2EWUn-_F5kxJTC_pWEzoI-OeNbUvp7S6QOxAIcqNGyg4R4ItV8SChU9qpEpUhfEKfuD7yF-rM2ON5nqZOnqwuS2TOQ5rlSEm3xO12bnHiyquDWjHiNw%3D%3D&amp;xkcb=SoD367M3rqeC0CSl1R0BbzkdCdPP&amp;fccid=fcca639559bdd82a&amp;vjs=3</td>\n",
              "      <td>Data Scientist - Product DS</td>\n",
              "      <td>Best Egg is a market-leading, tech-enabled financial platform helping people build financial confidence through a variety of installment lending solutions and financial health tools. We aim to help customers make smart financial decisions and stay on track, so they can be money confident no matter what life throws at them.\\nWe offer top-tier benefits and growth opportunities in a culture built on our core values:\\n\\nPut People First – We foster an inclusive, flexible, and fun workplace.\\nCreate Clarity – Open communication drives trust and results.\\nGet Things Done – We focus, prioritize, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=ea79974ba1e60c2d&amp;bb=KdZ-UDfEWbelc9dxMB_Pgg2lsrBaV1gUTAFPOSdxIfjHI-UZUu52amClVfvIv6trPtjqyjhMIYB-AgAfXc_hExzMZ-YuzXLgSyVf_8gMCUJNK78N_mCc_kShrxuizQalfJ3Efeh8nn53dsT5HLmi3w%3D%3D&amp;xkcb=SoBD67M3rqd6DVADMD0PbzkdCdPP&amp;fccid=5494ce7371c01502&amp;vjs=3</td>\n",
              "      <td>Senior Data Scientist</td>\n",
              "      <td>Headway's mission is a big one – to build a new mental health care system everyone can access. We've built technology that helps people find great therapists with the first software-enabled national network of providers accepting insurance.\\n1 in 4 people in the US have a treatable mental health condition, but the majority of providers don't accept insurance, making therapy too expensive for most people. Headway is building a new mental healthcare system that everyone can access by making it easy for therapists to accept insurance and scale their practice.\\nHeadway was founded in 2019. Sin...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1369e45-3e64-44d4-96fb-498e646eadd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1369e45-3e64-44d4-96fb-498e646eadd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1369e45-3e64-44d4-96fb-498e646eadd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wa6xuSe_9Vj5"
      },
      "outputs": [],
      "source": [
        "label_counts = df[skills].sum().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "621SNPLt90iu",
        "outputId": "8332b695-2856-48eb-9916-65afb4a943cd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Collaboration                      15167\n",
              "Communication                      14959\n",
              "Creativity                         10503\n",
              "Problem Solving                    10227\n",
              "Automation                          8815\n",
              "Leadership                          8718\n",
              "Cybersecurity                       8711\n",
              "Software Testing                    8631\n",
              "Software Engineering Principles     8379\n",
              "Python                              8153\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Collaboration</th>\n",
              "      <td>15167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Communication</th>\n",
              "      <td>14959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Creativity</th>\n",
              "      <td>10503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Problem Solving</th>\n",
              "      <td>10227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Automation</th>\n",
              "      <td>8815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Leadership</th>\n",
              "      <td>8718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cybersecurity</th>\n",
              "      <td>8711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Software Testing</th>\n",
              "      <td>8631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Software Engineering Principles</th>\n",
              "      <td>8379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Python</th>\n",
              "      <td>8153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "label_counts.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts.tail(10)"
      ],
      "metadata": {
        "id": "QljkBAxPfrkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a9828049-8786-47bb-cd91-87c2b04558a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "iOS Development                 749\n",
              "Systems Administration          727\n",
              "Android Development             685\n",
              "Data Cleaning & Wrangling       578\n",
              "Emotional Intelligence          563\n",
              "Site Reliability Engineering    529\n",
              "Django                          317\n",
              "EDA                             216\n",
              "A/B Testing                     216\n",
              "Flask                           176\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>iOS Development</th>\n",
              "      <td>749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Systems Administration</th>\n",
              "      <td>727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Android Development</th>\n",
              "      <td>685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data Cleaning &amp; Wrangling</th>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotional Intelligence</th>\n",
              "      <td>563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Site Reliability Engineering</th>\n",
              "      <td>529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Django</th>\n",
              "      <td>317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EDA</th>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A/B Testing</th>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flask</th>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUSvawdFO2ds",
        "outputId": "29e2c19d-777e-4179-ab4b-ae1abd059cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "skill_id = {skill: i for i, skill in enumerate(skills)}\n",
        "\n",
        "with open(\"skill_mapping.json\", \"w\") as f:\n",
        "    json.dump(skill_id, f)\n",
        "\n",
        "print(list(skill_id.keys()) == skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ-fZNAbBXl7",
        "outputId": "2c76c289-6808-4dd8-9693-e8de7da1a88e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 1],\n",
              "       [1, 0, 0, ..., 0, 1, 1],\n",
              "       [1, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df[skills].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4EmOVdAUC_7"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('skill_mapping.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4AeUh2DC_Qx"
      },
      "source": [
        "# **Dataloaders and Modeling (DistilRoberta-Base)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw17_mOnBbTD"
      },
      "outputs": [],
      "source": [
        "labels = skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqJz1lDtCkyO"
      },
      "outputs": [],
      "source": [
        "model_name = \"distilroberta-base\"\n",
        "model_cls = AutoModelForSequenceClassification\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config.num_labels = len(labels)\n",
        "\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, config=config)\n",
        "hf_model.config.problem_type = \"multi_label_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUACStpwKkHb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dblocks = (\n",
        "    TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model),\n",
        "    MultiCategoryBlock(vocab=labels)\n",
        ")\n",
        "\n",
        "def get_y_skills(row):\n",
        "    return [skill for skill in labels if row[skill] == 1]\n",
        "\n",
        "dblock = DataBlock(blocks=dblocks, get_x=ColReader('job_description'), get_y=get_y_skills, splitter=RandomSplitter(valid_pct=0.2, seed=42))\n",
        "dls = dblock.dataloaders(df, bs=32)\n",
        "\n",
        "output_dir = os.path.join(data_path,\"dataloaders\")\n",
        "torch.save(dls, os.path.join(output_dir, \"dls-multilabel-skill-classifier.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGoIBMhfY0dR"
      },
      "outputs": [],
      "source": [
        "def get_y_skills(row):\n",
        "    return [skill for skill in labels if row[skill] == 1]\n",
        "dls = torch.load(\"/content/drive/MyDrive/Data Science/CP3_Skill Classifier/dataloaders/dls-multilabel-skill-classifier.pkl\", weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcj2JEbZGbt1"
      },
      "outputs": [],
      "source": [
        "dls.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQdqu22oGc1m"
      },
      "outputs": [],
      "source": [
        "model = BaseModelWrapper(hf_model)\n",
        "acc_061 = partial(accuracy_multi, thresh=0.61)\n",
        "\n",
        "learner = Learner(dls,\n",
        "                  model,\n",
        "                  opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),\n",
        "                  loss_func=BCEWithLogitsLossFlat(),\n",
        "                  metrics=[acc_061],\n",
        "                  cbs=[BaseModelCallback],\n",
        "                  splitter=blurr_splitter\n",
        "                  ).to_fp16()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LoAa_nkSkqZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ag6H5soJn4a"
      },
      "source": [
        "## **Stage-0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QMlWU7hJlSS"
      },
      "outputs": [],
      "source": [
        "learner.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfpzDaDJJtuy"
      },
      "outputs": [],
      "source": [
        "learner.lr_find(suggest_funcs=[slide,valley])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st465rDVJzoy"
      },
      "outputs": [],
      "source": [
        "learner.fit_one_cycle(3,2e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luCxZfVaLvI8"
      },
      "outputs": [],
      "source": [
        "learner.save(\"skill-classifier-stage-0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkyIWmwyL2qm"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-stage-0.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "maun_kfSktn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98H98wfUMthO"
      },
      "source": [
        "## **Stage-1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTqP-iR7NSkB"
      },
      "outputs": [],
      "source": [
        "from fastai.learner import load_learner\n",
        "learner = load_learner(\"/content/drive/My Drive/Data Science/CP3/models/skill-classifier-stage-0.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffkU9JzBNWIK"
      },
      "outputs": [],
      "source": [
        "learner.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37dhaRZbcxm2"
      },
      "outputs": [],
      "source": [
        "print(f\"Train dataloader length: {len(learner.dls.train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCiDvYhfNfZV"
      },
      "outputs": [],
      "source": [
        "learner.lr_find(suggest_funcs=[slide, valley])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inkkb8MwPmRS"
      },
      "outputs": [],
      "source": [
        "learner.fit_one_cycle(5, lr_max=slice(3.5e-6, 3e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6MegfLBhI0q"
      },
      "outputs": [],
      "source": [
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "preds_binary = (preds_probs > 0.61).numpy()\n",
        "targs_binary = targs.numpy()\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f\"Accuracy:   0.9700\")\n",
        "print(f\"F1-Samples: {f1_score(targs_binary, preds_binary, average='samples'):.4f}\")\n",
        "print(f\"F1-Macro:   {f1_score(targs_binary, preds_binary, average='macro'):.4f}\")\n",
        "print(f\"F1-Micro:   {f1_score(targs_binary, preds_binary, average='micro'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZuabpBdTIK6"
      },
      "outputs": [],
      "source": [
        "learner.save(\"skill-classifier-stage-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfcRkuKsjVSV"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-stage-1.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloaders and Modeling (ModernBERT-base)**"
      ],
      "metadata": {
        "id": "GRknlye1rswl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kzOAGc9GTFF"
      },
      "outputs": [],
      "source": [
        "labels = skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "1093f2852c7f4ceeb8f3e7a8a70fc7ed",
            "c0fb21f8b9db410383e8efa43c980f6c",
            "f96847ae66bb4022bfc331f859e977bf",
            "3ed61402134b4f5bb4d6483dc57dc42b",
            "82fec06996f64b9586bdbb60952c08fe",
            "adbe57a14a8a4ecdb670818151ce611e",
            "7479fb54cb9e4391ad07099597dac190",
            "5997f136e3444431b7a15c99f68c72b0",
            "2a1159a5213d448991c5cc1c64388e9c",
            "a58b0ff9bdf14eb28d43e024c3aa9b5d",
            "f37dc31a8871418b983c4f8534fda668",
            "1da4488eece846b887235bac0fa9f68c",
            "9066927a63ca4400b574e9ddd5b4fdb4",
            "91ecbe9f23b1432b86e3dfab9b12993d",
            "bf8c6d994dba456e8cb89c626beb34d3",
            "760a601fadfc404c8fb516500283476d",
            "5d090aa99c9b47448a2ae8803574db06",
            "d5a003c4ce2642e2bbcfb346b4522d77",
            "23538f544e6244e797aa50f930d0737a",
            "1c29300d7e3f43fbada91584e7421646",
            "85fe1c7665404621831839bf84bc8df3",
            "f981664e1701492693019575de3150f8",
            "db8b3538453541ff8cae3b1d1f1af71c",
            "c078a3c6f10b41e29c862ca6176351e2",
            "ce9a0fb69adf4af680f68b23a41ed923",
            "157e8020a1964e40a60a2885f9ec937d",
            "d5ddd821f58341f1b4611c24a75b5c09",
            "99df24864b2f40b8a076f3e65fdd06c0",
            "4cd863e3c641457ebc1f86abda743cfa",
            "b5ccb965122142c9b28da36d69970068",
            "711cb1bcf7af42bf99b586e893b9238f",
            "9528e76188d34ceaa385345c26d9e447",
            "5c324ed35a404e868f603923130819db",
            "f743e24f91c24470bfece71c0fe9d981",
            "c91f87e0fc1d4aa8b745f3e447b222f7",
            "c1af3917b40e49a48cc4b68787be6027",
            "1ece1341f2f749ada326f23b54b48471",
            "9f571431d9a647eab3aec4f467a52806",
            "0792986b22ee4e48b6177349e156c015",
            "236055f31c874871b704d70c3d5d3c60",
            "d7f11b856dac4750889965e8ec9c06ee",
            "ea1eaa6a34c2499d8f7fbc45063a32c1",
            "1d641e08677246b68cec36d0cbea299d",
            "fed47c1a3efd4eb980f2fe07a73bb43c",
            "e8e2718948294d119ad0542d65714652",
            "56d9c17d614846d5a1d7b692632a1342",
            "3997b3ca318342ff8be3c94d1c7e0ffe",
            "ca131ca9c0dd4e2099cdf88470bd709b",
            "c582ded0f4a049dda09cdc328cefa1cf",
            "3ebb167761534b429cf192c6408ef791",
            "02fc7e21334b452a94352afe20cde81f",
            "f79b175c0bfb4904a3ee416330b9893c",
            "80a2fb91b5284a51882bdd37c7b026a1",
            "4690a23f03214068ad5ba98847e97132",
            "7c779f18f009428cb162f34ae6c6995f"
          ]
        },
        "id": "g9lS0_4FGUuG",
        "outputId": "4a70d37d-81cc-4d27-b24b-66532a30b623"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1093f2852c7f4ceeb8f3e7a8a70fc7ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1da4488eece846b887235bac0fa9f68c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db8b3538453541ff8cae3b1d1f1af71c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f743e24f91c24470bfece71c0fe9d981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8e2718948294d119ad0542d65714652"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"answerdotai/ModernBERT-base\"\n",
        "model_cls = AutoModelForSequenceClassification\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config.num_labels = len(labels)\n",
        "config.gradient_checkpointing = True\n",
        "\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, config=config)\n",
        "hf_model.config.problem_type = \"multi_label_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIGXpmekT7iG"
      },
      "outputs": [],
      "source": [
        "dblocks = (\n",
        "    TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model),\n",
        "    MultiCategoryBlock(vocab=labels)\n",
        ")\n",
        "\n",
        "def get_y_skills(row):\n",
        "    return [skill for skill in labels if row[skill] == 1]\n",
        "\n",
        "dblock = DataBlock(blocks=dblocks, get_x=ColReader('job_description'), get_y=get_y_skills, splitter=RandomSplitter(valid_pct=0.2, seed=42))\n",
        "dls = dblock.dataloaders(df, bs=8)\n",
        "\n",
        "# output_dir = os.path.join(data_path,\"dataloaders\")\n",
        "# torch.save(dls, os.path.join(output_dir, \"dls-electra.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7C0qp4IT-Tk"
      },
      "outputs": [],
      "source": [
        "model = BaseModelWrapper(hf_model)\n",
        "acc = partial(accuracy_multi, thresh=0.6)\n",
        "\n",
        "learner = Learner(dls,\n",
        "                  model,\n",
        "                  opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),\n",
        "                  loss_func=BCEWithLogitsLossFlat(),\n",
        "                  metrics=[acc],\n",
        "                  cbs=[BaseModelCallback],\n",
        "                  splitter=blurr_splitter\n",
        "                  ).to_fp16()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stage - 0**"
      ],
      "metadata": {
        "id": "-ToHXjGpl2mO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l6p2hwHUgGD"
      },
      "outputs": [],
      "source": [
        "learner.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "collapsed": true,
        "id": "jpCeXKN4U34s",
        "outputId": "6304bfa1-f6ec-47db-a11f-7cb4599c6cd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(slide=0.009120108559727669, valley=0.0004786300996784121)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_find(suggest_funcs=[slide,valley])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_one_cycle(1,5e-4)"
      ],
      "metadata": {
        "id": "zkPOtaKpgm6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "89c1961d-f554-4370-c880-3dfcd663771e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_multi</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.076706</td>\n",
              "      <td>0.073638</td>\n",
              "      <td>0.974475</td>\n",
              "      <td>30:44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RutpYqmQ09Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317f804f-c92a-4b98-f5a8-4ee0fbd4a778"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/skill-classifier-modernbert-stage-0.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "learner.save(\"skill-classifier-modernbert-stage-0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ-KgKpW1E15"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-modernbertstage-0.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stage-1**"
      ],
      "metadata": {
        "id": "As16GyLlrz7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.learner import load_learner\n",
        "learner = load_learner(os.path.join(data_path,\"models\",\"skill-classifier-modernbertstage-0.pkl\"))"
      ],
      "metadata": {
        "id": "gKaECv7wrzn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYIW6-FfSuPM"
      },
      "outputs": [],
      "source": [
        "learner.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOOeKEfV1USi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "6f2285af-799b-4259-d8fb-d5b520927a86"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(slide=0.002511886414140463, valley=1.2022644114040304e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_find(suggest_funcs=[slide, valley])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC0X6bli1Wvl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "667a4478-90f0-4358-b410-6c6ad41bf52b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_multi</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.034036</td>\n",
              "      <td>0.039747</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>34:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.012631</td>\n",
              "      <td>0.016105</td>\n",
              "      <td>0.995457</td>\n",
              "      <td>34:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.005342</td>\n",
              "      <td>0.005245</td>\n",
              "      <td>0.998730</td>\n",
              "      <td>34:23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000847</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>0.999618</td>\n",
              "      <td>34:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.999676</td>\n",
              "      <td>34:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.fit_one_cycle(5, lr_max=slice(1.2e-5, 2.5e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18BDoSnX0tCn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "f7ebbcea-8ea5-472c-c302-6c00dfd72e35"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINDING OPTIMAL THRESHOLD\n",
            "======================================================================\n",
            "Thresh 0.30: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.31: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.32: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.33: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.34: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.35: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.36: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.37: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.38: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.39: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.40: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.41: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.42: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.43: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.44: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.45: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.46: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.47: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.48: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.49: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.50: Avg preds=41.05, F1-Samples=0.4477, F1-Macro=0.4110, F1-Micro=0.4598\n",
            "Thresh 0.51: Avg preds=12.27, F1-Samples=0.9920, F1-Macro=0.9950, F1-Micro=0.9982\n",
            "Thresh 0.52: Avg preds=12.26, F1-Samples=0.9926, F1-Macro=0.9962, F1-Micro=0.9987\n",
            "Thresh 0.53: Avg preds=12.26, F1-Samples=0.9927, F1-Macro=0.9964, F1-Micro=0.9988\n",
            "Thresh 0.54: Avg preds=12.25, F1-Samples=0.9927, F1-Macro=0.9968, F1-Micro=0.9989\n",
            "Thresh 0.55: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9969, F1-Micro=0.9989\n",
            "Thresh 0.56: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9969, F1-Micro=0.9989\n",
            "Thresh 0.57: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9968, F1-Micro=0.9989\n",
            "Thresh 0.58: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9968, F1-Micro=0.9989\n",
            "Thresh 0.59: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9969, F1-Micro=0.9990\n",
            "Thresh 0.60: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9967, F1-Micro=0.9989\n",
            "Thresh 0.61: Avg preds=12.25, F1-Samples=0.9928, F1-Macro=0.9966, F1-Micro=0.9989\n",
            "Thresh 0.62: Avg preds=12.24, F1-Samples=0.9928, F1-Macro=0.9965, F1-Micro=0.9989\n",
            "Thresh 0.63: Avg preds=12.24, F1-Samples=0.9928, F1-Macro=0.9966, F1-Micro=0.9989\n",
            "Thresh 0.64: Avg preds=12.24, F1-Samples=0.9928, F1-Macro=0.9966, F1-Micro=0.9989\n",
            "Thresh 0.65: Avg preds=12.24, F1-Samples=0.9928, F1-Macro=0.9966, F1-Micro=0.9989\n",
            "Thresh 0.66: Avg preds=12.24, F1-Samples=0.9928, F1-Macro=0.9967, F1-Micro=0.9989\n",
            "Thresh 0.67: Avg preds=12.24, F1-Samples=0.9927, F1-Macro=0.9966, F1-Micro=0.9989\n",
            "Thresh 0.68: Avg preds=12.24, F1-Samples=0.9927, F1-Macro=0.9966, F1-Micro=0.9989\n",
            "Thresh 0.69: Avg preds=12.24, F1-Samples=0.9927, F1-Macro=0.9965, F1-Micro=0.9988\n",
            "Thresh 0.70: Avg preds=12.23, F1-Samples=0.9926, F1-Macro=0.9963, F1-Micro=0.9988\n",
            "Thresh 0.71: Avg preds=12.23, F1-Samples=0.9926, F1-Macro=0.9961, F1-Micro=0.9987\n",
            "Thresh 0.72: Avg preds=12.22, F1-Samples=0.9922, F1-Macro=0.9952, F1-Micro=0.9984\n",
            "Thresh 0.73: Avg preds=12.17, F1-Samples=0.9900, F1-Macro=0.9904, F1-Micro=0.9965\n",
            "\n",
            "======================================================================\n",
            "✓ OPTIMAL THRESHOLD: 0.59\n",
            "✓ Best F1-Samples: 0.9928\n",
            "✓ Avg predictions: 12.25\n",
            "✓ Avg true labels: 12.25\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Threshold finder\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "targs_np = targs.numpy()\n",
        "\n",
        "print(\"FINDING OPTIMAL THRESHOLD\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "best_metrics = {}\n",
        "\n",
        "\n",
        "for thresh in np.arange(0.30, 0.80, 0.01):\n",
        "    preds_binary = (preds_probs > thresh).numpy()\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_preds = preds_binary.sum(axis=1).mean()\n",
        "    f1_samples = f1_score(targs_np, preds_binary, average='samples', zero_division=0)\n",
        "    f1_macro = f1_score(targs_np, preds_binary, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(targs_np, preds_binary, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "    if avg_preds > 0.1:\n",
        "        print(f\"Thresh {thresh:.2f}: Avg preds={avg_preds:5.2f}, \"\n",
        "              f\"F1-Samples={f1_samples:.4f}, F1-Macro={f1_macro:.4f}, F1-Micro={f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "        if f1_samples > best_f1:\n",
        "            best_f1 = f1_samples\n",
        "            best_thresh = thresh\n",
        "            best_metrics = {\n",
        "                'f1_samples': f1_samples,\n",
        "                'f1_macro': f1_macro,\n",
        "                'f1_micro': f1_micro,\n",
        "                'avg_preds': avg_preds\n",
        "            }\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✓ OPTIMAL THRESHOLD: {best_thresh:.2f}\")\n",
        "print(f\"✓ Best F1-Samples: {best_f1:.4f}\")\n",
        "print(f\"✓ Avg predictions: {best_metrics['avg_preds']:.2f}\")\n",
        "print(f\"✓ Avg true labels: {targs_np.sum(axis=1).mean():.2f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUHgUUtT1QwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "e0c0789f-6439-4354-fca6-f5e34200acc3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:   0.9996\n",
            "F1-Samples: 0.9928\n",
            "F1-Macro:   0.9969\n",
            "F1-Micro:   0.9990\n"
          ]
        }
      ],
      "source": [
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "preds_binary = (preds_probs > 0.59).numpy()\n",
        "targs_binary = targs.numpy()\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f\"Accuracy:   0.9996\")\n",
        "print(f\"F1-Samples: {f1_score(targs_binary, preds_binary, average='samples'):.4f}\")\n",
        "print(f\"F1-Macro:   {f1_score(targs_binary, preds_binary, average='macro'):.4f}\")\n",
        "print(f\"F1-Micro:   {f1_score(targs_binary, preds_binary, average='micro'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6281512c-0f94-4a70-cfa9-47f412fd0953",
        "id": "G-o9ybes2Aam"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/skill-classifier-modernbert-stage-1.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "learner.save(\"skill-classifier-modernbert-stage-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PR6CfYN2Aan"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-modernbertstage-1.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bjduM046i25G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloaders and Modeling (sentence-transformers/all-MiniLM-L6-v2)**"
      ],
      "metadata": {
        "id": "1i_G5vVuk377"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNGoqoAulJWu"
      },
      "outputs": [],
      "source": [
        "labels = skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "eaeb52f1bcc64e18a709c1c04fb5d023",
            "f88dca7cd7014cba905f860c17ad67a0",
            "31fbe29a0e3844cf881f7e6a140ab77e",
            "f374daed1ed34703bd04a599e2a9f4c9",
            "2ab896710dd9424ebace4859ebfe2043",
            "89d4b01941884bf38d01113d8f62f4b9",
            "4abf8f29a8994b369578dee85f07a1d7",
            "eb04de70c4514131ba24c476d7e79ed7",
            "ecad1cc52dbf44d090a6bc4c61a573fb",
            "555b167348ba41dfb162e3ea6efccbcd",
            "f7d43930a06b44728710cf2bc53787b4",
            "2be75241914946c496a90d9fc9f5eb74",
            "9592de9322e6471da8d51ce190a94241",
            "7b11cb4a28d94ae8ad681372d8cd0f6f",
            "91b4c9d5ad4c4064a9e82300ec2a9ae9",
            "9053c83c592c407bb9a11f4b82e7a0ab",
            "dfc07d71aeef460ea93286ab67d16c4e",
            "d528cb2a24c84ff6905a46c228571ebd",
            "2aa3969e53af43fe87b0f9c87d46da74",
            "bd91526b4ece4dbe97b488c55bb4613c",
            "b4a1afe467f24f919c026555f8a1339e",
            "c89918c5897a40dea9c937b94f8b58c6",
            "79e76a01665d42f797094ea41b7d46aa",
            "451953dda2764169a8555835827f3211",
            "57c2d7cdd95a42b885632da8a4030d74",
            "57583e2caca14e169b36e5e95aeb95e9",
            "79032bc77845484f95ac82ed04721ed7",
            "595ea48734e7494b9b6ac1707b0f64d1",
            "b9ddf86d246d497d9082c5ff2756ed7e",
            "5e2d043382bf40208d143676638bbe13",
            "2525a13bc93e460d9be805f469de7738",
            "53e9cfdbdad54a849b7ce502760cf3d5",
            "8d62265657eb439294f9dd2415ec4eba",
            "56fb63b1871a4f3fbce45fb70722ae7b",
            "bd38ed700b3543a998c251941f2e36d0",
            "cf3efa4124fd4863b8b5b744e3cc5c21",
            "7be81b52b60f4bafade38de8d47766a2",
            "21bd174fef16474e97e942a2650e99ff",
            "bce21f9b3d774d238d497bd360b50fb7",
            "95104bd3efbb48fdb5d0d44544f0f4be",
            "92b92dcaa2c8456eadcc2d5eee69c10a",
            "bf02c2b81f4a493f8134c059f9531865",
            "9e77e043b03d4830a94bf3521f4123c8",
            "44ed91ab5f6a439fb06fd6b5f186a160",
            "2671b283a07e46a4b7926cbe15e42063",
            "37bc78236ef14e5f9ddbf42a3fd23558",
            "57c484fbbc684f53a38d41d547be66ca",
            "833d38cf37c3416f8717b2a0fb64b054",
            "de185bccd2404b9599476aabf71fe4a9",
            "cc98338d55cb4366996c5a91fb689669",
            "1340acbcb7ac4598983139d083e0b87d",
            "c8bc0ceb0df549e3bf58432041b94ff1",
            "63902b8f17764dc2bdbd8ada24bf3878",
            "4e953aeabc3c4db59c5ae5f1eb411a53",
            "eb0f3794e8e84122af88062e3454a525",
            "4e1bc1a257a2452287f04deba768a0e9",
            "039599d09fc2467a9c0b287bcf5014f7",
            "7852e57b4d444560b6c08d130753a834",
            "a0b186dff75e4d51aeaaf8d8e82c1e8b",
            "e43179d65b894a99a912729b862b85e6",
            "1d7dee7795294f51b4795a4e2be6de01",
            "57aa8797bbec402490094f24d3067d69",
            "983d6c1637b4477aa71553e5e68d3f0b",
            "b554452c309c49598781c7928f8c9773",
            "b70f6d4deb794a14a123f54a624b5812",
            "773e659627ce4410bc2bad7cdb7d19bb"
          ]
        },
        "outputId": "1b567acc-2a1a-4595-c86d-026cc03536ba",
        "id": "hYJtOCj2lJWu"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eaeb52f1bcc64e18a709c1c04fb5d023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2be75241914946c496a90d9fc9f5eb74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79e76a01665d42f797094ea41b7d46aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56fb63b1871a4f3fbce45fb70722ae7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2671b283a07e46a4b7926cbe15e42063"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e1bc1a257a2452287f04deba768a0e9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "model_cls = AutoModelForSequenceClassification\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config.num_labels = len(labels)\n",
        "config.gradient_checkpointing = True\n",
        "\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, config=config)\n",
        "hf_model.config.problem_type = \"multi_label_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UQUipJUlJWu"
      },
      "outputs": [],
      "source": [
        "dblocks = (\n",
        "    TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model),\n",
        "    MultiCategoryBlock(vocab=labels)\n",
        ")\n",
        "\n",
        "def get_y_skills(row):\n",
        "    return [skill for skill in labels if row[skill] == 1]\n",
        "\n",
        "dblock = DataBlock(blocks=dblocks, get_x=ColReader('job_description'), get_y=get_y_skills, splitter=RandomSplitter(valid_pct=0.2, seed=42))\n",
        "dls = dblock.dataloaders(df, bs=8)\n",
        "\n",
        "# output_dir = os.path.join(data_path,\"dataloaders\")\n",
        "# torch.save(dls, os.path.join(output_dir, \"dls-electra.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6r69nydlJWv"
      },
      "outputs": [],
      "source": [
        "model = BaseModelWrapper(hf_model)\n",
        "acc = partial(accuracy_multi, thresh=0.6)\n",
        "\n",
        "learner = Learner(dls,\n",
        "                  model,\n",
        "                  opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),\n",
        "                  loss_func=BCEWithLogitsLossFlat(),\n",
        "                  metrics=[acc],\n",
        "                  cbs=[BaseModelCallback],\n",
        "                  splitter=blurr_splitter\n",
        "                  ).to_fp16()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioS3nrtCUcHE"
      },
      "source": [
        "## **Stage - 0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbwJ2KJblJWv"
      },
      "outputs": [],
      "source": [
        "learner.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "collapsed": true,
        "outputId": "55ecbe17-01e2-4550-a051-b96e0b2e8e99",
        "id": "hct8MoHplJWv"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(slide=0.013182567432522774, valley=0.0008317637839354575)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_find(suggest_funcs=[slide,valley])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yF5dv8pknarc",
        "outputId": "1dea6f69-176f-4df0-e757-fda085136ded"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_multi</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.269378</td>\n",
              "      <td>0.263671</td>\n",
              "      <td>0.886595</td>\n",
              "      <td>02:50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.fit_one_cycle(1,8.3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI18Ui7nlJWv",
        "outputId": "8226644d-af54-4a17-e05c-27c234d067dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/skill-classifier-minilm-stage-0.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "learner.save(\"skill-classifier-minilm-stage-0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm7lISZ_lJWw"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-minilmstage-0.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PhVczAM1Fox"
      },
      "source": [
        "## **Stage-1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5KlBNAP1IDC"
      },
      "outputs": [],
      "source": [
        "# from fastai.learner import load_learner\n",
        "# learner = load_learner(os.path.join(data_path,\"models\",\"skill-classifier-modernbertstage-0.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeEkC6d4lJWw"
      },
      "outputs": [],
      "source": [
        "learner.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "XsE7hmZmlJWw",
        "outputId": "c451a239-9e35-412b-d610-bf3986958361"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(slide=0.009120108559727669, valley=4.786300905834651e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_find(suggest_funcs=[slide, valley])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pu0dDd6MlJWw",
        "outputId": "c274953b-8627-4d25-9408-55e8d76e026c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_multi</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.225290</td>\n",
              "      <td>0.198251</td>\n",
              "      <td>0.924297</td>\n",
              "      <td>03:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.164436</td>\n",
              "      <td>0.137219</td>\n",
              "      <td>0.951736</td>\n",
              "      <td>03:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.120593</td>\n",
              "      <td>0.099156</td>\n",
              "      <td>0.966017</td>\n",
              "      <td>03:58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.078428</td>\n",
              "      <td>0.081507</td>\n",
              "      <td>0.973034</td>\n",
              "      <td>04:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.081722</td>\n",
              "      <td>0.077108</td>\n",
              "      <td>0.974807</td>\n",
              "      <td>03:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.fit_one_cycle(5, lr_max=slice(5e-6, 9e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "wOdBgT7QlJWx",
        "outputId": "9c5fda48-b271-4cf8-cb84-af1a32116924"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINDING OPTIMAL THRESHOLD\n",
            "======================================================================\n",
            "Thresh 0.30: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.31: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.32: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.33: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.34: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.35: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.36: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.37: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.38: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.39: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.40: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.41: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.42: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.43: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.44: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.45: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.46: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.47: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.48: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.49: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.50: Avg preds=80.63, F1-Samples=0.2551, F1-Macro=0.2390, F1-Micro=0.2639\n",
            "Thresh 0.51: Avg preds=20.26, F1-Samples=0.7606, F1-Macro=0.6819, F1-Micro=0.7316\n",
            "Thresh 0.52: Avg preds=17.23, F1-Samples=0.8151, F1-Macro=0.7557, F1-Micro=0.7959\n",
            "Thresh 0.53: Avg preds=15.68, F1-Samples=0.8443, F1-Macro=0.7957, F1-Micro=0.8317\n",
            "Thresh 0.54: Avg preds=14.66, F1-Samples=0.8624, F1-Macro=0.8240, F1-Micro=0.8547\n",
            "Thresh 0.55: Avg preds=13.95, F1-Samples=0.8745, F1-Macro=0.8413, F1-Micro=0.8702\n",
            "Thresh 0.56: Avg preds=13.40, F1-Samples=0.8837, F1-Macro=0.8539, F1-Micro=0.8821\n",
            "Thresh 0.57: Avg preds=12.97, F1-Samples=0.8903, F1-Macro=0.8629, F1-Micro=0.8905\n",
            "Thresh 0.58: Avg preds=12.62, F1-Samples=0.8951, F1-Macro=0.8681, F1-Micro=0.8969\n",
            "Thresh 0.59: Avg preds=12.32, F1-Samples=0.8985, F1-Macro=0.8722, F1-Micro=0.9017\n",
            "Thresh 0.60: Avg preds=12.06, F1-Samples=0.9011, F1-Macro=0.8753, F1-Micro=0.9054\n",
            "Thresh 0.61: Avg preds=11.83, F1-Samples=0.9028, F1-Macro=0.8782, F1-Micro=0.9081\n",
            "Thresh 0.62: Avg preds=11.62, F1-Samples=0.9036, F1-Macro=0.8793, F1-Micro=0.9098\n",
            "Thresh 0.63: Avg preds=11.43, F1-Samples=0.9042, F1-Macro=0.8803, F1-Micro=0.9110\n",
            "Thresh 0.64: Avg preds=11.25, F1-Samples=0.9033, F1-Macro=0.8782, F1-Micro=0.9107\n",
            "Thresh 0.65: Avg preds=11.09, F1-Samples=0.9027, F1-Macro=0.8773, F1-Micro=0.9106\n",
            "Thresh 0.66: Avg preds=10.92, F1-Samples=0.9012, F1-Macro=0.8754, F1-Micro=0.9095\n",
            "Thresh 0.67: Avg preds=10.76, F1-Samples=0.8987, F1-Macro=0.8709, F1-Micro=0.9074\n",
            "Thresh 0.68: Avg preds=10.60, F1-Samples=0.8967, F1-Macro=0.8677, F1-Micro=0.9055\n",
            "Thresh 0.69: Avg preds=10.43, F1-Samples=0.8927, F1-Macro=0.8624, F1-Micro=0.9024\n",
            "Thresh 0.70: Avg preds=10.22, F1-Samples=0.8877, F1-Macro=0.8555, F1-Micro=0.8973\n",
            "Thresh 0.71: Avg preds=10.00, F1-Samples=0.8807, F1-Macro=0.8450, F1-Micro=0.8901\n",
            "Thresh 0.72: Avg preds= 9.63, F1-Samples=0.8664, F1-Macro=0.8236, F1-Micro=0.8760\n",
            "Thresh 0.73: Avg preds= 7.86, F1-Samples=0.7719, F1-Macro=0.7038, F1-Micro=0.7810\n",
            "\n",
            "======================================================================\n",
            "✓ OPTIMAL THRESHOLD: 0.63\n",
            "✓ Best F1-Samples: 0.9042\n",
            "✓ Avg predictions: 11.43\n",
            "✓ Avg true labels: 12.25\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "targs_np = targs.numpy()\n",
        "\n",
        "print(\"FINDING OPTIMAL THRESHOLD\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "best_metrics = {}\n",
        "\n",
        "\n",
        "for thresh in np.arange(0.30, 0.80, 0.01):\n",
        "    preds_binary = (preds_probs > thresh).numpy()\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_preds = preds_binary.sum(axis=1).mean()\n",
        "    f1_samples = f1_score(targs_np, preds_binary, average='samples', zero_division=0)\n",
        "    f1_macro = f1_score(targs_np, preds_binary, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(targs_np, preds_binary, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "    if avg_preds > 0.1:\n",
        "        print(f\"Thresh {thresh:.2f}: Avg preds={avg_preds:5.2f}, \"\n",
        "              f\"F1-Samples={f1_samples:.4f}, F1-Macro={f1_macro:.4f}, F1-Micro={f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "        if f1_samples > best_f1:\n",
        "            best_f1 = f1_samples\n",
        "            best_thresh = thresh\n",
        "            best_metrics = {\n",
        "                'f1_samples': f1_samples,\n",
        "                'f1_macro': f1_macro,\n",
        "                'f1_micro': f1_micro,\n",
        "                'avg_preds': avg_preds\n",
        "            }\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✓ OPTIMAL THRESHOLD: {best_thresh:.2f}\")\n",
        "print(f\"✓ Best F1-Samples: {best_f1:.4f}\")\n",
        "print(f\"✓ Avg predictions: {best_metrics['avg_preds']:.2f}\")\n",
        "print(f\"✓ Avg true labels: {targs_np.sum(axis=1).mean():.2f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "1ieaZnFKlJWx",
        "outputId": "c2d68551-9ec5-46ab-8aac-8a86174129df"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:   0.9700\n",
            "F1-Samples: 0.9028\n",
            "F1-Macro:   0.8782\n",
            "F1-Micro:   0.9081\n"
          ]
        }
      ],
      "source": [
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "preds_binary = (preds_probs > 0.61).numpy()\n",
        "targs_binary = targs.numpy()\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f\"Accuracy:   0.9700\")\n",
        "print(f\"F1-Samples: {f1_score(targs_binary, preds_binary, average='samples'):.4f}\")\n",
        "print(f\"F1-Macro:   {f1_score(targs_binary, preds_binary, average='macro'):.4f}\")\n",
        "print(f\"F1-Micro:   {f1_score(targs_binary, preds_binary, average='micro'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6281512c-0f94-4a70-cfa9-47f412fd0953",
        "id": "Ur6nyNZ9ll2O"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/skill-classifier-modernbert-stage-1.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "learner.save(\"skill-classifier-modernbert-stage-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN1Ura9Qll2P"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-modernbertstage-1.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataloaders and Modeling (google-bert/bert-base-uncased)**"
      ],
      "metadata": {
        "id": "nk-c5vnPsSHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqMw9tIosSHQ"
      },
      "outputs": [],
      "source": [
        "labels = skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VROwRBfsSHR"
      },
      "outputs": [],
      "source": [
        "model_name = \"google-bert/bert-base-uncased\"\n",
        "model_cls = AutoModelForSequenceClassification\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "config.num_labels = len(labels)\n",
        "config.gradient_checkpointing = True\n",
        "\n",
        "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, config=config)\n",
        "hf_model.config.problem_type = \"multi_label_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHecTqSwsSHR"
      },
      "outputs": [],
      "source": [
        "dblocks = (\n",
        "    TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model),\n",
        "    MultiCategoryBlock(vocab=labels)\n",
        ")\n",
        "\n",
        "def get_y_skills(row):\n",
        "    return [skill for skill in labels if row[skill] == 1]\n",
        "\n",
        "dblock = DataBlock(blocks=dblocks, get_x=ColReader('job_description'), get_y=get_y_skills, splitter=RandomSplitter(valid_pct=0.2, seed=42))\n",
        "dls = dblock.dataloaders(df, bs=8)\n",
        "\n",
        "# output_dir = os.path.join(data_path,\"dataloaders\")\n",
        "# torch.save(dls, os.path.join(output_dir, \"dls-electra.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wap9VhH2sSHR"
      },
      "outputs": [],
      "source": [
        "model = BaseModelWrapper(hf_model)\n",
        "acc = partial(accuracy_multi, thresh=0.6)\n",
        "\n",
        "learner = Learner(dls,\n",
        "                  model,\n",
        "                  opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),\n",
        "                  loss_func=BCEWithLogitsLossFlat(),\n",
        "                  metrics=[acc],\n",
        "                  cbs=[BaseModelCallback],\n",
        "                  splitter=blurr_splitter\n",
        "                  ).to_fp16()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stage - 0**"
      ],
      "metadata": {
        "id": "S5nBHgxhsSHR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdscUaZ_sSHR"
      },
      "outputs": [],
      "source": [
        "learner.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "collapsed": true,
        "outputId": "9a88a046-739b-4933-d2d4-5cc28ff14923",
        "id": "vW8KJB31sSHR"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(slide=0.0012022644514217973, valley=0.0002290867705596611)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_find(suggest_funcs=[slide,valley])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner.fit_one_cycle(1,2.29e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "267a1e1d-5dd8-4acc-b02c-a6c6f56cb68e",
        "id": "V0D-Y7_msSHS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_multi</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.321167</td>\n",
              "      <td>0.321292</td>\n",
              "      <td>0.865466</td>\n",
              "      <td>08:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3dd462-61a4-481c-951c-4434e3d06633",
        "id": "dvZeXPROsSHS"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/skill-classifier-googlebert-stage-0.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "learner.save(\"skill-classifier-googlebert-stage-0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9cCbKxosSHS"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-googlebertstage-0.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stage-1**"
      ],
      "metadata": {
        "id": "oeM4FnLusSHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.learner import load_learner\n",
        "learner = load_learner(os.path.join(data_path,\"models\",\"skill-classifier-modernbertstage-0.pkl\"))"
      ],
      "metadata": {
        "id": "UMjENk_MsSHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_mRtvv_sSHT"
      },
      "outputs": [],
      "source": [
        "learner.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "41fc0230-0f27-4c8c-8ec5-178b2e7fac57",
        "id": "0b2YSRZRsSHT"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SuggestedLRs(slide=0.007585775572806597, valley=4.786300905834651e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.lr_find(suggest_funcs=[slide, valley])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "798de14d-4763-4dbd-ff24-2f44d8e291c1",
        "id": "oz9SKiG_sSHT"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy_multi</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.204121</td>\n",
              "      <td>0.191048</td>\n",
              "      <td>0.927959</td>\n",
              "      <td>11:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.126762</td>\n",
              "      <td>0.115719</td>\n",
              "      <td>0.960453</td>\n",
              "      <td>11:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.081494</td>\n",
              "      <td>0.082021</td>\n",
              "      <td>0.973590</td>\n",
              "      <td>11:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.048595</td>\n",
              "      <td>0.061385</td>\n",
              "      <td>0.981039</td>\n",
              "      <td>11:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.034466</td>\n",
              "      <td>0.058773</td>\n",
              "      <td>0.982802</td>\n",
              "      <td>11:10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "learner.fit_one_cycle(5, lr_max=slice(4.8e-6, 7.5e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "26f56ae2-4566-418c-f920-0c4f686a8bbd",
        "id": "hOa76LiWsSHT"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINDING OPTIMAL THRESHOLD\n",
            "======================================================================\n",
            "Thresh 0.30: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.31: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.32: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.33: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.34: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.35: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.36: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.37: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.38: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.39: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.40: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.41: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.42: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.43: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.44: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.45: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.46: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.47: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.48: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.49: Avg preds=83.00, F1-Samples=0.2498, F1-Macro=0.2366, F1-Micro=0.2573\n",
            "Thresh 0.50: Avg preds=73.47, F1-Samples=0.2767, F1-Macro=0.2534, F1-Micro=0.2859\n",
            "Thresh 0.51: Avg preds=16.16, F1-Samples=0.8632, F1-Macro=0.7895, F1-Micro=0.8362\n",
            "Thresh 0.52: Avg preds=14.66, F1-Samples=0.8897, F1-Macro=0.8392, F1-Micro=0.8751\n",
            "Thresh 0.53: Avg preds=13.90, F1-Samples=0.9031, F1-Macro=0.8644, F1-Micro=0.8949\n",
            "Thresh 0.54: Avg preds=13.41, F1-Samples=0.9117, F1-Macro=0.8784, F1-Micro=0.9071\n",
            "Thresh 0.55: Avg preds=13.05, F1-Samples=0.9176, F1-Macro=0.8893, F1-Micro=0.9156\n",
            "Thresh 0.56: Avg preds=12.77, F1-Samples=0.9219, F1-Macro=0.8957, F1-Micro=0.9218\n",
            "Thresh 0.57: Avg preds=12.55, F1-Samples=0.9248, F1-Macro=0.9016, F1-Micro=0.9263\n",
            "Thresh 0.58: Avg preds=12.37, F1-Samples=0.9269, F1-Macro=0.9046, F1-Micro=0.9296\n",
            "Thresh 0.59: Avg preds=12.22, F1-Samples=0.9287, F1-Macro=0.9081, F1-Micro=0.9323\n",
            "Thresh 0.60: Avg preds=12.08, F1-Samples=0.9304, F1-Macro=0.9110, F1-Micro=0.9348\n",
            "Thresh 0.61: Avg preds=11.96, F1-Samples=0.9315, F1-Macro=0.9123, F1-Micro=0.9366\n",
            "Thresh 0.62: Avg preds=11.85, F1-Samples=0.9325, F1-Macro=0.9139, F1-Micro=0.9382\n",
            "Thresh 0.63: Avg preds=11.75, F1-Samples=0.9333, F1-Macro=0.9144, F1-Micro=0.9394\n",
            "Thresh 0.64: Avg preds=11.64, F1-Samples=0.9335, F1-Macro=0.9145, F1-Micro=0.9399\n",
            "Thresh 0.65: Avg preds=11.55, F1-Samples=0.9334, F1-Macro=0.9152, F1-Micro=0.9402\n",
            "Thresh 0.66: Avg preds=11.45, F1-Samples=0.9327, F1-Macro=0.9140, F1-Micro=0.9399\n",
            "Thresh 0.67: Avg preds=11.36, F1-Samples=0.9318, F1-Macro=0.9129, F1-Micro=0.9395\n",
            "Thresh 0.68: Avg preds=11.27, F1-Samples=0.9310, F1-Macro=0.9118, F1-Micro=0.9390\n",
            "Thresh 0.69: Avg preds=11.17, F1-Samples=0.9299, F1-Macro=0.9093, F1-Micro=0.9381\n",
            "Thresh 0.70: Avg preds=11.06, F1-Samples=0.9279, F1-Macro=0.9068, F1-Micro=0.9364\n",
            "Thresh 0.71: Avg preds=10.92, F1-Samples=0.9246, F1-Macro=0.9020, F1-Micro=0.9333\n",
            "Thresh 0.72: Avg preds=10.72, F1-Samples=0.9185, F1-Macro=0.8939, F1-Micro=0.9274\n",
            "Thresh 0.73: Avg preds= 9.85, F1-Samples=0.8811, F1-Macro=0.8335, F1-Micro=0.8902\n",
            "\n",
            "======================================================================\n",
            "✓ OPTIMAL THRESHOLD: 0.64\n",
            "✓ Best F1-Samples: 0.9335\n",
            "✓ Avg predictions: 11.64\n",
            "✓ Avg true labels: 12.25\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "targs_np = targs.numpy()\n",
        "\n",
        "print(\"FINDING OPTIMAL THRESHOLD\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "best_metrics = {}\n",
        "\n",
        "\n",
        "for thresh in np.arange(0.30, 0.80, 0.01):\n",
        "    preds_binary = (preds_probs > thresh).numpy()\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_preds = preds_binary.sum(axis=1).mean()\n",
        "    f1_samples = f1_score(targs_np, preds_binary, average='samples', zero_division=0)\n",
        "    f1_macro = f1_score(targs_np, preds_binary, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(targs_np, preds_binary, average='micro', zero_division=0)\n",
        "\n",
        "\n",
        "    if avg_preds > 0.1:\n",
        "        print(f\"Thresh {thresh:.2f}: Avg preds={avg_preds:5.2f}, \"\n",
        "              f\"F1-Samples={f1_samples:.4f}, F1-Macro={f1_macro:.4f}, F1-Micro={f1_micro:.4f}\")\n",
        "\n",
        "\n",
        "        if f1_samples > best_f1:\n",
        "            best_f1 = f1_samples\n",
        "            best_thresh = thresh\n",
        "            best_metrics = {\n",
        "                'f1_samples': f1_samples,\n",
        "                'f1_macro': f1_macro,\n",
        "                'f1_micro': f1_micro,\n",
        "                'avg_preds': avg_preds\n",
        "            }\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✓ OPTIMAL THRESHOLD: {best_thresh:.2f}\")\n",
        "print(f\"✓ Best F1-Samples: {best_f1:.4f}\")\n",
        "print(f\"✓ Avg predictions: {best_metrics['avg_preds']:.2f}\")\n",
        "print(f\"✓ Avg true labels: {targs_np.sum(axis=1).mean():.2f}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "398417ec-18ea-4244-eaf1-90b29b49ea8f",
        "id": "A_n4nnLxsSHU"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:   0.98\n",
            "F1-Samples: 0.9304\n",
            "F1-Macro:   0.9110\n",
            "F1-Micro:   0.9348\n"
          ]
        }
      ],
      "source": [
        "preds, targs = learner.get_preds()\n",
        "preds_probs = torch.sigmoid(preds)\n",
        "preds_binary = (preds_probs > 0.6).numpy()\n",
        "targs_binary = targs.numpy()\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(f\"Accuracy:   0.98\")\n",
        "print(f\"F1-Samples: {f1_score(targs_binary, preds_binary, average='samples'):.4f}\")\n",
        "print(f\"F1-Macro:   {f1_score(targs_binary, preds_binary, average='macro'):.4f}\")\n",
        "print(f\"F1-Micro:   {f1_score(targs_binary, preds_binary, average='micro'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86f1608-0c23-401c-c282-5bd642815faa",
        "id": "bkYj7mQ7sSHU"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/skill-classifier-googlebertuncased-stage-1.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "learner.save(\"skill-classifier-googlebertuncased-stage-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFFB8t2NsSHU"
      },
      "outputs": [],
      "source": [
        "output_dir = os.path.join(data_path,\"models\")\n",
        "learner.export(os.path.join(output_dir,\"skill-classifier-googlebertuncased-1.pkl\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpX1NbfpH9xy"
      },
      "source": [
        "# **Data Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKZvxivyH9Ra"
      },
      "outputs": [],
      "source": [
        "labels = skills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh3MqCNSJyAM",
        "outputId": "623c2503-c664-4d03-ded6-060f39bcaafc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlT56zm2Jzhd",
        "outputId": "713cb7e3-433b-44d0-c5a2-96e1202dfe6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python', 'Java', 'C/C++', 'SQL', 'Machine Learning']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "labels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSjL7ZmWJ1R5",
        "outputId": "335a7a08-093c-4369-e656-9bd4f2f372e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20573, 2285)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "splitter = RandomSplitter(valid_pct=0.1, seed=42)\n",
        "train_ids, valid_ids = splitter(df)\n",
        "len(train_ids), len(valid_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LAeHbUV1KGN6",
        "outputId": "54f1e82b-7252-4737-c0ff-e2abb6d7df4a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                  job_url  \\\n",
              "4593                 https://www.indeed.com/rc/clk?jk=ec52e85b5a36778e&bb=8HSamVpDIIxqu-8QktTa4tgxIKO8H-vqMzsIHtLzHL6JhsfWGL_G4CoYpVjcGkZrmT4io0Wump1zf-SWL52rSRi051X-Rx_lLPIWpvbrmXWHmrOCV21yd28IFsmwEs_N46omIIh0e5x9TDzGSH_rULtsJmYUeplz&xkcb=SoCC67M3rr2RMTSV3R0KbzkdCdPP&fccid=6116b77c1a5422c4&vjs=3   \n",
              "16766                https://www.indeed.com/rc/clk?jk=b455474ed86f0dd0&bb=GTX8MGXv3wDWi-b5e-H1Ejkt-fqBQTqOj8Wk7LDloamQqAdMYd-27AdUUMLUYQciCdcGvsZ92Cby_GaPGn8HkDawDiLcjCMzW07nTWQLWdwuFJPfa7Yk9mSq2ktqUkFxy_UmvsucrukixOQFy828kReeGVzOoJlk&xkcb=SoD467M3rsJGSWQGah0CbzkdCdPP&fccid=a72d24fff35243e1&vjs=3   \n",
              "11712                https://www.indeed.com/rc/clk?jk=1ed7ecec910d9e7a&bb=1bwldHO0Y5e_xERU7CZN41pphDulXSEmQM4jaVRR1UNAkIW2DJ8iz8MjiuOcypPLJaN7MdxJsBmo5z4WnbPNA-fXheUBRPVgHp24E3yF1qGPL8f17f2sNKA1vJ57-Cb9VTs5kF4Lhr_mSlG8oudRbu58VueNwa17&xkcb=SoC367M3rqpPEbgN5b0LbzkdCdPP&fccid=8bd4bed1b0ebda69&vjs=3   \n",
              "2374   https://www.indeed.com/rc/clk?jk=152a277ec05e3cfa&bb=4yA79InukhRpGh_rF66q2-ZtE66UreI7Pd6auOomGdMvVw39voGpFZtm2fHx8YuHO5Lw6SgrfYaQQiyNGw6dKWiNYnf3h2DSWa4MsZAh6BH5GGYyhQEdl9Ig8mIvkPMBfqAS6rYsLmt6evL2JisaiFVUQOxWfthv2Av1e8QGSFA%3D&xkcb=SoA067M3rqr0SwwVr50ObzkdCdPP&fccid=e3ed794da90b8e4a&vjs=3   \n",
              "2994                     https://www.indeed.com/rc/clk?jk=521bcdb724812ce9&bb=4j-O-65woy2wW2wXJNJ-B9iGFdIntvCbG3gcB6zm219HX0pi-PHyFG-GA2dJ6gOQu_53P_MyCunEHp4sDZGdjCeaXF1TDTKH-RRu_4B6d0ftWU6Ozivh4HKN5_RxzOKFJZAJEjub8boKuf1_il3jdQ%3D%3D&xkcb=SoA567M3rr0oDIRNUB0PbzkdCdPP&fccid=798f4b32531a5ddb&vjs=3   \n",
              "\n",
              "                                   title  \\\n",
              "4593    Senior Machine Learning Engineer   \n",
              "16766  IT Help Desk II - 1st & 2nd Shift   \n",
              "11712    Deep Learning Compiler Engineer   \n",
              "2374          Business Intelligence Lead   \n",
              "2994                 Structural Designer   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               job_description  \\\n",
              "4593   Why join Freenome?\\nFreenome is a high-growth biotech company developing tests to detect cancer using a standard blood draw. To do this, Freenome uses a multiomics platform that combines tumor and non-tumor signals with machine learning to find cancer in its earliest, most-treatable stages.\\nCancer is relentless. This is why Freenome is building the clinical, economic, and operational evidence to drive cancer screening and save lives. Our first screening test is for colorectal cancer (CRC) and advanced adenomas, and it's just the beginning.\\nFounded in 2014, Freenome has ~400 employees and...   \n",
              "16766  BENEFITS\\nMedical & Vision Insurance\\nSupplemental Insurance Plans Available\\nDental Insurance (Company paid)\\nSTD and Life & AD&D Insurance (Company paid)\\n401(K) Matching\\nPTO & Unpaid Excused Absences\\nUniforms (Company paid)\\nTraining & Apprenticeship Opportunities\\nSafety Shoe & Glasses Reimbursement Program\\nGym Membership Reimbursement Program\\n15% Shift Premium - 2ND SHIFT ONLY\\nJOB SUMMARY\\nIT Help Desk II configures and maintains desktop, laptop, and mobile device operating systems and provides technical support for all Company employees. They also aid System Administrator and Ne...   \n",
              "11712  Quadric has created an innovative general purpose neural processing unit (GPNPU) architecture. Quadric's co-optimized software and hardware is targeted to run neural network (NN) inference workloads in a wide variety of edge and endpoint devices, ranging from battery operated smart-sensor systems to high-performance automotive or autonomous vehicle systems. Unlike other NPUs or neural network accelerators in the industry today that can only accelerate a portion of a machine learning graph, the Quadric GPNPU executes both NN graph code and conventional C++ DSP and control code.\\nIf making a...   \n",
              "2374   Passion. Purpose. Impact. CJP is at the heart of Greater Boston's Jewish community, but our reach is felt around the world. Ranked by BBJ as Massachusetts’ largest non-profit organization – CJP is a philanthropic investor and mobilizer of people, resources, and skills that make a bigger difference locally and globally.\\nThe Business Intelligence (BI) Lead is responsible for transforming complex business needs into actionable insights through data analysis, reporting, and dashboard development. This includes aligning on BI strategy, designing, developing, and maintaining systems that collec...   \n",
              "2994   Atlas Structural Systems is a manufacturer specializing in the design and manufacture of pre-engineered structural systems for commercial and residential construction projects in Eastern Canada and the US. Our integrated roof, wall, and floor systems offer proven quality and provide a great deal of benefit and value.\\n\\nDesign cost-effective and easy to install residential and commercial roof, wall and floor systems conforming to building codes.\\nPrepare engineered drawings, layouts, and job site packages.\\nProvide customer service to contractors and homeowners.\\nCreate quotes for roof, wa...   \n",
              "\n",
              "       Python  Java  C/C++  SQL  R  JavaScript  Machine Learning  ...  \\\n",
              "4593        1     1      1    0  1           0                 1  ...   \n",
              "16766       0     0      0    0  0           0                 0  ...   \n",
              "11712       0     0      0    0  0           0                 1  ...   \n",
              "2374        0     0      0    1  0           0                 0  ...   \n",
              "2994        0     0      0    0  0           0                 0  ...   \n",
              "\n",
              "       Creativity  Time Management  Attention to Detail  Critical Thinking  \\\n",
              "4593            0                0                    0                  0   \n",
              "16766           0                0                    0                  0   \n",
              "11712           1                0                    0                  0   \n",
              "2374            1                0                    0                  0   \n",
              "2994            1                0                    1                  0   \n",
              "\n",
              "       Decision Making  Collaboration  Work Ethic  Emotional Intelligence  \\\n",
              "4593                 0              1           0                       0   \n",
              "16766                0              0           0                       0   \n",
              "11712                0              1           0                       0   \n",
              "2374                 1              1           1                       0   \n",
              "2994                 0              1           1                       0   \n",
              "\n",
              "       Self-Motivation  Flexibility  \n",
              "4593                 0            0  \n",
              "16766                0            0  \n",
              "11712                0            0  \n",
              "2374                 0            1  \n",
              "2994                 1            0  \n",
              "\n",
              "[5 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23f920a8-542e-4c7c-849c-6e8d318b625b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_url</th>\n",
              "      <th>title</th>\n",
              "      <th>job_description</th>\n",
              "      <th>Python</th>\n",
              "      <th>Java</th>\n",
              "      <th>C/C++</th>\n",
              "      <th>SQL</th>\n",
              "      <th>R</th>\n",
              "      <th>JavaScript</th>\n",
              "      <th>Machine Learning</th>\n",
              "      <th>...</th>\n",
              "      <th>Creativity</th>\n",
              "      <th>Time Management</th>\n",
              "      <th>Attention to Detail</th>\n",
              "      <th>Critical Thinking</th>\n",
              "      <th>Decision Making</th>\n",
              "      <th>Collaboration</th>\n",
              "      <th>Work Ethic</th>\n",
              "      <th>Emotional Intelligence</th>\n",
              "      <th>Self-Motivation</th>\n",
              "      <th>Flexibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4593</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=ec52e85b5a36778e&amp;bb=8HSamVpDIIxqu-8QktTa4tgxIKO8H-vqMzsIHtLzHL6JhsfWGL_G4CoYpVjcGkZrmT4io0Wump1zf-SWL52rSRi051X-Rx_lLPIWpvbrmXWHmrOCV21yd28IFsmwEs_N46omIIh0e5x9TDzGSH_rULtsJmYUeplz&amp;xkcb=SoCC67M3rr2RMTSV3R0KbzkdCdPP&amp;fccid=6116b77c1a5422c4&amp;vjs=3</td>\n",
              "      <td>Senior Machine Learning Engineer</td>\n",
              "      <td>Why join Freenome?\\nFreenome is a high-growth biotech company developing tests to detect cancer using a standard blood draw. To do this, Freenome uses a multiomics platform that combines tumor and non-tumor signals with machine learning to find cancer in its earliest, most-treatable stages.\\nCancer is relentless. This is why Freenome is building the clinical, economic, and operational evidence to drive cancer screening and save lives. Our first screening test is for colorectal cancer (CRC) and advanced adenomas, and it's just the beginning.\\nFounded in 2014, Freenome has ~400 employees and...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16766</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=b455474ed86f0dd0&amp;bb=GTX8MGXv3wDWi-b5e-H1Ejkt-fqBQTqOj8Wk7LDloamQqAdMYd-27AdUUMLUYQciCdcGvsZ92Cby_GaPGn8HkDawDiLcjCMzW07nTWQLWdwuFJPfa7Yk9mSq2ktqUkFxy_UmvsucrukixOQFy828kReeGVzOoJlk&amp;xkcb=SoD467M3rsJGSWQGah0CbzkdCdPP&amp;fccid=a72d24fff35243e1&amp;vjs=3</td>\n",
              "      <td>IT Help Desk II - 1st &amp; 2nd Shift</td>\n",
              "      <td>BENEFITS\\nMedical &amp; Vision Insurance\\nSupplemental Insurance Plans Available\\nDental Insurance (Company paid)\\nSTD and Life &amp; AD&amp;D Insurance (Company paid)\\n401(K) Matching\\nPTO &amp; Unpaid Excused Absences\\nUniforms (Company paid)\\nTraining &amp; Apprenticeship Opportunities\\nSafety Shoe &amp; Glasses Reimbursement Program\\nGym Membership Reimbursement Program\\n15% Shift Premium - 2ND SHIFT ONLY\\nJOB SUMMARY\\nIT Help Desk II configures and maintains desktop, laptop, and mobile device operating systems and provides technical support for all Company employees. They also aid System Administrator and Ne...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11712</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=1ed7ecec910d9e7a&amp;bb=1bwldHO0Y5e_xERU7CZN41pphDulXSEmQM4jaVRR1UNAkIW2DJ8iz8MjiuOcypPLJaN7MdxJsBmo5z4WnbPNA-fXheUBRPVgHp24E3yF1qGPL8f17f2sNKA1vJ57-Cb9VTs5kF4Lhr_mSlG8oudRbu58VueNwa17&amp;xkcb=SoC367M3rqpPEbgN5b0LbzkdCdPP&amp;fccid=8bd4bed1b0ebda69&amp;vjs=3</td>\n",
              "      <td>Deep Learning Compiler Engineer</td>\n",
              "      <td>Quadric has created an innovative general purpose neural processing unit (GPNPU) architecture. Quadric's co-optimized software and hardware is targeted to run neural network (NN) inference workloads in a wide variety of edge and endpoint devices, ranging from battery operated smart-sensor systems to high-performance automotive or autonomous vehicle systems. Unlike other NPUs or neural network accelerators in the industry today that can only accelerate a portion of a machine learning graph, the Quadric GPNPU executes both NN graph code and conventional C++ DSP and control code.\\nIf making a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=152a277ec05e3cfa&amp;bb=4yA79InukhRpGh_rF66q2-ZtE66UreI7Pd6auOomGdMvVw39voGpFZtm2fHx8YuHO5Lw6SgrfYaQQiyNGw6dKWiNYnf3h2DSWa4MsZAh6BH5GGYyhQEdl9Ig8mIvkPMBfqAS6rYsLmt6evL2JisaiFVUQOxWfthv2Av1e8QGSFA%3D&amp;xkcb=SoA067M3rqr0SwwVr50ObzkdCdPP&amp;fccid=e3ed794da90b8e4a&amp;vjs=3</td>\n",
              "      <td>Business Intelligence Lead</td>\n",
              "      <td>Passion. Purpose. Impact. CJP is at the heart of Greater Boston's Jewish community, but our reach is felt around the world. Ranked by BBJ as Massachusetts’ largest non-profit organization – CJP is a philanthropic investor and mobilizer of people, resources, and skills that make a bigger difference locally and globally.\\nThe Business Intelligence (BI) Lead is responsible for transforming complex business needs into actionable insights through data analysis, reporting, and dashboard development. This includes aligning on BI strategy, designing, developing, and maintaining systems that collec...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2994</th>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=521bcdb724812ce9&amp;bb=4j-O-65woy2wW2wXJNJ-B9iGFdIntvCbG3gcB6zm219HX0pi-PHyFG-GA2dJ6gOQu_53P_MyCunEHp4sDZGdjCeaXF1TDTKH-RRu_4B6d0ftWU6Ozivh4HKN5_RxzOKFJZAJEjub8boKuf1_il3jdQ%3D%3D&amp;xkcb=SoA567M3rr0oDIRNUB0PbzkdCdPP&amp;fccid=798f4b32531a5ddb&amp;vjs=3</td>\n",
              "      <td>Structural Designer</td>\n",
              "      <td>Atlas Structural Systems is a manufacturer specializing in the design and manufacture of pre-engineered structural systems for commercial and residential construction projects in Eastern Canada and the US. Our integrated roof, wall, and floor systems offer proven quality and provide a great deal of benefit and value.\\n\\nDesign cost-effective and easy to install residential and commercial roof, wall and floor systems conforming to building codes.\\nPrepare engineered drawings, layouts, and job site packages.\\nProvide customer service to contractors and homeowners.\\nCreate quotes for roof, wa...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23f920a8-542e-4c7c-849c-6e8d318b625b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23f920a8-542e-4c7c-849c-6e8d318b625b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23f920a8-542e-4c7c-849c-6e8d318b625b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "valid_df"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "existing_valid_ids = [idx for idx in valid_ids if idx in df.index]\n",
        "valid_df = df.loc[existing_valid_ids]\n",
        "valid_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btRty5zOK2M_"
      },
      "source": [
        "# **ONNX**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miZfrmrpKLoQ"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/drive/MyDrive/Data Science/CP3_Skill Classifier/models/skill-classifier-modernbertstage-1.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1MjRIdtLLte"
      },
      "outputs": [],
      "source": [
        "learner_inf = load_learner(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t0KPOCwTLO7J",
        "outputId": "09a201a9-1cbf-422a-833b-3fefe63231b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModernBertForSequenceClassification(\n",
              "  (model): ModernBertModel(\n",
              "    (embeddings): ModernBertEmbeddings(\n",
              "      (tok_embeddings): Embedding(50368, 768, padding_idx=50283)\n",
              "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): ModernBertEncoderLayer(\n",
              "        (attn_norm): Identity()\n",
              "        (attn): ModernBertAttention(\n",
              "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
              "          (rotary_emb): ModernBertRotaryEmbedding()\n",
              "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (out_drop): Identity()\n",
              "        )\n",
              "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): ModernBertMLP(\n",
              "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
              "          (act): GELUActivation()\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
              "        )\n",
              "      )\n",
              "      (1-21): 21 x ModernBertEncoderLayer(\n",
              "        (attn_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ModernBertAttention(\n",
              "          (Wqkv): Linear(in_features=768, out_features=2304, bias=False)\n",
              "          (rotary_emb): ModernBertRotaryEmbedding()\n",
              "          (Wo): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (out_drop): Identity()\n",
              "        )\n",
              "        (mlp_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): ModernBertMLP(\n",
              "          (Wi): Linear(in_features=768, out_features=2304, bias=False)\n",
              "          (act): GELUActivation()\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "          (Wo): Linear(in_features=1152, out_features=768, bias=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (head): ModernBertPredictionHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=False)\n",
              "    (act): GELUActivation()\n",
              "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (drop): Dropout(p=0.0, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=83, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "learner_inf.model.hf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QE5DjxMkLXZm",
        "outputId": "5321eee4-d71c-415f-8145-98e843aa6841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `SkillClassifierModel([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `SkillClassifierModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 41 of general pattern rewrite rules.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 18},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.0+cu126',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"input_ids\"<INT64,[s72,s53]>,\n",
              "                %\"attention_mask\"<INT64,[s43,s53]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"logits\"<FLOAT,[1,83]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"hf_model.roberta.embeddings.word_embeddings.weight\"<FLOAT,[50265,768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.embeddings.position_embeddings.weight\"<FLOAT,[514,768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.embeddings.token_type_embeddings.weight\"<FLOAT,[1,768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.embeddings.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.embeddings.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.0.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.1.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.2.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.3.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.4.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.attention.self.query.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.attention.self.key.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.attention.self.value.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.attention.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.attention.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.attention.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.intermediate.dense.bias\"<FLOAT,[3072]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.output.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.output.LayerNorm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.encoder.layer.5.output.LayerNorm.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.classifier.dense.weight\"<FLOAT,[768,768]>{TorchTensor(...)},\n",
              "                %\"hf_model.classifier.dense.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"hf_model.classifier.out_proj.weight\"<FLOAT,[83,768]>{TorchTensor(...)},\n",
              "                %\"hf_model.classifier.out_proj.bias\"<FLOAT,[83]>{TorchTensor(...)},\n",
              "                %\"hf_model.roberta.embeddings.token_type_ids\"<INT64,[1,514]>{TorchTensor(...)},\n",
              "                %\"val_10\"<INT64,[1]>{Tensor<INT64,[1]>(array([1]), name='val_10')},\n",
              "                %\"clone_1\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1., dtype=float32), name='clone_1')},\n",
              "                %\"val_51\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_51')},\n",
              "                %\"val_52\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_60\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_68\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_99\"<FLOAT,[1]>{Tensor<FLOAT,[1]>(array([0.35355338], dtype=float32), name='val_99')},\n",
              "                %\"val_111\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_115\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_124\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_128\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_136\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_144\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_185\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_189\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_198\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_202\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_210\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_218\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_259\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_263\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_272\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_276\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_284\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_292\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_333\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_337\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_346\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_350\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_358\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_366\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_407\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_411\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_420\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_424\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_432\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_440\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_481\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_485\"<FLOAT,[768,3072]>{Tensor(...)},\n",
              "                %\"val_494\"<FLOAT,[3072,768]>{Tensor(...)},\n",
              "                %\"val_3\"<INT64,[1]>{Tensor<INT64,[1]>(array([0]), name='val_3')},\n",
              "                %\"val_7\"<INT64,[]>{Tensor<INT64,[]>(array(1), name='val_7')},\n",
              "                %\"val_17\"<INT64,[]>{Tensor<INT64,[]>(array(0), name='val_17')},\n",
              "                %\"val_508\"<INT64,[2]>{Tensor<INT64,[2]>(array([1, 2]), name='val_508')},\n",
              "                %\"val_56\"<INT64,[1]>{Tensor<INT64,[1]>(array([-1]), name='val_56')},\n",
              "                %\"val_57\"<INT64,[1]>{Tensor<INT64,[1]>(array([12]), name='val_57')},\n",
              "                %\"val_58\"<INT64,[1]>{Tensor<INT64,[1]>(array([64]), name='val_58')},\n",
              "                %\"val_86\"<INT64,[1]>{Tensor<INT64,[1]>(array([9223372036854775807]), name='val_86')},\n",
              "                %\"val_89\"<INT64,[1]>{Tensor<INT64,[1]>(array([-2]), name='val_89')},\n",
              "                %\"val_91\"<INT64,[1]>{Tensor<INT64,[1]>(array([-9223372036854775808]), name='val_91')},\n",
              "                %\"val_109\"<INT64,[1]>{Tensor<INT64,[1]>(array([768]), name='val_109')},\n",
              "                %\"val_117\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1.4142135, dtype=float32), name='val_117')},\n",
              "                %\"val_122\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(0.5, dtype=float32), name='val_122')}\n",
              "            ),\n",
              "        ) {\n",
              "              0 |  # node_Shape_0\n",
              "                   %\"val_0\"<INT64,[1]> ⬅️ ::Shape(%\"input_ids\") {end=1, start=0}\n",
              "              1 |  # node_Shape_1\n",
              "                   %\"val_1\"<INT64,[1]> ⬅️ ::Shape(%\"attention_mask\") {end=1, start=0}\n",
              "              2 |  # node_Shape_2\n",
              "                   %\"val_2\"<INT64,[1]> ⬅️ ::Shape(%\"attention_mask\") {end=2, start=1}\n",
              "              3 |  # node_slice_1\n",
              "                   %\"slice_1\"<INT64,[1,s53]> ⬅️ ::Slice(%\"hf_model.roberta.embeddings.token_type_ids\"{...}, %\"val_3\"{[0]}, %\"val_2\", %\"val_10\"{[1]}, %\"val_10\"{[1]})\n",
              "              4 |  # node_Concat_15\n",
              "                   %\"val_15\"<INT64,[2]> ⬅️ ::Concat(%\"val_0\", %\"val_2\") {axis=0}\n",
              "              5 |  # node_expand\n",
              "                   %\"expand\"<INT64,[s72,s53]> ⬅️ ::Expand(%\"slice_1\", %\"val_15\")\n",
              "              6 |  # node_Equal_16\n",
              "                   %\"val_16\"<BOOL,[s72,s53]> ⬅️ ::Equal(%\"input_ids\", %\"val_7\"{1})\n",
              "              7 |  # node_ne\n",
              "                   %\"ne\"<BOOL,[s72,s53]> ⬅️ ::Not(%\"val_16\")\n",
              "              8 |  # node__to_copy\n",
              "                   %\"_to_copy\"<INT32,[s72,s53]> ⬅️ ::Cast(%\"ne\") {to=6}\n",
              "              9 |  # node_convert_element_type_default\n",
              "                   %\"convert_element_type_default\"<INT64,[s72,s53]> ⬅️ ::Cast(%\"_to_copy\") {to=7}\n",
              "             10 |  # node_cumsum\n",
              "                   %\"cumsum\"<INT64,[1,s53]> ⬅️ ::CumSum(%\"convert_element_type_default\", %\"val_7\"{1}) {reverse=0, exclusive=0}\n",
              "             11 |  # node_type_as\n",
              "                   %\"type_as\"<INT32,[1,s53]> ⬅️ ::Cast(%\"cumsum\") {to=6}\n",
              "             12 |  # node_mul_12\n",
              "                   %\"mul_12\"<INT32,[s72,s53]> ⬅️ ::Mul(%\"type_as\", %\"_to_copy\")\n",
              "             13 |  # node__to_copy_1\n",
              "                   %\"_to_copy_1\"<INT64,[s72,s53]> ⬅️ ::Cast(%\"mul_12\") {to=7}\n",
              "             14 |  # node_add_24\n",
              "                   %\"add_24\"<INT64,[1,s53]> ⬅️ ::Add(%\"_to_copy_1\", %\"val_7\"{1})\n",
              "             15 |  # node_embedding\n",
              "                   %\"embedding\"<FLOAT,[s72,s53,768]> ⬅️ ::Gather(%\"hf_model.roberta.embeddings.word_embeddings.weight\"{...}, %\"input_ids\") {axis=0}\n",
              "             16 |  # node_embedding_1\n",
              "                   %\"embedding_1\"<FLOAT,[s72,s53,768]> ⬅️ ::Gather(%\"hf_model.roberta.embeddings.token_type_embeddings.weight\"{...}, %\"expand\") {axis=0}\n",
              "             17 |  # node_add_35\n",
              "                   %\"add_35\"<FLOAT,[s72,s53,768]> ⬅️ ::Add(%\"embedding\", %\"embedding_1\")\n",
              "             18 |  # node_embedding_2\n",
              "                   %\"embedding_2\"<FLOAT,[1,s53,768]> ⬅️ ::Gather(%\"hf_model.roberta.embeddings.position_embeddings.weight\"{...}, %\"add_24\") {axis=0}\n",
              "             19 |  # node_add_50\n",
              "                   %\"add_50\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_35\", %\"embedding_2\")\n",
              "             20 |  # node_layer_norm\n",
              "                   %\"layer_norm\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_50\", %\"hf_model.roberta.embeddings.LayerNorm.weight\"{...}, %\"hf_model.roberta.embeddings.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             21 |  # node_Unsqueeze_524\n",
              "                   %\"unsqueeze_1\"<INT64,[s43,1,1,s53]> ⬅️ ::Unsqueeze(%\"attention_mask\", %\"val_508\"{[1, 2]})\n",
              "             22 |  # node_Concat_47\n",
              "                   %\"val_49\"<INT64,[4]> ⬅️ ::Concat(%\"val_1\", %\"val_10\"{[1]}, %\"val_2\", %\"val_2\") {axis=0}\n",
              "             23 |  # node_expand_1\n",
              "                   %\"expand_1\"<INT64,[s43,1,s53,s53]> ⬅️ ::Expand(%\"unsqueeze_1\", %\"val_49\")\n",
              "             24 |  # node__to_copy_2\n",
              "                   %\"_to_copy_2\"<FLOAT,[s43,1,s53,s53]> ⬅️ ::Cast(%\"expand_1\") {to=1}\n",
              "             25 |  # node_sub_42\n",
              "                   %\"sub_42\"<FLOAT,[s43,1,s53,s53]> ⬅️ ::Sub(%\"clone_1\"{1.0}, %\"_to_copy_2\")\n",
              "             26 |  # node__to_copy_3\n",
              "                   %\"_to_copy_3\"<BOOL,[s43,1,s53,s53]> ⬅️ ::Cast(%\"sub_42\") {to=9}\n",
              "             27 |  # node_masked_fill\n",
              "                   %\"masked_fill\"<FLOAT,[s43,1,s53,s53]> ⬅️ ::Where(%\"_to_copy_3\", %\"val_51\"{-3.4028234663852886e+38}, %\"sub_42\")\n",
              "             28 |  # node_MatMul_51\n",
              "                   %\"val_53\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_52\"{...})\n",
              "             29 |  # node_linear\n",
              "                   %\"linear\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_53\", %\"hf_model.roberta.encoder.layer.0.attention.self.query.bias\"{...})\n",
              "             30 |  # node_Concat_57\n",
              "                   %\"val_59\"<INT64,[4]> ⬅️ ::Concat(%\"val_0\", %\"val_56\"{[-1]}, %\"val_57\"{[12]}, %\"val_58\"{[64]}) {axis=0}\n",
              "             31 |  # node_view\n",
              "                   %\"view\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear\", %\"val_59\") {allowzero=1}\n",
              "             32 |  # node_transpose\n",
              "                   %\"transpose\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view\") {perm=(0, 2, 1, 3)}\n",
              "             33 |  # node_MatMul_59\n",
              "                   %\"val_61\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_60\"{...})\n",
              "             34 |  # node_linear_1\n",
              "                   %\"linear_1\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_61\", %\"hf_model.roberta.encoder.layer.0.attention.self.key.bias\"{...})\n",
              "             35 |  # node_view_1\n",
              "                   %\"view_1\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_1\", %\"val_59\") {allowzero=1}\n",
              "             36 |  # node_transpose_1\n",
              "                   %\"transpose_1\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_1\") {perm=(0, 2, 1, 3)}\n",
              "             37 |  # node_MatMul_67\n",
              "                   %\"val_69\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_68\"{...})\n",
              "             38 |  # node_linear_2\n",
              "                   %\"linear_2\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_69\", %\"hf_model.roberta.encoder.layer.0.attention.self.value.bias\"{...})\n",
              "             39 |  # node_view_2\n",
              "                   %\"view_2\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_2\", %\"val_59\") {allowzero=1}\n",
              "             40 |  # node_transpose_2\n",
              "                   %\"transpose_2\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_2\") {perm=(0, 2, 1, 3)}\n",
              "             41 |  # node_Shape_83\n",
              "                   %\"val_85\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_1\") {start=0}\n",
              "             42 |  # node_Slice_86\n",
              "                   %\"val_88\"<INT64,[1]> ⬅️ ::Slice(%\"val_85\", %\"val_56\"{[-1]}, %\"val_86\"{[9223372036854775807]})\n",
              "             43 |  # node_Slice_88\n",
              "                   %\"val_90\"<INT64,[1]> ⬅️ ::Slice(%\"val_85\", %\"val_89\"{[-2]}, %\"val_56\"{[-1]})\n",
              "             44 |  # node_Slice_90\n",
              "                   %\"val_92\"<INT64,[2]> ⬅️ ::Slice(%\"val_85\", %\"val_91\"{[-9223372036854775808]}, %\"val_89\"{[-2]})\n",
              "             45 |  # node_Concat_92\n",
              "                   %\"val_94\"<INT64,[3]> ⬅️ ::Concat(%\"val_56\"{[-1]}, %\"val_90\", %\"val_88\") {axis=0}\n",
              "             46 |  # node_Reshape_93\n",
              "                   %\"val_95\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"transpose_1\", %\"val_94\") {allowzero=0}\n",
              "             47 |  # node_Transpose_94\n",
              "                   %\"val_96\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_95\") {perm=(0, 2, 1)}\n",
              "             48 |  # node_Concat_95\n",
              "                   %\"val_97\"<INT64,[4]> ⬅️ ::Concat(%\"val_92\", %\"val_88\", %\"val_90\") {axis=0}\n",
              "             49 |  # node_Reshape_96\n",
              "                   %\"val_98\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_96\", %\"val_97\") {allowzero=0}\n",
              "             50 |  # node_Mul_98\n",
              "                   %\"val_100\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"transpose\", %\"val_99\"{[0.3535533845424652]})\n",
              "             51 |  # node_Mul_100\n",
              "                   %\"val_102\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_98\", %\"val_99\"{[0.3535533845424652]})\n",
              "             52 |  # node_MatMul_101\n",
              "                   %\"val_103\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_100\", %\"val_102\")\n",
              "             53 |  # node_Add_102\n",
              "                   %\"val_104\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_103\", %\"masked_fill\")\n",
              "             54 |  # node_Softmax_103\n",
              "                   %\"val_105\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_104\") {axis=-1}\n",
              "             55 |  # node_scaled_dot_product_attention\n",
              "                   %\"scaled_dot_product_attention\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_105\", %\"transpose_2\")\n",
              "             56 |  # node_transpose_3\n",
              "                   %\"transpose_3\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention\") {perm=(0, 2, 1, 3)}\n",
              "             57 |  # node_Concat_108\n",
              "                   %\"val_110\"<INT64,[3]> ⬅️ ::Concat(%\"val_0\", %\"val_2\", %\"val_109\"{[768]}) {axis=0}\n",
              "             58 |  # node_view_3\n",
              "                   %\"view_3\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_3\", %\"val_110\") {allowzero=1}\n",
              "             59 |  # node_MatMul_110\n",
              "                   %\"val_112\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_3\", %\"val_111\"{...})\n",
              "             60 |  # node_linear_3\n",
              "                   %\"linear_3\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_112\", %\"hf_model.roberta.encoder.layer.0.attention.output.dense.bias\"{...})\n",
              "             61 |  # node_add_148\n",
              "                   %\"add_148\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_3\", %\"layer_norm\")\n",
              "             62 |  # node_layer_norm_1\n",
              "                   %\"layer_norm_1\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_148\", %\"hf_model.roberta.encoder.layer.0.attention.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.0.attention.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             63 |  # node_MatMul_112\n",
              "                   %\"val_116\"<FLOAT,[1,s53,3072]> ⬅️ ::MatMul(%\"layer_norm_1\", %\"val_115\"{...})\n",
              "             64 |  # node_linear_4\n",
              "                   %\"linear_4\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_116\", %\"hf_model.roberta.encoder.layer.0.intermediate.dense.bias\"{...})\n",
              "             65 |  # node_Div_114\n",
              "                   %\"val_118\"<FLOAT,[1,s53,3072]> ⬅️ ::Div(%\"linear_4\", %\"val_117\"{1.4142135381698608})\n",
              "             66 |  # node_Erf_115\n",
              "                   %\"val_119\"<FLOAT,[1,s53,3072]> ⬅️ ::Erf(%\"val_118\")\n",
              "             67 |  # node_Add_117\n",
              "                   %\"val_121\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_119\", %\"clone_1\"{1.0})\n",
              "             68 |  # node_Mul_119\n",
              "                   %\"val_123\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"val_122\"{0.5}, %\"val_121\")\n",
              "             69 |  # node_gelu\n",
              "                   %\"gelu\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"linear_4\", %\"val_123\")\n",
              "             70 |  # node_MatMul_121\n",
              "                   %\"val_125\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"gelu\", %\"val_124\"{...})\n",
              "             71 |  # node_linear_5\n",
              "                   %\"linear_5\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_125\", %\"hf_model.roberta.encoder.layer.0.output.dense.bias\"{...})\n",
              "             72 |  # node_add_167\n",
              "                   %\"add_167\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_5\", %\"layer_norm_1\")\n",
              "             73 |  # node_layer_norm_2\n",
              "                   %\"layer_norm_2\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_167\", %\"hf_model.roberta.encoder.layer.0.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.0.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             74 |  # node_MatMul_123\n",
              "                   %\"val_129\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_128\"{...})\n",
              "             75 |  # node_linear_6\n",
              "                   %\"linear_6\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_129\", %\"hf_model.roberta.encoder.layer.1.attention.self.query.bias\"{...})\n",
              "             76 |  # node_view_4\n",
              "                   %\"view_4\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_6\", %\"val_59\") {allowzero=1}\n",
              "             77 |  # node_transpose_4\n",
              "                   %\"transpose_4\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_4\") {perm=(0, 2, 1, 3)}\n",
              "             78 |  # node_MatMul_131\n",
              "                   %\"val_137\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_136\"{...})\n",
              "             79 |  # node_linear_7\n",
              "                   %\"linear_7\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_137\", %\"hf_model.roberta.encoder.layer.1.attention.self.key.bias\"{...})\n",
              "             80 |  # node_view_5\n",
              "                   %\"view_5\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_7\", %\"val_59\") {allowzero=1}\n",
              "             81 |  # node_transpose_5\n",
              "                   %\"transpose_5\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_5\") {perm=(0, 2, 1, 3)}\n",
              "             82 |  # node_MatMul_139\n",
              "                   %\"val_145\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_144\"{...})\n",
              "             83 |  # node_linear_8\n",
              "                   %\"linear_8\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_145\", %\"hf_model.roberta.encoder.layer.1.attention.self.value.bias\"{...})\n",
              "             84 |  # node_view_6\n",
              "                   %\"view_6\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_8\", %\"val_59\") {allowzero=1}\n",
              "             85 |  # node_transpose_6\n",
              "                   %\"transpose_6\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_6\") {perm=(0, 2, 1, 3)}\n",
              "             86 |  # node_Shape_155\n",
              "                   %\"val_161\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_5\") {start=0}\n",
              "             87 |  # node_Slice_157\n",
              "                   %\"val_163\"<INT64,[1]> ⬅️ ::Slice(%\"val_161\", %\"val_56\"{[-1]}, %\"val_86\"{[9223372036854775807]})\n",
              "             88 |  # node_Slice_158\n",
              "                   %\"val_164\"<INT64,[1]> ⬅️ ::Slice(%\"val_161\", %\"val_89\"{[-2]}, %\"val_56\"{[-1]})\n",
              "             89 |  # node_Slice_160\n",
              "                   %\"val_166\"<INT64,[2]> ⬅️ ::Slice(%\"val_161\", %\"val_91\"{[-9223372036854775808]}, %\"val_89\"{[-2]})\n",
              "             90 |  # node_Concat_162\n",
              "                   %\"val_168\"<INT64,[3]> ⬅️ ::Concat(%\"val_56\"{[-1]}, %\"val_164\", %\"val_163\") {axis=0}\n",
              "             91 |  # node_Reshape_163\n",
              "                   %\"val_169\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"transpose_5\", %\"val_168\") {allowzero=0}\n",
              "             92 |  # node_Transpose_164\n",
              "                   %\"val_170\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_169\") {perm=(0, 2, 1)}\n",
              "             93 |  # node_Concat_165\n",
              "                   %\"val_171\"<INT64,[4]> ⬅️ ::Concat(%\"val_166\", %\"val_163\", %\"val_164\") {axis=0}\n",
              "             94 |  # node_Reshape_166\n",
              "                   %\"val_172\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_170\", %\"val_171\") {allowzero=0}\n",
              "             95 |  # node_Mul_168\n",
              "                   %\"val_174\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"transpose_4\", %\"val_99\"{[0.3535533845424652]})\n",
              "             96 |  # node_Mul_170\n",
              "                   %\"val_176\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_172\", %\"val_99\"{[0.3535533845424652]})\n",
              "             97 |  # node_MatMul_171\n",
              "                   %\"val_177\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_174\", %\"val_176\")\n",
              "             98 |  # node_Add_172\n",
              "                   %\"val_178\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_177\", %\"masked_fill\")\n",
              "             99 |  # node_Softmax_173\n",
              "                   %\"val_179\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_178\") {axis=-1}\n",
              "            100 |  # node_scaled_dot_product_attention_1\n",
              "                   %\"scaled_dot_product_attention_1\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_179\", %\"transpose_6\")\n",
              "            101 |  # node_transpose_7\n",
              "                   %\"transpose_7\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_1\") {perm=(0, 2, 1, 3)}\n",
              "            102 |  # node_view_7\n",
              "                   %\"view_7\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_7\", %\"val_110\") {allowzero=1}\n",
              "            103 |  # node_MatMul_180\n",
              "                   %\"val_186\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_7\", %\"val_185\"{...})\n",
              "            104 |  # node_linear_9\n",
              "                   %\"linear_9\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_186\", %\"hf_model.roberta.encoder.layer.1.attention.output.dense.bias\"{...})\n",
              "            105 |  # node_add_220\n",
              "                   %\"add_220\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_9\", %\"layer_norm_2\")\n",
              "            106 |  # node_layer_norm_3\n",
              "                   %\"layer_norm_3\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_220\", %\"hf_model.roberta.encoder.layer.1.attention.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.1.attention.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            107 |  # node_MatMul_182\n",
              "                   %\"val_190\"<FLOAT,[1,s53,3072]> ⬅️ ::MatMul(%\"layer_norm_3\", %\"val_189\"{...})\n",
              "            108 |  # node_linear_10\n",
              "                   %\"linear_10\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_190\", %\"hf_model.roberta.encoder.layer.1.intermediate.dense.bias\"{...})\n",
              "            109 |  # node_Div_184\n",
              "                   %\"val_192\"<FLOAT,[1,s53,3072]> ⬅️ ::Div(%\"linear_10\", %\"val_117\"{1.4142135381698608})\n",
              "            110 |  # node_Erf_185\n",
              "                   %\"val_193\"<FLOAT,[1,s53,3072]> ⬅️ ::Erf(%\"val_192\")\n",
              "            111 |  # node_Add_187\n",
              "                   %\"val_195\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_193\", %\"clone_1\"{1.0})\n",
              "            112 |  # node_Mul_189\n",
              "                   %\"val_197\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"val_122\"{0.5}, %\"val_195\")\n",
              "            113 |  # node_gelu_1\n",
              "                   %\"gelu_1\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"linear_10\", %\"val_197\")\n",
              "            114 |  # node_MatMul_191\n",
              "                   %\"val_199\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"gelu_1\", %\"val_198\"{...})\n",
              "            115 |  # node_linear_11\n",
              "                   %\"linear_11\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_199\", %\"hf_model.roberta.encoder.layer.1.output.dense.bias\"{...})\n",
              "            116 |  # node_add_239\n",
              "                   %\"add_239\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_11\", %\"layer_norm_3\")\n",
              "            117 |  # node_layer_norm_4\n",
              "                   %\"layer_norm_4\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_239\", %\"hf_model.roberta.encoder.layer.1.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.1.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            118 |  # node_MatMul_193\n",
              "                   %\"val_203\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_202\"{...})\n",
              "            119 |  # node_linear_12\n",
              "                   %\"linear_12\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_203\", %\"hf_model.roberta.encoder.layer.2.attention.self.query.bias\"{...})\n",
              "            120 |  # node_view_8\n",
              "                   %\"view_8\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_12\", %\"val_59\") {allowzero=1}\n",
              "            121 |  # node_transpose_8\n",
              "                   %\"transpose_8\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_8\") {perm=(0, 2, 1, 3)}\n",
              "            122 |  # node_MatMul_201\n",
              "                   %\"val_211\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_210\"{...})\n",
              "            123 |  # node_linear_13\n",
              "                   %\"linear_13\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_211\", %\"hf_model.roberta.encoder.layer.2.attention.self.key.bias\"{...})\n",
              "            124 |  # node_view_9\n",
              "                   %\"view_9\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_13\", %\"val_59\") {allowzero=1}\n",
              "            125 |  # node_transpose_9\n",
              "                   %\"transpose_9\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_9\") {perm=(0, 2, 1, 3)}\n",
              "            126 |  # node_MatMul_209\n",
              "                   %\"val_219\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_218\"{...})\n",
              "            127 |  # node_linear_14\n",
              "                   %\"linear_14\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_219\", %\"hf_model.roberta.encoder.layer.2.attention.self.value.bias\"{...})\n",
              "            128 |  # node_view_10\n",
              "                   %\"view_10\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_14\", %\"val_59\") {allowzero=1}\n",
              "            129 |  # node_transpose_10\n",
              "                   %\"transpose_10\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_10\") {perm=(0, 2, 1, 3)}\n",
              "            130 |  # node_Shape_225\n",
              "                   %\"val_235\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_9\") {start=0}\n",
              "            131 |  # node_Slice_227\n",
              "                   %\"val_237\"<INT64,[1]> ⬅️ ::Slice(%\"val_235\", %\"val_56\"{[-1]}, %\"val_86\"{[9223372036854775807]})\n",
              "            132 |  # node_Slice_228\n",
              "                   %\"val_238\"<INT64,[1]> ⬅️ ::Slice(%\"val_235\", %\"val_89\"{[-2]}, %\"val_56\"{[-1]})\n",
              "            133 |  # node_Slice_230\n",
              "                   %\"val_240\"<INT64,[2]> ⬅️ ::Slice(%\"val_235\", %\"val_91\"{[-9223372036854775808]}, %\"val_89\"{[-2]})\n",
              "            134 |  # node_Concat_232\n",
              "                   %\"val_242\"<INT64,[3]> ⬅️ ::Concat(%\"val_56\"{[-1]}, %\"val_238\", %\"val_237\") {axis=0}\n",
              "            135 |  # node_Reshape_233\n",
              "                   %\"val_243\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"transpose_9\", %\"val_242\") {allowzero=0}\n",
              "            136 |  # node_Transpose_234\n",
              "                   %\"val_244\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_243\") {perm=(0, 2, 1)}\n",
              "            137 |  # node_Concat_235\n",
              "                   %\"val_245\"<INT64,[4]> ⬅️ ::Concat(%\"val_240\", %\"val_237\", %\"val_238\") {axis=0}\n",
              "            138 |  # node_Reshape_236\n",
              "                   %\"val_246\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_244\", %\"val_245\") {allowzero=0}\n",
              "            139 |  # node_Mul_238\n",
              "                   %\"val_248\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"transpose_8\", %\"val_99\"{[0.3535533845424652]})\n",
              "            140 |  # node_Mul_240\n",
              "                   %\"val_250\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_246\", %\"val_99\"{[0.3535533845424652]})\n",
              "            141 |  # node_MatMul_241\n",
              "                   %\"val_251\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_248\", %\"val_250\")\n",
              "            142 |  # node_Add_242\n",
              "                   %\"val_252\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_251\", %\"masked_fill\")\n",
              "            143 |  # node_Softmax_243\n",
              "                   %\"val_253\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_252\") {axis=-1}\n",
              "            144 |  # node_scaled_dot_product_attention_2\n",
              "                   %\"scaled_dot_product_attention_2\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_253\", %\"transpose_10\")\n",
              "            145 |  # node_transpose_11\n",
              "                   %\"transpose_11\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_2\") {perm=(0, 2, 1, 3)}\n",
              "            146 |  # node_view_11\n",
              "                   %\"view_11\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_11\", %\"val_110\") {allowzero=1}\n",
              "            147 |  # node_MatMul_250\n",
              "                   %\"val_260\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_11\", %\"val_259\"{...})\n",
              "            148 |  # node_linear_15\n",
              "                   %\"linear_15\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_260\", %\"hf_model.roberta.encoder.layer.2.attention.output.dense.bias\"{...})\n",
              "            149 |  # node_add_292\n",
              "                   %\"add_292\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_15\", %\"layer_norm_4\")\n",
              "            150 |  # node_layer_norm_5\n",
              "                   %\"layer_norm_5\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_292\", %\"hf_model.roberta.encoder.layer.2.attention.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.2.attention.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            151 |  # node_MatMul_252\n",
              "                   %\"val_264\"<FLOAT,[1,s53,3072]> ⬅️ ::MatMul(%\"layer_norm_5\", %\"val_263\"{...})\n",
              "            152 |  # node_linear_16\n",
              "                   %\"linear_16\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_264\", %\"hf_model.roberta.encoder.layer.2.intermediate.dense.bias\"{...})\n",
              "            153 |  # node_Div_254\n",
              "                   %\"val_266\"<FLOAT,[1,s53,3072]> ⬅️ ::Div(%\"linear_16\", %\"val_117\"{1.4142135381698608})\n",
              "            154 |  # node_Erf_255\n",
              "                   %\"val_267\"<FLOAT,[1,s53,3072]> ⬅️ ::Erf(%\"val_266\")\n",
              "            155 |  # node_Add_257\n",
              "                   %\"val_269\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_267\", %\"clone_1\"{1.0})\n",
              "            156 |  # node_Mul_259\n",
              "                   %\"val_271\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"val_122\"{0.5}, %\"val_269\")\n",
              "            157 |  # node_gelu_2\n",
              "                   %\"gelu_2\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"linear_16\", %\"val_271\")\n",
              "            158 |  # node_MatMul_261\n",
              "                   %\"val_273\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"gelu_2\", %\"val_272\"{...})\n",
              "            159 |  # node_linear_17\n",
              "                   %\"linear_17\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_273\", %\"hf_model.roberta.encoder.layer.2.output.dense.bias\"{...})\n",
              "            160 |  # node_add_311\n",
              "                   %\"add_311\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_17\", %\"layer_norm_5\")\n",
              "            161 |  # node_layer_norm_6\n",
              "                   %\"layer_norm_6\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_311\", %\"hf_model.roberta.encoder.layer.2.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.2.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            162 |  # node_MatMul_263\n",
              "                   %\"val_277\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_276\"{...})\n",
              "            163 |  # node_linear_18\n",
              "                   %\"linear_18\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_277\", %\"hf_model.roberta.encoder.layer.3.attention.self.query.bias\"{...})\n",
              "            164 |  # node_view_12\n",
              "                   %\"view_12\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_18\", %\"val_59\") {allowzero=1}\n",
              "            165 |  # node_transpose_12\n",
              "                   %\"transpose_12\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_12\") {perm=(0, 2, 1, 3)}\n",
              "            166 |  # node_MatMul_271\n",
              "                   %\"val_285\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_284\"{...})\n",
              "            167 |  # node_linear_19\n",
              "                   %\"linear_19\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_285\", %\"hf_model.roberta.encoder.layer.3.attention.self.key.bias\"{...})\n",
              "            168 |  # node_view_13\n",
              "                   %\"view_13\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_19\", %\"val_59\") {allowzero=1}\n",
              "            169 |  # node_transpose_13\n",
              "                   %\"transpose_13\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_13\") {perm=(0, 2, 1, 3)}\n",
              "            170 |  # node_MatMul_279\n",
              "                   %\"val_293\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_292\"{...})\n",
              "            171 |  # node_linear_20\n",
              "                   %\"linear_20\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_293\", %\"hf_model.roberta.encoder.layer.3.attention.self.value.bias\"{...})\n",
              "            172 |  # node_view_14\n",
              "                   %\"view_14\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_20\", %\"val_59\") {allowzero=1}\n",
              "            173 |  # node_transpose_14\n",
              "                   %\"transpose_14\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_14\") {perm=(0, 2, 1, 3)}\n",
              "            174 |  # node_Shape_295\n",
              "                   %\"val_309\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_13\") {start=0}\n",
              "            175 |  # node_Slice_297\n",
              "                   %\"val_311\"<INT64,[1]> ⬅️ ::Slice(%\"val_309\", %\"val_56\"{[-1]}, %\"val_86\"{[9223372036854775807]})\n",
              "            176 |  # node_Slice_298\n",
              "                   %\"val_312\"<INT64,[1]> ⬅️ ::Slice(%\"val_309\", %\"val_89\"{[-2]}, %\"val_56\"{[-1]})\n",
              "            177 |  # node_Slice_300\n",
              "                   %\"val_314\"<INT64,[2]> ⬅️ ::Slice(%\"val_309\", %\"val_91\"{[-9223372036854775808]}, %\"val_89\"{[-2]})\n",
              "            178 |  # node_Concat_302\n",
              "                   %\"val_316\"<INT64,[3]> ⬅️ ::Concat(%\"val_56\"{[-1]}, %\"val_312\", %\"val_311\") {axis=0}\n",
              "            179 |  # node_Reshape_303\n",
              "                   %\"val_317\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"transpose_13\", %\"val_316\") {allowzero=0}\n",
              "            180 |  # node_Transpose_304\n",
              "                   %\"val_318\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_317\") {perm=(0, 2, 1)}\n",
              "            181 |  # node_Concat_305\n",
              "                   %\"val_319\"<INT64,[4]> ⬅️ ::Concat(%\"val_314\", %\"val_311\", %\"val_312\") {axis=0}\n",
              "            182 |  # node_Reshape_306\n",
              "                   %\"val_320\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_318\", %\"val_319\") {allowzero=0}\n",
              "            183 |  # node_Mul_308\n",
              "                   %\"val_322\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"transpose_12\", %\"val_99\"{[0.3535533845424652]})\n",
              "            184 |  # node_Mul_310\n",
              "                   %\"val_324\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_320\", %\"val_99\"{[0.3535533845424652]})\n",
              "            185 |  # node_MatMul_311\n",
              "                   %\"val_325\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_322\", %\"val_324\")\n",
              "            186 |  # node_Add_312\n",
              "                   %\"val_326\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_325\", %\"masked_fill\")\n",
              "            187 |  # node_Softmax_313\n",
              "                   %\"val_327\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_326\") {axis=-1}\n",
              "            188 |  # node_scaled_dot_product_attention_3\n",
              "                   %\"scaled_dot_product_attention_3\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_327\", %\"transpose_14\")\n",
              "            189 |  # node_transpose_15\n",
              "                   %\"transpose_15\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_3\") {perm=(0, 2, 1, 3)}\n",
              "            190 |  # node_view_15\n",
              "                   %\"view_15\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_15\", %\"val_110\") {allowzero=1}\n",
              "            191 |  # node_MatMul_320\n",
              "                   %\"val_334\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_15\", %\"val_333\"{...})\n",
              "            192 |  # node_linear_21\n",
              "                   %\"linear_21\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_334\", %\"hf_model.roberta.encoder.layer.3.attention.output.dense.bias\"{...})\n",
              "            193 |  # node_add_364\n",
              "                   %\"add_364\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_21\", %\"layer_norm_6\")\n",
              "            194 |  # node_layer_norm_7\n",
              "                   %\"layer_norm_7\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_364\", %\"hf_model.roberta.encoder.layer.3.attention.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.3.attention.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            195 |  # node_MatMul_322\n",
              "                   %\"val_338\"<FLOAT,[1,s53,3072]> ⬅️ ::MatMul(%\"layer_norm_7\", %\"val_337\"{...})\n",
              "            196 |  # node_linear_22\n",
              "                   %\"linear_22\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_338\", %\"hf_model.roberta.encoder.layer.3.intermediate.dense.bias\"{...})\n",
              "            197 |  # node_Div_324\n",
              "                   %\"val_340\"<FLOAT,[1,s53,3072]> ⬅️ ::Div(%\"linear_22\", %\"val_117\"{1.4142135381698608})\n",
              "            198 |  # node_Erf_325\n",
              "                   %\"val_341\"<FLOAT,[1,s53,3072]> ⬅️ ::Erf(%\"val_340\")\n",
              "            199 |  # node_Add_327\n",
              "                   %\"val_343\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_341\", %\"clone_1\"{1.0})\n",
              "            200 |  # node_Mul_329\n",
              "                   %\"val_345\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"val_122\"{0.5}, %\"val_343\")\n",
              "            201 |  # node_gelu_3\n",
              "                   %\"gelu_3\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"linear_22\", %\"val_345\")\n",
              "            202 |  # node_MatMul_331\n",
              "                   %\"val_347\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"gelu_3\", %\"val_346\"{...})\n",
              "            203 |  # node_linear_23\n",
              "                   %\"linear_23\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_347\", %\"hf_model.roberta.encoder.layer.3.output.dense.bias\"{...})\n",
              "            204 |  # node_add_383\n",
              "                   %\"add_383\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_23\", %\"layer_norm_7\")\n",
              "            205 |  # node_layer_norm_8\n",
              "                   %\"layer_norm_8\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_383\", %\"hf_model.roberta.encoder.layer.3.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.3.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            206 |  # node_MatMul_333\n",
              "                   %\"val_351\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_350\"{...})\n",
              "            207 |  # node_linear_24\n",
              "                   %\"linear_24\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_351\", %\"hf_model.roberta.encoder.layer.4.attention.self.query.bias\"{...})\n",
              "            208 |  # node_view_16\n",
              "                   %\"view_16\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_24\", %\"val_59\") {allowzero=1}\n",
              "            209 |  # node_transpose_16\n",
              "                   %\"transpose_16\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_16\") {perm=(0, 2, 1, 3)}\n",
              "            210 |  # node_MatMul_341\n",
              "                   %\"val_359\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_358\"{...})\n",
              "            211 |  # node_linear_25\n",
              "                   %\"linear_25\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_359\", %\"hf_model.roberta.encoder.layer.4.attention.self.key.bias\"{...})\n",
              "            212 |  # node_view_17\n",
              "                   %\"view_17\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_25\", %\"val_59\") {allowzero=1}\n",
              "            213 |  # node_transpose_17\n",
              "                   %\"transpose_17\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_17\") {perm=(0, 2, 1, 3)}\n",
              "            214 |  # node_MatMul_349\n",
              "                   %\"val_367\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_366\"{...})\n",
              "            215 |  # node_linear_26\n",
              "                   %\"linear_26\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_367\", %\"hf_model.roberta.encoder.layer.4.attention.self.value.bias\"{...})\n",
              "            216 |  # node_view_18\n",
              "                   %\"view_18\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_26\", %\"val_59\") {allowzero=1}\n",
              "            217 |  # node_transpose_18\n",
              "                   %\"transpose_18\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_18\") {perm=(0, 2, 1, 3)}\n",
              "            218 |  # node_Shape_365\n",
              "                   %\"val_383\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_17\") {start=0}\n",
              "            219 |  # node_Slice_367\n",
              "                   %\"val_385\"<INT64,[1]> ⬅️ ::Slice(%\"val_383\", %\"val_56\"{[-1]}, %\"val_86\"{[9223372036854775807]})\n",
              "            220 |  # node_Slice_368\n",
              "                   %\"val_386\"<INT64,[1]> ⬅️ ::Slice(%\"val_383\", %\"val_89\"{[-2]}, %\"val_56\"{[-1]})\n",
              "            221 |  # node_Slice_370\n",
              "                   %\"val_388\"<INT64,[2]> ⬅️ ::Slice(%\"val_383\", %\"val_91\"{[-9223372036854775808]}, %\"val_89\"{[-2]})\n",
              "            222 |  # node_Concat_372\n",
              "                   %\"val_390\"<INT64,[3]> ⬅️ ::Concat(%\"val_56\"{[-1]}, %\"val_386\", %\"val_385\") {axis=0}\n",
              "            223 |  # node_Reshape_373\n",
              "                   %\"val_391\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"transpose_17\", %\"val_390\") {allowzero=0}\n",
              "            224 |  # node_Transpose_374\n",
              "                   %\"val_392\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_391\") {perm=(0, 2, 1)}\n",
              "            225 |  # node_Concat_375\n",
              "                   %\"val_393\"<INT64,[4]> ⬅️ ::Concat(%\"val_388\", %\"val_385\", %\"val_386\") {axis=0}\n",
              "            226 |  # node_Reshape_376\n",
              "                   %\"val_394\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_392\", %\"val_393\") {allowzero=0}\n",
              "            227 |  # node_Mul_378\n",
              "                   %\"val_396\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"transpose_16\", %\"val_99\"{[0.3535533845424652]})\n",
              "            228 |  # node_Mul_380\n",
              "                   %\"val_398\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_394\", %\"val_99\"{[0.3535533845424652]})\n",
              "            229 |  # node_MatMul_381\n",
              "                   %\"val_399\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_396\", %\"val_398\")\n",
              "            230 |  # node_Add_382\n",
              "                   %\"val_400\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_399\", %\"masked_fill\")\n",
              "            231 |  # node_Softmax_383\n",
              "                   %\"val_401\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_400\") {axis=-1}\n",
              "            232 |  # node_scaled_dot_product_attention_4\n",
              "                   %\"scaled_dot_product_attention_4\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_401\", %\"transpose_18\")\n",
              "            233 |  # node_transpose_19\n",
              "                   %\"transpose_19\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_4\") {perm=(0, 2, 1, 3)}\n",
              "            234 |  # node_view_19\n",
              "                   %\"view_19\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_19\", %\"val_110\") {allowzero=1}\n",
              "            235 |  # node_MatMul_390\n",
              "                   %\"val_408\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_19\", %\"val_407\"{...})\n",
              "            236 |  # node_linear_27\n",
              "                   %\"linear_27\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_408\", %\"hf_model.roberta.encoder.layer.4.attention.output.dense.bias\"{...})\n",
              "            237 |  # node_add_436\n",
              "                   %\"add_436\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_27\", %\"layer_norm_8\")\n",
              "            238 |  # node_layer_norm_9\n",
              "                   %\"layer_norm_9\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_436\", %\"hf_model.roberta.encoder.layer.4.attention.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.4.attention.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            239 |  # node_MatMul_392\n",
              "                   %\"val_412\"<FLOAT,[1,s53,3072]> ⬅️ ::MatMul(%\"layer_norm_9\", %\"val_411\"{...})\n",
              "            240 |  # node_linear_28\n",
              "                   %\"linear_28\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_412\", %\"hf_model.roberta.encoder.layer.4.intermediate.dense.bias\"{...})\n",
              "            241 |  # node_Div_394\n",
              "                   %\"val_414\"<FLOAT,[1,s53,3072]> ⬅️ ::Div(%\"linear_28\", %\"val_117\"{1.4142135381698608})\n",
              "            242 |  # node_Erf_395\n",
              "                   %\"val_415\"<FLOAT,[1,s53,3072]> ⬅️ ::Erf(%\"val_414\")\n",
              "            243 |  # node_Add_397\n",
              "                   %\"val_417\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_415\", %\"clone_1\"{1.0})\n",
              "            244 |  # node_Mul_399\n",
              "                   %\"val_419\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"val_122\"{0.5}, %\"val_417\")\n",
              "            245 |  # node_gelu_4\n",
              "                   %\"gelu_4\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"linear_28\", %\"val_419\")\n",
              "            246 |  # node_MatMul_401\n",
              "                   %\"val_421\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"gelu_4\", %\"val_420\"{...})\n",
              "            247 |  # node_linear_29\n",
              "                   %\"linear_29\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_421\", %\"hf_model.roberta.encoder.layer.4.output.dense.bias\"{...})\n",
              "            248 |  # node_add_455\n",
              "                   %\"add_455\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_29\", %\"layer_norm_9\")\n",
              "            249 |  # node_layer_norm_10\n",
              "                   %\"layer_norm_10\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_455\", %\"hf_model.roberta.encoder.layer.4.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.4.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            250 |  # node_MatMul_403\n",
              "                   %\"val_425\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_424\"{...})\n",
              "            251 |  # node_linear_30\n",
              "                   %\"linear_30\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_425\", %\"hf_model.roberta.encoder.layer.5.attention.self.query.bias\"{...})\n",
              "            252 |  # node_view_20\n",
              "                   %\"view_20\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_30\", %\"val_59\") {allowzero=1}\n",
              "            253 |  # node_transpose_20\n",
              "                   %\"transpose_20\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_20\") {perm=(0, 2, 1, 3)}\n",
              "            254 |  # node_MatMul_411\n",
              "                   %\"val_433\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_432\"{...})\n",
              "            255 |  # node_linear_31\n",
              "                   %\"linear_31\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_433\", %\"hf_model.roberta.encoder.layer.5.attention.self.key.bias\"{...})\n",
              "            256 |  # node_view_21\n",
              "                   %\"view_21\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_31\", %\"val_59\") {allowzero=1}\n",
              "            257 |  # node_transpose_21\n",
              "                   %\"transpose_21\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_21\") {perm=(0, 2, 1, 3)}\n",
              "            258 |  # node_MatMul_419\n",
              "                   %\"val_441\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_440\"{...})\n",
              "            259 |  # node_linear_32\n",
              "                   %\"linear_32\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_441\", %\"hf_model.roberta.encoder.layer.5.attention.self.value.bias\"{...})\n",
              "            260 |  # node_view_22\n",
              "                   %\"view_22\"<FLOAT,[1,s53,12,64]> ⬅️ ::Reshape(%\"linear_32\", %\"val_59\") {allowzero=1}\n",
              "            261 |  # node_transpose_22\n",
              "                   %\"transpose_22\"<FLOAT,[1,12,s53,64]> ⬅️ ::Transpose(%\"view_22\") {perm=(0, 2, 1, 3)}\n",
              "            262 |  # node_Shape_435\n",
              "                   %\"val_457\"<INT64,[4]> ⬅️ ::Shape(%\"transpose_21\") {start=0}\n",
              "            263 |  # node_Slice_437\n",
              "                   %\"val_459\"<INT64,[1]> ⬅️ ::Slice(%\"val_457\", %\"val_56\"{[-1]}, %\"val_86\"{[9223372036854775807]})\n",
              "            264 |  # node_Slice_438\n",
              "                   %\"val_460\"<INT64,[1]> ⬅️ ::Slice(%\"val_457\", %\"val_89\"{[-2]}, %\"val_56\"{[-1]})\n",
              "            265 |  # node_Slice_440\n",
              "                   %\"val_462\"<INT64,[2]> ⬅️ ::Slice(%\"val_457\", %\"val_91\"{[-9223372036854775808]}, %\"val_89\"{[-2]})\n",
              "            266 |  # node_Concat_442\n",
              "                   %\"val_464\"<INT64,[3]> ⬅️ ::Concat(%\"val_56\"{[-1]}, %\"val_460\", %\"val_459\") {axis=0}\n",
              "            267 |  # node_Reshape_443\n",
              "                   %\"val_465\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"transpose_21\", %\"val_464\") {allowzero=0}\n",
              "            268 |  # node_Transpose_444\n",
              "                   %\"val_466\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_465\") {perm=(0, 2, 1)}\n",
              "            269 |  # node_Concat_445\n",
              "                   %\"val_467\"<INT64,[4]> ⬅️ ::Concat(%\"val_462\", %\"val_459\", %\"val_460\") {axis=0}\n",
              "            270 |  # node_Reshape_446\n",
              "                   %\"val_468\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_466\", %\"val_467\") {allowzero=0}\n",
              "            271 |  # node_Mul_448\n",
              "                   %\"val_470\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"transpose_20\", %\"val_99\"{[0.3535533845424652]})\n",
              "            272 |  # node_Mul_450\n",
              "                   %\"val_472\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_468\", %\"val_99\"{[0.3535533845424652]})\n",
              "            273 |  # node_MatMul_451\n",
              "                   %\"val_473\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_470\", %\"val_472\")\n",
              "            274 |  # node_Add_452\n",
              "                   %\"val_474\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_473\", %\"masked_fill\")\n",
              "            275 |  # node_Softmax_453\n",
              "                   %\"val_475\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_474\") {axis=-1}\n",
              "            276 |  # node_scaled_dot_product_attention_5\n",
              "                   %\"scaled_dot_product_attention_5\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_475\", %\"transpose_22\")\n",
              "            277 |  # node_transpose_23\n",
              "                   %\"transpose_23\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_5\") {perm=(0, 2, 1, 3)}\n",
              "            278 |  # node_view_23\n",
              "                   %\"view_23\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_23\", %\"val_110\") {allowzero=1}\n",
              "            279 |  # node_MatMul_460\n",
              "                   %\"val_482\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_23\", %\"val_481\"{...})\n",
              "            280 |  # node_linear_33\n",
              "                   %\"linear_33\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_482\", %\"hf_model.roberta.encoder.layer.5.attention.output.dense.bias\"{...})\n",
              "            281 |  # node_add_508\n",
              "                   %\"add_508\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_33\", %\"layer_norm_10\")\n",
              "            282 |  # node_layer_norm_11\n",
              "                   %\"layer_norm_11\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_508\", %\"hf_model.roberta.encoder.layer.5.attention.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.5.attention.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            283 |  # node_MatMul_462\n",
              "                   %\"val_486\"<FLOAT,[1,s53,3072]> ⬅️ ::MatMul(%\"layer_norm_11\", %\"val_485\"{...})\n",
              "            284 |  # node_linear_34\n",
              "                   %\"linear_34\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_486\", %\"hf_model.roberta.encoder.layer.5.intermediate.dense.bias\"{...})\n",
              "            285 |  # node_Div_464\n",
              "                   %\"val_488\"<FLOAT,[1,s53,3072]> ⬅️ ::Div(%\"linear_34\", %\"val_117\"{1.4142135381698608})\n",
              "            286 |  # node_Erf_465\n",
              "                   %\"val_489\"<FLOAT,[1,s53,3072]> ⬅️ ::Erf(%\"val_488\")\n",
              "            287 |  # node_Add_467\n",
              "                   %\"val_491\"<FLOAT,[1,s53,3072]> ⬅️ ::Add(%\"val_489\", %\"clone_1\"{1.0})\n",
              "            288 |  # node_Mul_469\n",
              "                   %\"val_493\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"val_122\"{0.5}, %\"val_491\")\n",
              "            289 |  # node_gelu_5\n",
              "                   %\"gelu_5\"<FLOAT,[1,s53,3072]> ⬅️ ::Mul(%\"linear_34\", %\"val_493\")\n",
              "            290 |  # node_MatMul_471\n",
              "                   %\"val_495\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"gelu_5\", %\"val_494\"{...})\n",
              "            291 |  # node_linear_35\n",
              "                   %\"linear_35\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"val_495\", %\"hf_model.roberta.encoder.layer.5.output.dense.bias\"{...})\n",
              "            292 |  # node_add_527\n",
              "                   %\"add_527\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"linear_35\", %\"layer_norm_11\")\n",
              "            293 |  # node_layer_norm_12\n",
              "                   %\"layer_norm_12\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_527\", %\"hf_model.roberta.encoder.layer.5.output.LayerNorm.weight\"{...}, %\"hf_model.roberta.encoder.layer.5.output.LayerNorm.bias\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            294 |  # node_select\n",
              "                   %\"select\"<FLOAT,[1,768]> ⬅️ ::Gather(%\"layer_norm_12\", %\"val_17\"{0}) {axis=1}\n",
              "            295 |  # node_linear_36\n",
              "                   %\"linear_36\"<FLOAT,[1,768]> ⬅️ ::Gemm(%\"select\", %\"hf_model.classifier.dense.weight\"{...}, %\"hf_model.classifier.dense.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            296 |  # node_tanh\n",
              "                   %\"tanh\"<FLOAT,[1,768]> ⬅️ ::Tanh(%\"linear_36\")\n",
              "            297 |  # node_linear_37\n",
              "                   %\"logits\"<FLOAT,[1,83]> ⬅️ ::Gemm(%\"tanh\", %\"hf_model.classifier.out_proj.weight\"{...}, %\"hf_model.classifier.out_proj.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            return %\"logits\"<FLOAT,[1,83]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_hf_model_roberta_embeddings_word_embeddings_weight: \"f32[50265, 768]\", p_hf_model_roberta_embeddings_position_embeddings_weight: \"f32[514, 768]\", p_hf_model_roberta_embeddings_token_type_embeddings_weight: \"f32[1, 768]\", p_hf_model_roberta_embeddings_layernorm_weight: \"f32[768]\", p_hf_model_roberta_embeddings_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_attention_self_query_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_0_attention_self_query_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_attention_self_key_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_0_attention_self_key_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_attention_self_value_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_0_attention_self_value_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_attention_output_dense_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_0_attention_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_intermediate_dense_weight: \"f32[3072, 768]\", p_hf_model_roberta_encoder_layer_0_intermediate_dense_bias: \"f32[3072]\", p_hf_model_roberta_encoder_layer_0_output_dense_weight: \"f32[768, 3072]\", p_hf_model_roberta_encoder_layer_0_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_0_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_attention_self_query_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_1_attention_self_query_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_attention_self_key_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_1_attention_self_key_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_attention_self_value_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_1_attention_self_value_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_attention_output_dense_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_1_attention_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_intermediate_dense_weight: \"f32[3072, 768]\", p_hf_model_roberta_encoder_layer_1_intermediate_dense_bias: \"f32[3072]\", p_hf_model_roberta_encoder_layer_1_output_dense_weight: \"f32[768, 3072]\", p_hf_model_roberta_encoder_layer_1_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_1_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_attention_self_query_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_2_attention_self_query_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_attention_self_key_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_2_attention_self_key_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_attention_self_value_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_2_attention_self_value_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_attention_output_dense_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_2_attention_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_intermediate_dense_weight: \"f32[3072, 768]\", p_hf_model_roberta_encoder_layer_2_intermediate_dense_bias: \"f32[3072]\", p_hf_model_roberta_encoder_layer_2_output_dense_weight: \"f32[768, 3072]\", p_hf_model_roberta_encoder_layer_2_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_2_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_attention_self_query_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_3_attention_self_query_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_attention_self_key_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_3_attention_self_key_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_attention_self_value_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_3_attention_self_value_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_attention_output_dense_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_3_attention_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_intermediate_dense_weight: \"f32[3072, 768]\", p_hf_model_roberta_encoder_layer_3_intermediate_dense_bias: \"f32[3072]\", p_hf_model_roberta_encoder_layer_3_output_dense_weight: \"f32[768, 3072]\", p_hf_model_roberta_encoder_layer_3_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_3_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_attention_self_query_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_4_attention_self_query_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_attention_self_key_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_4_attention_self_key_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_attention_self_value_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_4_attention_self_value_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_attention_output_dense_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_4_attention_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_intermediate_dense_weight: \"f32[3072, 768]\", p_hf_model_roberta_encoder_layer_4_intermediate_dense_bias: \"f32[3072]\", p_hf_model_roberta_encoder_layer_4_output_dense_weight: \"f32[768, 3072]\", p_hf_model_roberta_encoder_layer_4_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_4_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_attention_self_query_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_5_attention_self_query_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_attention_self_key_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_5_attention_self_key_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_attention_self_value_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_5_attention_self_value_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_attention_output_dense_weight: \"f32[768, 768]\", p_hf_model_roberta_encoder_layer_5_attention_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_intermediate_dense_weight: \"f32[3072, 768]\", p_hf_model_roberta_encoder_layer_5_intermediate_dense_bias: \"f32[3072]\", p_hf_model_roberta_encoder_layer_5_output_dense_weight: \"f32[768, 3072]\", p_hf_model_roberta_encoder_layer_5_output_dense_bias: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_output_layernorm_weight: \"f32[768]\", p_hf_model_roberta_encoder_layer_5_output_layernorm_bias: \"f32[768]\", p_hf_model_classifier_dense_weight: \"f32[768, 768]\", p_hf_model_classifier_dense_bias: \"f32[768]\", p_hf_model_classifier_out_proj_weight: \"f32[83, 768]\", p_hf_model_classifier_out_proj_bias: \"f32[83]\", c_hf_model_roberta_lifted_tensor_0: \"f32[]\", b_hf_model_roberta_embeddings_position_ids: \"i64[1, 514]\", b_hf_model_roberta_embeddings_token_type_ids: \"i64[1, 514]\", input_ids: \"i64[s72, s53]\", attention_mask: \"i64[s43, s53]\"):\n",
              "                     # \n",
              "                    sym_size_int_44: \"Sym(s72)\" = torch.ops.aten.sym_size.int(input_ids, 0)\n",
              "                    sym_size_int_46: \"Sym(s43)\" = torch.ops.aten.sym_size.int(attention_mask, 0)\n",
              "                    sym_size_int_47: \"Sym(s53)\" = torch.ops.aten.sym_size.int(attention_mask, 1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:792 in forward, code: buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
              "                    slice_1: \"i64[1, s53]\" = torch.ops.aten.slice.Tensor(b_hf_model_roberta_embeddings_token_type_ids, 1, None, sym_size_int_47);  b_hf_model_roberta_embeddings_token_type_ids = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:793 in forward, code: buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
              "                    expand: \"i64[s72, s53]\" = torch.ops.aten.expand.default(slice_1, [sym_size_int_44, sym_size_int_47]);  slice_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:87 in forward, code: position_ids = create_position_ids_from_input_ids(input_ids, self.padding_idx, past_key_values_length)\n",
              "                    ne: \"b8[s72, s53]\" = torch.ops.aten.ne.Scalar(input_ids, 1)\n",
              "                    _to_copy: \"i32[s72, s53]\" = torch.ops.aten._to_copy.default(ne, dtype = torch.int32);  ne = None\n",
              "                    convert_element_type_default: \"i64[s72, s53]\" = torch.ops.prims.convert_element_type.default(_to_copy, dtype = torch.int64)\n",
              "                    cumsum: \"i64[1, s53]\" = torch.ops.aten.cumsum.default(convert_element_type_default, 1);  convert_element_type_default = None\n",
              "                    type_as: \"i32[1, s53]\" = torch.ops.aten.type_as.default(cumsum, _to_copy);  cumsum = None\n",
              "                    scalar_tensor_default: \"i32[]\" = torch.ops.aten.scalar_tensor.default(0, dtype = torch.int32)\n",
              "                    add_15: \"i32[1, s53]\" = torch.ops.aten.add.Tensor(type_as, scalar_tensor_default);  type_as = scalar_tensor_default = None\n",
              "                    mul_12: \"i32[s72, s53]\" = torch.ops.aten.mul.Tensor(add_15, _to_copy);  add_15 = _to_copy = None\n",
              "                    _to_copy_1: \"i64[s72, s53]\" = torch.ops.aten._to_copy.default(mul_12, dtype = torch.int64);  mul_12 = None\n",
              "                    add_24: \"i64[1, s53]\" = torch.ops.aten.add.Tensor(_to_copy_1, 1);  _to_copy_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:192 in forward, code: return F.embedding(\n",
              "                    embedding: \"f32[s72, s53, 768]\" = torch.ops.aten.embedding.default(p_hf_model_roberta_embeddings_word_embeddings_weight, input_ids, 1);  p_hf_model_roberta_embeddings_word_embeddings_weight = input_ids = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:192 in forward, code: return F.embedding(\n",
              "                    embedding_1: \"f32[s72, s53, 768]\" = torch.ops.aten.embedding.default(p_hf_model_roberta_embeddings_token_type_embeddings_weight, expand);  p_hf_model_roberta_embeddings_token_type_embeddings_weight = expand = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:113 in forward, code: embeddings = inputs_embeds + token_type_embeddings\n",
              "                    add_35: \"f32[s72, s53, 768]\" = torch.ops.aten.add.Tensor(embedding, embedding_1);  embedding = embedding_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:192 in forward, code: return F.embedding(\n",
              "                    embedding_2: \"f32[1, s53, 768]\" = torch.ops.aten.embedding.default(p_hf_model_roberta_embeddings_position_embeddings_weight, add_24, 1);  p_hf_model_roberta_embeddings_position_embeddings_weight = add_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:116 in forward, code: embeddings += position_embeddings\n",
              "                    add_50: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_35, embedding_2);  add_35 = embedding_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_50, [768], p_hf_model_roberta_embeddings_layernorm_weight, p_hf_model_roberta_embeddings_layernorm_bias);  add_50 = p_hf_model_roberta_embeddings_layernorm_weight = p_hf_model_roberta_embeddings_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(layer_norm);  layer_norm = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:828 in forward, code: extended_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n",
              "                    slice_2: \"i64[s43, s53]\" = torch.ops.aten.slice.Tensor(attention_mask, 0, 0, 9223372036854775807);  attention_mask = None\n",
              "                    unsqueeze: \"i64[s43, 1, s53]\" = torch.ops.aten.unsqueeze.default(slice_2, 1);  slice_2 = None\n",
              "                    unsqueeze_1: \"i64[s43, 1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 2);  unsqueeze = None\n",
              "                    slice_3: \"i64[s43, 1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_1, 3, 0, 9223372036854775807);  unsqueeze_1 = None\n",
              "                    expand_1: \"i64[s43, 1, s53, s53]\" = torch.ops.aten.expand.default(slice_3, [sym_size_int_46, 1, sym_size_int_47, sym_size_int_47]);  slice_3 = sym_size_int_46 = None\n",
              "                    _to_copy_2: \"f32[s43, 1, s53, s53]\" = torch.ops.aten._to_copy.default(expand_1, dtype = torch.float32);  expand_1 = None\n",
              "                    clone_1: \"f32[]\" = torch.ops.aten.clone.default(c_hf_model_roberta_lifted_tensor_0);  c_hf_model_roberta_lifted_tensor_0 = None\n",
              "                    sub_42: \"f32[s43, 1, s53, s53]\" = torch.ops.aten.sub.Tensor(clone_1, _to_copy_2);  clone_1 = _to_copy_2 = None\n",
              "                    _to_copy_3: \"b8[s43, 1, s53, s53]\" = torch.ops.aten._to_copy.default(sub_42, dtype = torch.bool)\n",
              "                    masked_fill: \"f32[s43, 1, s53, s53]\" = torch.ops.aten.masked_fill.Scalar(sub_42, _to_copy_3, -3.4028234663852886e+38);  sub_42 = _to_copy_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone, p_hf_model_roberta_encoder_layer_0_attention_self_query_weight, p_hf_model_roberta_encoder_layer_0_attention_self_query_bias);  p_hf_model_roberta_encoder_layer_0_attention_self_query_weight = p_hf_model_roberta_encoder_layer_0_attention_self_query_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:313 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
              "                    view: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear, [sym_size_int_44, -1, 12, 64]);  linear = None\n",
              "                    transpose: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view, 1, 2);  view = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_1: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone, p_hf_model_roberta_encoder_layer_0_attention_self_key_weight, p_hf_model_roberta_encoder_layer_0_attention_self_key_bias);  p_hf_model_roberta_encoder_layer_0_attention_self_key_weight = p_hf_model_roberta_encoder_layer_0_attention_self_key_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:338 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_1: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_1, [sym_size_int_44, -1, 12, 64]);  linear_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:339 in forward, code: .transpose(1, 2)\n",
              "                    transpose_1: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_1, 1, 2);  view_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_2: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone, p_hf_model_roberta_encoder_layer_0_attention_self_value_weight, p_hf_model_roberta_encoder_layer_0_attention_self_value_bias);  p_hf_model_roberta_encoder_layer_0_attention_self_value_weight = p_hf_model_roberta_encoder_layer_0_attention_self_value_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:343 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_2: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_2, [sym_size_int_44, -1, 12, 64]);  linear_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:344 in forward, code: .transpose(1, 2)\n",
              "                    transpose_2: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_2, 1, 2);  view_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:363 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
              "                    scaled_dot_product_attention: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose, transpose_1, transpose_2, masked_fill);  transpose = transpose_1 = transpose_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:372 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
              "                    transpose_3: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:373 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
              "                    view_3: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_3, [sym_size_int_44, sym_size_int_47, 768]);  transpose_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_3: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_3, p_hf_model_roberta_encoder_layer_0_attention_output_dense_weight, p_hf_model_roberta_encoder_layer_0_attention_output_dense_bias);  view_3 = p_hf_model_roberta_encoder_layer_0_attention_output_dense_weight = p_hf_model_roberta_encoder_layer_0_attention_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_2: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_3);  linear_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:389 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_148: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_2, clone);  clone_2 = clone = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_1: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_148, [768], p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_weight, p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_bias);  add_148 = p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_weight = p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_4: \"f32[1, s53, 3072]\" = torch.ops.aten.linear.default(layer_norm_1, p_hf_model_roberta_encoder_layer_0_intermediate_dense_weight, p_hf_model_roberta_encoder_layer_0_intermediate_dense_bias);  p_hf_model_roberta_encoder_layer_0_intermediate_dense_weight = p_hf_model_roberta_encoder_layer_0_intermediate_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu: \"f32[1, s53, 3072]\" = torch.ops.aten.gelu.default(linear_4);  linear_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_5: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(gelu, p_hf_model_roberta_encoder_layer_0_output_dense_weight, p_hf_model_roberta_encoder_layer_0_output_dense_bias);  gelu = p_hf_model_roberta_encoder_layer_0_output_dense_weight = p_hf_model_roberta_encoder_layer_0_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_3: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_5);  linear_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:481 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_167: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_3, layer_norm_1);  clone_3 = layer_norm_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_2: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_167, [768], p_hf_model_roberta_encoder_layer_0_output_layernorm_weight, p_hf_model_roberta_encoder_layer_0_output_layernorm_bias);  add_167 = p_hf_model_roberta_encoder_layer_0_output_layernorm_weight = p_hf_model_roberta_encoder_layer_0_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_6: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_hf_model_roberta_encoder_layer_1_attention_self_query_weight, p_hf_model_roberta_encoder_layer_1_attention_self_query_bias);  p_hf_model_roberta_encoder_layer_1_attention_self_query_weight = p_hf_model_roberta_encoder_layer_1_attention_self_query_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:313 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
              "                    view_4: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_6, [sym_size_int_44, -1, 12, 64]);  linear_6 = None\n",
              "                    transpose_4: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_4, 1, 2);  view_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_7: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_hf_model_roberta_encoder_layer_1_attention_self_key_weight, p_hf_model_roberta_encoder_layer_1_attention_self_key_bias);  p_hf_model_roberta_encoder_layer_1_attention_self_key_weight = p_hf_model_roberta_encoder_layer_1_attention_self_key_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:338 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_5: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_7, [sym_size_int_44, -1, 12, 64]);  linear_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:339 in forward, code: .transpose(1, 2)\n",
              "                    transpose_5: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_5, 1, 2);  view_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_8: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_2, p_hf_model_roberta_encoder_layer_1_attention_self_value_weight, p_hf_model_roberta_encoder_layer_1_attention_self_value_bias);  p_hf_model_roberta_encoder_layer_1_attention_self_value_weight = p_hf_model_roberta_encoder_layer_1_attention_self_value_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:343 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_6: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_8, [sym_size_int_44, -1, 12, 64]);  linear_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:344 in forward, code: .transpose(1, 2)\n",
              "                    transpose_6: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_6, 1, 2);  view_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:363 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
              "                    scaled_dot_product_attention_1: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_4, transpose_5, transpose_6, masked_fill);  transpose_4 = transpose_5 = transpose_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:372 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
              "                    transpose_7: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_1, 1, 2);  scaled_dot_product_attention_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:373 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
              "                    view_7: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_7, [sym_size_int_44, sym_size_int_47, 768]);  transpose_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_9: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_7, p_hf_model_roberta_encoder_layer_1_attention_output_dense_weight, p_hf_model_roberta_encoder_layer_1_attention_output_dense_bias);  view_7 = p_hf_model_roberta_encoder_layer_1_attention_output_dense_weight = p_hf_model_roberta_encoder_layer_1_attention_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_4: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_9);  linear_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:389 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_220: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_4, layer_norm_2);  clone_4 = layer_norm_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_3: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_220, [768], p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_weight, p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_bias);  add_220 = p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_weight = p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_10: \"f32[1, s53, 3072]\" = torch.ops.aten.linear.default(layer_norm_3, p_hf_model_roberta_encoder_layer_1_intermediate_dense_weight, p_hf_model_roberta_encoder_layer_1_intermediate_dense_bias);  p_hf_model_roberta_encoder_layer_1_intermediate_dense_weight = p_hf_model_roberta_encoder_layer_1_intermediate_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_1: \"f32[1, s53, 3072]\" = torch.ops.aten.gelu.default(linear_10);  linear_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_11: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(gelu_1, p_hf_model_roberta_encoder_layer_1_output_dense_weight, p_hf_model_roberta_encoder_layer_1_output_dense_bias);  gelu_1 = p_hf_model_roberta_encoder_layer_1_output_dense_weight = p_hf_model_roberta_encoder_layer_1_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_5: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_11);  linear_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:481 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_239: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_5, layer_norm_3);  clone_5 = layer_norm_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_4: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_239, [768], p_hf_model_roberta_encoder_layer_1_output_layernorm_weight, p_hf_model_roberta_encoder_layer_1_output_layernorm_bias);  add_239 = p_hf_model_roberta_encoder_layer_1_output_layernorm_weight = p_hf_model_roberta_encoder_layer_1_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_12: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_hf_model_roberta_encoder_layer_2_attention_self_query_weight, p_hf_model_roberta_encoder_layer_2_attention_self_query_bias);  p_hf_model_roberta_encoder_layer_2_attention_self_query_weight = p_hf_model_roberta_encoder_layer_2_attention_self_query_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:313 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
              "                    view_8: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_12, [sym_size_int_44, -1, 12, 64]);  linear_12 = None\n",
              "                    transpose_8: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_8, 1, 2);  view_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_13: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_hf_model_roberta_encoder_layer_2_attention_self_key_weight, p_hf_model_roberta_encoder_layer_2_attention_self_key_bias);  p_hf_model_roberta_encoder_layer_2_attention_self_key_weight = p_hf_model_roberta_encoder_layer_2_attention_self_key_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:338 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_9: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_13, [sym_size_int_44, -1, 12, 64]);  linear_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:339 in forward, code: .transpose(1, 2)\n",
              "                    transpose_9: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_9, 1, 2);  view_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_14: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_4, p_hf_model_roberta_encoder_layer_2_attention_self_value_weight, p_hf_model_roberta_encoder_layer_2_attention_self_value_bias);  p_hf_model_roberta_encoder_layer_2_attention_self_value_weight = p_hf_model_roberta_encoder_layer_2_attention_self_value_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:343 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_10: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_14, [sym_size_int_44, -1, 12, 64]);  linear_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:344 in forward, code: .transpose(1, 2)\n",
              "                    transpose_10: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_10, 1, 2);  view_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:363 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
              "                    scaled_dot_product_attention_2: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_8, transpose_9, transpose_10, masked_fill);  transpose_8 = transpose_9 = transpose_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:372 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
              "                    transpose_11: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_2, 1, 2);  scaled_dot_product_attention_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:373 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
              "                    view_11: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_11, [sym_size_int_44, sym_size_int_47, 768]);  transpose_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_15: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_11, p_hf_model_roberta_encoder_layer_2_attention_output_dense_weight, p_hf_model_roberta_encoder_layer_2_attention_output_dense_bias);  view_11 = p_hf_model_roberta_encoder_layer_2_attention_output_dense_weight = p_hf_model_roberta_encoder_layer_2_attention_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_6: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_15);  linear_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:389 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_292: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_6, layer_norm_4);  clone_6 = layer_norm_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_5: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_292, [768], p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_weight, p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_bias);  add_292 = p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_weight = p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_16: \"f32[1, s53, 3072]\" = torch.ops.aten.linear.default(layer_norm_5, p_hf_model_roberta_encoder_layer_2_intermediate_dense_weight, p_hf_model_roberta_encoder_layer_2_intermediate_dense_bias);  p_hf_model_roberta_encoder_layer_2_intermediate_dense_weight = p_hf_model_roberta_encoder_layer_2_intermediate_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_2: \"f32[1, s53, 3072]\" = torch.ops.aten.gelu.default(linear_16);  linear_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_17: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(gelu_2, p_hf_model_roberta_encoder_layer_2_output_dense_weight, p_hf_model_roberta_encoder_layer_2_output_dense_bias);  gelu_2 = p_hf_model_roberta_encoder_layer_2_output_dense_weight = p_hf_model_roberta_encoder_layer_2_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_7: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_17);  linear_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:481 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_311: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_7, layer_norm_5);  clone_7 = layer_norm_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_6: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_311, [768], p_hf_model_roberta_encoder_layer_2_output_layernorm_weight, p_hf_model_roberta_encoder_layer_2_output_layernorm_bias);  add_311 = p_hf_model_roberta_encoder_layer_2_output_layernorm_weight = p_hf_model_roberta_encoder_layer_2_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_18: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_hf_model_roberta_encoder_layer_3_attention_self_query_weight, p_hf_model_roberta_encoder_layer_3_attention_self_query_bias);  p_hf_model_roberta_encoder_layer_3_attention_self_query_weight = p_hf_model_roberta_encoder_layer_3_attention_self_query_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:313 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
              "                    view_12: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_18, [sym_size_int_44, -1, 12, 64]);  linear_18 = None\n",
              "                    transpose_12: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_12, 1, 2);  view_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_19: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_hf_model_roberta_encoder_layer_3_attention_self_key_weight, p_hf_model_roberta_encoder_layer_3_attention_self_key_bias);  p_hf_model_roberta_encoder_layer_3_attention_self_key_weight = p_hf_model_roberta_encoder_layer_3_attention_self_key_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:338 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_13: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_19, [sym_size_int_44, -1, 12, 64]);  linear_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:339 in forward, code: .transpose(1, 2)\n",
              "                    transpose_13: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_13, 1, 2);  view_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_20: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_6, p_hf_model_roberta_encoder_layer_3_attention_self_value_weight, p_hf_model_roberta_encoder_layer_3_attention_self_value_bias);  p_hf_model_roberta_encoder_layer_3_attention_self_value_weight = p_hf_model_roberta_encoder_layer_3_attention_self_value_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:343 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_14: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_20, [sym_size_int_44, -1, 12, 64]);  linear_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:344 in forward, code: .transpose(1, 2)\n",
              "                    transpose_14: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_14, 1, 2);  view_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:363 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
              "                    scaled_dot_product_attention_3: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_12, transpose_13, transpose_14, masked_fill);  transpose_12 = transpose_13 = transpose_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:372 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
              "                    transpose_15: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_3, 1, 2);  scaled_dot_product_attention_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:373 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
              "                    view_15: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_15, [sym_size_int_44, sym_size_int_47, 768]);  transpose_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_21: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_15, p_hf_model_roberta_encoder_layer_3_attention_output_dense_weight, p_hf_model_roberta_encoder_layer_3_attention_output_dense_bias);  view_15 = p_hf_model_roberta_encoder_layer_3_attention_output_dense_weight = p_hf_model_roberta_encoder_layer_3_attention_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_8: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_21);  linear_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:389 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_364: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_8, layer_norm_6);  clone_8 = layer_norm_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_7: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_364, [768], p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_weight, p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_bias);  add_364 = p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_weight = p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_22: \"f32[1, s53, 3072]\" = torch.ops.aten.linear.default(layer_norm_7, p_hf_model_roberta_encoder_layer_3_intermediate_dense_weight, p_hf_model_roberta_encoder_layer_3_intermediate_dense_bias);  p_hf_model_roberta_encoder_layer_3_intermediate_dense_weight = p_hf_model_roberta_encoder_layer_3_intermediate_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_3: \"f32[1, s53, 3072]\" = torch.ops.aten.gelu.default(linear_22);  linear_22 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_23: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(gelu_3, p_hf_model_roberta_encoder_layer_3_output_dense_weight, p_hf_model_roberta_encoder_layer_3_output_dense_bias);  gelu_3 = p_hf_model_roberta_encoder_layer_3_output_dense_weight = p_hf_model_roberta_encoder_layer_3_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_9: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_23);  linear_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:481 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_383: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_9, layer_norm_7);  clone_9 = layer_norm_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_8: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_383, [768], p_hf_model_roberta_encoder_layer_3_output_layernorm_weight, p_hf_model_roberta_encoder_layer_3_output_layernorm_bias);  add_383 = p_hf_model_roberta_encoder_layer_3_output_layernorm_weight = p_hf_model_roberta_encoder_layer_3_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_24: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_hf_model_roberta_encoder_layer_4_attention_self_query_weight, p_hf_model_roberta_encoder_layer_4_attention_self_query_bias);  p_hf_model_roberta_encoder_layer_4_attention_self_query_weight = p_hf_model_roberta_encoder_layer_4_attention_self_query_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:313 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
              "                    view_16: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_24, [sym_size_int_44, -1, 12, 64]);  linear_24 = None\n",
              "                    transpose_16: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_16, 1, 2);  view_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_25: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_hf_model_roberta_encoder_layer_4_attention_self_key_weight, p_hf_model_roberta_encoder_layer_4_attention_self_key_bias);  p_hf_model_roberta_encoder_layer_4_attention_self_key_weight = p_hf_model_roberta_encoder_layer_4_attention_self_key_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:338 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_17: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_25, [sym_size_int_44, -1, 12, 64]);  linear_25 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:339 in forward, code: .transpose(1, 2)\n",
              "                    transpose_17: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_17, 1, 2);  view_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_26: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_8, p_hf_model_roberta_encoder_layer_4_attention_self_value_weight, p_hf_model_roberta_encoder_layer_4_attention_self_value_bias);  p_hf_model_roberta_encoder_layer_4_attention_self_value_weight = p_hf_model_roberta_encoder_layer_4_attention_self_value_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:343 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_18: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_26, [sym_size_int_44, -1, 12, 64]);  linear_26 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:344 in forward, code: .transpose(1, 2)\n",
              "                    transpose_18: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_18, 1, 2);  view_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:363 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
              "                    scaled_dot_product_attention_4: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_16, transpose_17, transpose_18, masked_fill);  transpose_16 = transpose_17 = transpose_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:372 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
              "                    transpose_19: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_4, 1, 2);  scaled_dot_product_attention_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:373 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
              "                    view_19: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_19, [sym_size_int_44, sym_size_int_47, 768]);  transpose_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_27: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_19, p_hf_model_roberta_encoder_layer_4_attention_output_dense_weight, p_hf_model_roberta_encoder_layer_4_attention_output_dense_bias);  view_19 = p_hf_model_roberta_encoder_layer_4_attention_output_dense_weight = p_hf_model_roberta_encoder_layer_4_attention_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_10: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_27);  linear_27 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:389 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_436: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_10, layer_norm_8);  clone_10 = layer_norm_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_9: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_436, [768], p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_weight, p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_bias);  add_436 = p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_weight = p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_28: \"f32[1, s53, 3072]\" = torch.ops.aten.linear.default(layer_norm_9, p_hf_model_roberta_encoder_layer_4_intermediate_dense_weight, p_hf_model_roberta_encoder_layer_4_intermediate_dense_bias);  p_hf_model_roberta_encoder_layer_4_intermediate_dense_weight = p_hf_model_roberta_encoder_layer_4_intermediate_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_4: \"f32[1, s53, 3072]\" = torch.ops.aten.gelu.default(linear_28);  linear_28 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_29: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(gelu_4, p_hf_model_roberta_encoder_layer_4_output_dense_weight, p_hf_model_roberta_encoder_layer_4_output_dense_bias);  gelu_4 = p_hf_model_roberta_encoder_layer_4_output_dense_weight = p_hf_model_roberta_encoder_layer_4_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_11: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_29);  linear_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:481 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_455: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_11, layer_norm_9);  clone_11 = layer_norm_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_10: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_455, [768], p_hf_model_roberta_encoder_layer_4_output_layernorm_weight, p_hf_model_roberta_encoder_layer_4_output_layernorm_bias);  add_455 = p_hf_model_roberta_encoder_layer_4_output_layernorm_weight = p_hf_model_roberta_encoder_layer_4_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_30: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_hf_model_roberta_encoder_layer_5_attention_self_query_weight, p_hf_model_roberta_encoder_layer_5_attention_self_query_bias);  p_hf_model_roberta_encoder_layer_5_attention_self_query_weight = p_hf_model_roberta_encoder_layer_5_attention_self_query_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:313 in forward, code: self.query(hidden_states).view(bsz, -1, self.num_attention_heads, self.attention_head_size).transpose(1, 2)\n",
              "                    view_20: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_30, [sym_size_int_44, -1, 12, 64]);  linear_30 = None\n",
              "                    transpose_20: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_20, 1, 2);  view_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_31: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_hf_model_roberta_encoder_layer_5_attention_self_key_weight, p_hf_model_roberta_encoder_layer_5_attention_self_key_bias);  p_hf_model_roberta_encoder_layer_5_attention_self_key_weight = p_hf_model_roberta_encoder_layer_5_attention_self_key_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:338 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_21: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_31, [sym_size_int_44, -1, 12, 64]);  linear_31 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:339 in forward, code: .transpose(1, 2)\n",
              "                    transpose_21: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_21, 1, 2);  view_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_32: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(layer_norm_10, p_hf_model_roberta_encoder_layer_5_attention_self_value_weight, p_hf_model_roberta_encoder_layer_5_attention_self_value_bias);  p_hf_model_roberta_encoder_layer_5_attention_self_value_weight = p_hf_model_roberta_encoder_layer_5_attention_self_value_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:343 in forward, code: .view(bsz, -1, self.num_attention_heads, self.attention_head_size)\n",
              "                    view_22: \"f32[1, s53, 12, 64]\" = torch.ops.aten.view.default(linear_32, [sym_size_int_44, -1, 12, 64]);  linear_32 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:344 in forward, code: .transpose(1, 2)\n",
              "                    transpose_22: \"f32[1, 12, s53, 64]\" = torch.ops.aten.transpose.int(view_22, 1, 2);  view_22 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:363 in forward, code: attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
              "                    scaled_dot_product_attention_5: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(transpose_20, transpose_21, transpose_22, masked_fill);  transpose_20 = transpose_21 = transpose_22 = masked_fill = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:372 in forward, code: attn_output = attn_output.transpose(1, 2)\n",
              "                    transpose_23: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_5, 1, 2);  scaled_dot_product_attention_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:373 in forward, code: attn_output = attn_output.reshape(bsz, tgt_len, self.all_head_size)\n",
              "                    view_23: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_23, [sym_size_int_44, sym_size_int_47, 768]);  transpose_23 = sym_size_int_44 = sym_size_int_47 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_33: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_23, p_hf_model_roberta_encoder_layer_5_attention_output_dense_weight, p_hf_model_roberta_encoder_layer_5_attention_output_dense_bias);  view_23 = p_hf_model_roberta_encoder_layer_5_attention_output_dense_weight = p_hf_model_roberta_encoder_layer_5_attention_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_12: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_33);  linear_33 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:389 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_508: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_12, layer_norm_10);  clone_12 = layer_norm_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_11: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_508, [768], p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_weight, p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_bias);  add_508 = p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_weight = p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_34: \"f32[1, s53, 3072]\" = torch.ops.aten.linear.default(layer_norm_11, p_hf_model_roberta_encoder_layer_5_intermediate_dense_weight, p_hf_model_roberta_encoder_layer_5_intermediate_dense_bias);  p_hf_model_roberta_encoder_layer_5_intermediate_dense_weight = p_hf_model_roberta_encoder_layer_5_intermediate_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_5: \"f32[1, s53, 3072]\" = torch.ops.aten.gelu.default(linear_34);  linear_34 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_35: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(gelu_5, p_hf_model_roberta_encoder_layer_5_output_dense_weight, p_hf_model_roberta_encoder_layer_5_output_dense_bias);  gelu_5 = p_hf_model_roberta_encoder_layer_5_output_dense_weight = p_hf_model_roberta_encoder_layer_5_output_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_13: \"f32[1, s53, 768]\" = torch.ops.aten.clone.default(linear_35);  linear_35 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:481 in forward, code: hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
              "                    add_527: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(clone_13, layer_norm_11);  clone_13 = layer_norm_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_12: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_527, [768], p_hf_model_roberta_encoder_layer_5_output_layernorm_weight, p_hf_model_roberta_encoder_layer_5_output_layernorm_bias);  add_527 = p_hf_model_roberta_encoder_layer_5_output_layernorm_weight = p_hf_model_roberta_encoder_layer_5_output_layernorm_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:1439 in forward, code: x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
              "                    slice_4: \"f32[1, s53, 768]\" = torch.ops.aten.slice.Tensor(layer_norm_12, 0, 0, 9223372036854775807);  layer_norm_12 = None\n",
              "                    select: \"f32[1, 768]\" = torch.ops.aten.select.int(slice_4, 1, 0);  slice_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_14: \"f32[1, 768]\" = torch.ops.aten.clone.default(select);  select = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_36: \"f32[1, 768]\" = torch.ops.aten.linear.default(clone_14, p_hf_model_classifier_dense_weight, p_hf_model_classifier_dense_bias);  clone_14 = p_hf_model_classifier_dense_weight = p_hf_model_classifier_dense_bias = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/roberta/modeling_roberta.py:1442 in forward, code: x = torch.tanh(x)\n",
              "                    tanh: \"f32[1, 768]\" = torch.ops.aten.tanh.default(linear_36);  linear_36 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_15: \"f32[1, 768]\" = torch.ops.aten.clone.default(tanh);  tanh = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_37: \"f32[1, 83]\" = torch.ops.aten.linear.default(clone_15, p_hf_model_classifier_out_proj_weight, p_hf_model_classifier_out_proj_bias);  clone_15 = p_hf_model_classifier_out_proj_weight = p_hf_model_classifier_out_proj_bias = None\n",
              "                    return (linear_37,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_hf_model_roberta_embeddings_word_embeddings_weight: PARAMETER target='hf_model.roberta.embeddings.word_embeddings.weight'\n",
              "            p_hf_model_roberta_embeddings_position_embeddings_weight: PARAMETER target='hf_model.roberta.embeddings.position_embeddings.weight'\n",
              "            p_hf_model_roberta_embeddings_token_type_embeddings_weight: PARAMETER target='hf_model.roberta.embeddings.token_type_embeddings.weight'\n",
              "            p_hf_model_roberta_embeddings_layernorm_weight: PARAMETER target='hf_model.roberta.embeddings.LayerNorm.weight'\n",
              "            p_hf_model_roberta_embeddings_layernorm_bias: PARAMETER target='hf_model.roberta.embeddings.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_self_query_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.self.query.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_self_query_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.self.query.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_self_key_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.self.key.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_self_key_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.self.key.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_self_value_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.self.value.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_self_value_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.self.value.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_attention_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.attention.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_intermediate_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.intermediate.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_intermediate_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.intermediate.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_0_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.0.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_0_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.0.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_self_query_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.self.query.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_self_query_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.self.query.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_self_key_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.self.key.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_self_key_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.self.key.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_self_value_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.self.value.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_self_value_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.self.value.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_attention_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.attention.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_intermediate_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.intermediate.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_intermediate_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.intermediate.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_1_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.1.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_1_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.1.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_self_query_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.self.query.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_self_query_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.self.query.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_self_key_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.self.key.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_self_key_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.self.key.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_self_value_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.self.value.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_self_value_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.self.value.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_attention_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.attention.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_intermediate_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.intermediate.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_intermediate_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.intermediate.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_2_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.2.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_2_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.2.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_self_query_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.self.query.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_self_query_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.self.query.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_self_key_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.self.key.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_self_key_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.self.key.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_self_value_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.self.value.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_self_value_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.self.value.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_attention_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.attention.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_intermediate_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.intermediate.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_intermediate_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.intermediate.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_3_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.3.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_3_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.3.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_self_query_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.self.query.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_self_query_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.self.query.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_self_key_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.self.key.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_self_key_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.self.key.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_self_value_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.self.value.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_self_value_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.self.value.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_attention_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.attention.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_intermediate_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.intermediate.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_intermediate_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.intermediate.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_4_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.4.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_4_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.4.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_self_query_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.self.query.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_self_query_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.self.query.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_self_key_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.self.key.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_self_key_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.self.key.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_self_value_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.self.value.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_self_value_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.self.value.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_attention_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.attention.output.LayerNorm.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_intermediate_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.intermediate.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_intermediate_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.intermediate.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_output_dense_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.output.dense.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_output_dense_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.output.dense.bias'\n",
              "            p_hf_model_roberta_encoder_layer_5_output_layernorm_weight: PARAMETER target='hf_model.roberta.encoder.layer.5.output.LayerNorm.weight'\n",
              "            p_hf_model_roberta_encoder_layer_5_output_layernorm_bias: PARAMETER target='hf_model.roberta.encoder.layer.5.output.LayerNorm.bias'\n",
              "            p_hf_model_classifier_dense_weight: PARAMETER target='hf_model.classifier.dense.weight'\n",
              "            p_hf_model_classifier_dense_bias: PARAMETER target='hf_model.classifier.dense.bias'\n",
              "            p_hf_model_classifier_out_proj_weight: PARAMETER target='hf_model.classifier.out_proj.weight'\n",
              "            p_hf_model_classifier_out_proj_bias: PARAMETER target='hf_model.classifier.out_proj.bias'\n",
              "            c_hf_model_roberta_lifted_tensor_0: CONSTANT_TENSOR target='hf_model.roberta.lifted_tensor_0'\n",
              "            b_hf_model_roberta_embeddings_position_ids: BUFFER target='hf_model.roberta.embeddings.position_ids' persistent=False\n",
              "            b_hf_model_roberta_embeddings_token_type_ids: BUFFER target='hf_model.roberta.embeddings.token_type_ids' persistent=False\n",
              "            input_ids: USER_INPUT\n",
              "            attention_mask: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            linear_37: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {s72: VR[0, int_oo], s53: VR[0, 514], s43: VR[1, 2]}\n",
              "\n",
              ")"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = learner_inf.model.hf_model.eval()\n",
        "\n",
        "class SkillClassifierModel(torch.nn.Module):\n",
        "    def __init__(self, hf_model):\n",
        "        super().__init__()\n",
        "        self.hf_model = hf_model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        output = self.hf_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return output.logits\n",
        "\n",
        "wrapped_model = SkillClassifierModel(learner_inf.model.hf_model)\n",
        "\n",
        "dummy_input_ids = torch.LongTensor([[0] * 512])\n",
        "dummy_attention_mask = torch.LongTensor([[1] * 512])\n",
        "\n",
        "torch.onnx.export(\n",
        "    wrapped_model,\n",
        "    (dummy_input_ids, dummy_attention_mask),\n",
        "    '/content/drive/MyDrive/Data Science/CP3_Skill Classifier/models/skill-classifier.onnx',\n",
        "    verbose=True,\n",
        "    input_names=['input_ids', 'attention_mask'],\n",
        "    output_names=['logits'],\n",
        "    opset_version=18,\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch_size', 1: 'sequence_len'},\n",
        "        'attention_mask': {0: 'batch_size', 1: 'sequence_len'},\n",
        "        'logits': {0: 'batch_size'}\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sXOrjJm3f8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1b60b1ca-d2bd-435e-bbc0-74e53b4091fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxscript in /usr/local/lib/python3.12/dist-packages (0.5.7)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Requirement already satisfied: onnx_ir<2,>=0.1.12 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.1.14)\n",
            "Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n",
            "[torch.onnx] Obtain model graph for `ModernBertForSequenceClassification([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ModernBertForSequenceClassification([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n",
            "Applied 117 of general pattern rewrite rules.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ONNXProgram(\n",
              "    model=\n",
              "        <\n",
              "            ir_version=10,\n",
              "            opset_imports={'': 18},\n",
              "            producer_name='pytorch',\n",
              "            producer_version='2.9.0+cu126',\n",
              "            domain=None,\n",
              "            model_version=None,\n",
              "        >\n",
              "        graph(\n",
              "            name=main_graph,\n",
              "            inputs=(\n",
              "                %\"input_ids\"<INT64,[s72,s53]>,\n",
              "                %\"attention_mask\"<INT64,[s43,s53]>\n",
              "            ),\n",
              "            outputs=(\n",
              "                %\"logits\"<FLOAT,[1,83]>\n",
              "            ),\n",
              "            initializers=(\n",
              "                %\"model.embeddings.tok_embeddings.weight\"<FLOAT,[50368,768]>{TorchTensor(...)},\n",
              "                %\"model.embeddings.norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.0.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.1.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.1.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.2.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.2.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.3.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.3.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.4.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.4.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.5.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.5.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.6.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.6.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.7.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.7.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.8.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.8.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.9.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.9.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.10.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.10.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.11.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.11.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.12.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.12.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.13.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.13.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.14.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.14.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.15.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.15.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.16.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.16.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.17.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.17.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.18.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.18.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.19.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.19.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.20.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.20.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.21.attn_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.layers.21.mlp_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"model.final_norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"head.dense.weight\"<FLOAT,[768,768]>{TorchTensor(...)},\n",
              "                %\"head.norm.weight\"<FLOAT,[768]>{TorchTensor(...)},\n",
              "                %\"classifier.weight\"<FLOAT,[83,768]>{TorchTensor(...)},\n",
              "                %\"classifier.bias\"<FLOAT,[83]>{TorchTensor(...)},\n",
              "                %\"val_4\"<INT64,[]>{Tensor<INT64,[]>(array(0), name='val_4')},\n",
              "                %\"val_6\"<INT64,[]>{Tensor<INT64,[]>(array(1), name='val_6')},\n",
              "                %\"clone\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1., dtype=float32), name='clone')},\n",
              "                %\"val_40\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(-3.4028235e+38, dtype=float32), name='val_40')},\n",
              "                %\"val_47\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"expand_1\"<FLOAT,[1,32,1]>{Tensor(...)},\n",
              "                %\"val_85\"<INT64,[1]>{Tensor<INT64,[1]>(array([0]), name='val_85')},\n",
              "                %\"val_89\"<INT64,[1]>{Tensor<INT64,[1]>(array([32]), name='val_89')},\n",
              "                %\"val_92\"<INT64,[1]>{Tensor<INT64,[1]>(array([3]), name='val_92')},\n",
              "                %\"val_99\"<INT64,[1]>{Tensor<INT64,[1]>(array([9223372036854775807]), name='val_99')},\n",
              "                %\"val_147\"<FLOAT,[1]>{Tensor<FLOAT,[1]>(array([0.35355338], dtype=float32), name='val_147')},\n",
              "                %\"val_159\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_162\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_172\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_175\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"expand_2\"<FLOAT,[1,32,1]>{Tensor(...)},\n",
              "                %\"val_283\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_286\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_294\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_297\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_405\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_408\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_416\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_419\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_527\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_530\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_538\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_541\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_649\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_652\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_660\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_663\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_771\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_774\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_782\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_785\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_893\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_896\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_904\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_907\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1015\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1018\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1026\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1029\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1137\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1140\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1148\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1151\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1259\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1262\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1270\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1273\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1381\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1384\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1392\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1395\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1503\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1506\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1514\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1517\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1625\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1628\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1636\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1639\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1747\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1750\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1758\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1761\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1869\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1872\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1880\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_1883\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_1991\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_1994\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2002\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2005\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2113\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_2116\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2124\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2127\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2235\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_2238\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2246\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2249\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2357\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_2360\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2368\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2371\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2479\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_2482\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2490\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2493\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2601\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_2604\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2612\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2615\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2723\"<FLOAT,[768,768]>{Tensor(...)},\n",
              "                %\"val_2726\"<FLOAT,[768,2304]>{Tensor(...)},\n",
              "                %\"val_2734\"<FLOAT,[1152,768]>{Tensor(...)},\n",
              "                %\"val_2739\"<INT64,[1]>{Tensor<INT64,[1]>(array([1]), name='val_2739')},\n",
              "                %\"val_21\"<INT64,[1]>{Tensor<INT64,[1]>(array([2]), name='val_21')},\n",
              "                %\"val_2752\"<INT64,[2]>{Tensor<INT64,[2]>(array([1, 2]), name='val_2752')},\n",
              "                %\"val_43\"<INT64,[]>{Tensor<INT64,[]>(array(64), name='val_43')},\n",
              "                %\"val_2753\"<INT64,[2]>{Tensor<INT64,[2]>(array([0, 1]), name='val_2753')},\n",
              "                %\"val_50\"<INT64,[1]>{Tensor<INT64,[1]>(array([-1]), name='val_50')},\n",
              "                %\"val_52\"<INT64,[1]>{Tensor<INT64,[1]>(array([12]), name='val_52')},\n",
              "                %\"val_53\"<INT64,[1]>{Tensor<INT64,[1]>(array([64]), name='val_53')},\n",
              "                %\"val_137\"<INT64,[1]>{Tensor<INT64,[1]>(array([-2]), name='val_137')},\n",
              "                %\"val_139\"<INT64,[1]>{Tensor<INT64,[1]>(array([-9223372036854775808]), name='val_139')},\n",
              "                %\"val_157\"<INT64,[1]>{Tensor<INT64,[1]>(array([768]), name='val_157')},\n",
              "                %\"val_165\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(1.4142135, dtype=float32), name='val_165')},\n",
              "                %\"val_170\"<FLOAT,[]>{Tensor<FLOAT,[]>(array(0.5, dtype=float32), name='val_170')}\n",
              "            ),\n",
              "        ) {\n",
              "               0 |  # node_Shape_0\n",
              "                    %\"val_0\"<INT64,[1]> ⬅️ ::Shape(%\"input_ids\") {end=1, start=0}\n",
              "               1 |  # node_Shape_1\n",
              "                    %\"val_1\"<INT64,[1]> ⬅️ ::Shape(%\"attention_mask\") {end=1, start=0}\n",
              "               2 |  # node_Shape_2\n",
              "                    %\"val_2\"<INT64,[1]> ⬅️ ::Shape(%\"attention_mask\") {end=2, start=1}\n",
              "               3 |  # node_sym_size_int_121\n",
              "                    %\"sym_size_int_121\"<INT64,[]> ⬅️ ::Squeeze(%\"val_2\")\n",
              "               4 |  # node_arange\n",
              "                    %\"arange\"<INT64,[s53]> ⬅️ ::Range(%\"val_4\"{0}, %\"sym_size_int_121\", %\"val_6\"{1})\n",
              "               5 |  # node_unsqueeze\n",
              "                    %\"unsqueeze\"<INT64,[1,s53]> ⬅️ ::Unsqueeze(%\"arange\", %\"val_85\"{[0]})\n",
              "               6 |  # node_Unsqueeze_3182\n",
              "                    %\"unsqueeze_2\"<INT64,[s43,1,1,s53]> ⬅️ ::Unsqueeze(%\"attention_mask\", %\"val_2752\"{[1, 2]})\n",
              "               7 |  # node_Concat_38\n",
              "                    %\"val_38\"<INT64,[4]> ⬅️ ::Concat(%\"val_1\", %\"val_2739\"{[1]}, %\"val_2\", %\"val_2\") {axis=0}\n",
              "               8 |  # node_expand\n",
              "                    %\"expand\"<INT64,[s43,1,s53,s53]> ⬅️ ::Expand(%\"unsqueeze_2\", %\"val_38\")\n",
              "               9 |  # node__to_copy\n",
              "                    %\"_to_copy\"<FLOAT,[s43,1,s53,s53]> ⬅️ ::Cast(%\"expand\") {to=1}\n",
              "              10 |  # node_sub_16\n",
              "                    %\"sub_16\"<FLOAT,[s43,1,s53,s53]> ⬅️ ::Sub(%\"clone\"{1.0}, %\"_to_copy\")\n",
              "              11 |  # node__to_copy_1\n",
              "                    %\"_to_copy_1\"<BOOL,[s43,1,s53,s53]> ⬅️ ::Cast(%\"sub_16\") {to=9}\n",
              "              12 |  # node_masked_fill\n",
              "                    %\"masked_fill\"<FLOAT,[s43,1,s53,s53]> ⬅️ ::Where(%\"_to_copy_1\", %\"val_40\"{-3.4028234663852886e+38}, %\"sub_16\")\n",
              "              13 |  # node_permute\n",
              "                    %\"permute\"<INT64,[s53,1]> ⬅️ ::Transpose(%\"unsqueeze\") {perm=(1, 0)}\n",
              "              14 |  # node_sub_29\n",
              "                    %\"sub_29\"<INT64,[s53,s53]> ⬅️ ::Sub(%\"unsqueeze\", %\"permute\")\n",
              "              15 |  # node_abs_1\n",
              "                    %\"abs_1\"<INT64,[s53,s53]> ⬅️ ::Abs(%\"sub_29\")\n",
              "              16 |  # node_le_1\n",
              "                    %\"le_1\"<BOOL,[s53,s53]> ⬅️ ::LessOrEqual(%\"abs_1\", %\"val_43\"{64})\n",
              "              17 |  # node_Unsqueeze_3188\n",
              "                    %\"unsqueeze_5\"<BOOL,[1,1,s53,s53]> ⬅️ ::Unsqueeze(%\"le_1\", %\"val_2753\"{[0, 1]})\n",
              "              18 |  # node_logical_not\n",
              "                    %\"logical_not\"<BOOL,[1,1,s53,s53]> ⬅️ ::Not(%\"unsqueeze_5\")\n",
              "              19 |  # node_masked_fill_1\n",
              "                    %\"masked_fill_1\"<FLOAT,[1,1,s53,s53]> ⬅️ ::Where(%\"logical_not\", %\"val_40\"{-3.4028234663852886e+38}, %\"masked_fill\")\n",
              "              20 |  # node_embedding\n",
              "                    %\"embedding\"<FLOAT,[s72,s53,768]> ⬅️ ::Gather(%\"model.embeddings.tok_embeddings.weight\"{...}, %\"input_ids\") {axis=0}\n",
              "              21 |  # node_layer_norm\n",
              "                    %\"layer_norm\"<FLOAT,[s72,s53,768]> ⬅️ ::LayerNormalization(%\"embedding\", %\"model.embeddings.norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "              22 |  # node_linear\n",
              "                    %\"linear\"<FLOAT,[s72,(s53//s72),2304]> ⬅️ ::MatMul(%\"layer_norm\", %\"val_47\"{...})\n",
              "              23 |  # node_Concat_52\n",
              "                    %\"val_54\"<INT64,[5]> ⬅️ ::Concat(%\"val_0\", %\"val_50\"{[-1]}, %\"val_92\"{[3]}, %\"val_52\"{[12]}, %\"val_53\"{[64]}) {axis=0}\n",
              "              24 |  # node_view\n",
              "                    %\"view\"<FLOAT,[s72,(s53//s72),3,12,64]> ⬅️ ::Reshape(%\"linear\", %\"val_54\") {allowzero=1}\n",
              "              25 |  # node_unsqueeze_8\n",
              "                    %\"unsqueeze_8\"<INT64,[1,1,s53]> ⬅️ ::Unsqueeze(%\"unsqueeze\", %\"val_2739\"{[1]})\n",
              "              26 |  # node__to_copy_2\n",
              "                    %\"_to_copy_2\"<FLOAT,[1,1,s53]> ⬅️ ::Cast(%\"unsqueeze_8\") {to=1}\n",
              "              27 |  # node_matmul\n",
              "                    %\"matmul\"<FLOAT,[1,32,s53]> ⬅️ ::MatMul(%\"expand_1\"{...}, %\"_to_copy_2\")\n",
              "              28 |  # node_transpose\n",
              "                    %\"transpose\"<FLOAT,[1,s53,32]> ⬅️ ::Transpose(%\"matmul\") {perm=(0, 2, 1)}\n",
              "              29 |  # node_cat\n",
              "                    %\"cat\"<FLOAT,[1,s53,64]> ⬅️ ::Concat(%\"transpose\", %\"transpose\") {axis=-1}\n",
              "              30 |  # node_cos\n",
              "                    %\"cos\"<FLOAT,[1,s53,64]> ⬅️ ::Cos(%\"cat\")\n",
              "              31 |  # node_sin\n",
              "                    %\"sin\"<FLOAT,[1,s53,64]> ⬅️ ::Sin(%\"cat\")\n",
              "              32 |  # node_transpose_1\n",
              "                    %\"transpose_1\"<FLOAT,[s72,12,3,(s53//s72),64]> ⬅️ ::Transpose(%\"view\") {perm=(0, 3, 2, 1, 4)}\n",
              "              33 |  # node_Slice_72\n",
              "                    %\"val_74\"<FLOAT,[s72,12,1,(s53//s72),64]> ⬅️ ::Slice(%\"transpose_1\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "              34 |  # node_unbind__0\n",
              "                    %\"getitem\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Squeeze(%\"val_74\", %\"val_21\"{[2]})\n",
              "              35 |  # node_Slice_76\n",
              "                    %\"val_78\"<FLOAT,[s72,12,1,(s53//s72),64]> ⬅️ ::Slice(%\"transpose_1\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "              36 |  # node_unbind__1\n",
              "                    %\"getitem_1\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Squeeze(%\"val_78\", %\"val_21\"{[2]})\n",
              "              37 |  # node_Slice_80\n",
              "                    %\"val_82\"<FLOAT,[s72,12,1,(s53//s72),64]> ⬅️ ::Slice(%\"transpose_1\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "              38 |  # node_unbind__2\n",
              "                    %\"getitem_2\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Squeeze(%\"val_82\", %\"val_21\"{[2]})\n",
              "              39 |  # node_unsqueeze_9\n",
              "                    %\"unsqueeze_9\"<FLOAT,[1,1,s53,64]> ⬅️ ::Unsqueeze(%\"cos\", %\"val_2739\"{[1]})\n",
              "              40 |  # node_unsqueeze_10\n",
              "                    %\"unsqueeze_10\"<FLOAT,[1,1,s53,64]> ⬅️ ::Unsqueeze(%\"sin\", %\"val_2739\"{[1]})\n",
              "              41 |  # node_mul_124\n",
              "                    %\"mul_124\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Mul(%\"getitem\", %\"unsqueeze_9\")\n",
              "              42 |  # node_slice_4\n",
              "                    %\"slice_4\"<FLOAT,[s72,12,(s53//s72),32]> ⬅️ ::Slice(%\"getitem\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "              43 |  # node_slice_5\n",
              "                    %\"slice_5\"<FLOAT,[s72,12,(s53//s72),32]> ⬅️ ::Slice(%\"getitem\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "              44 |  # node_neg\n",
              "                    %\"neg\"<FLOAT,[s72,12,(s53//s72),32]> ⬅️ ::Neg(%\"slice_5\")\n",
              "              45 |  # node_cat_1\n",
              "                    %\"cat_1\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Concat(%\"neg\", %\"slice_4\") {axis=-1}\n",
              "              46 |  # node_mul_141\n",
              "                    %\"mul_141\"<FLOAT,[1,12,(s53//s72),64]> ⬅️ ::Mul(%\"cat_1\", %\"unsqueeze_10\")\n",
              "              47 |  # node_add_179\n",
              "                    %\"add_179\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Add(%\"mul_124\", %\"mul_141\")\n",
              "              48 |  # node_mul_149\n",
              "                    %\"mul_149\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Mul(%\"getitem_1\", %\"unsqueeze_9\")\n",
              "              49 |  # node_slice_6\n",
              "                    %\"slice_6\"<FLOAT,[s72,12,(s53//s72),32]> ⬅️ ::Slice(%\"getitem_1\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "              50 |  # node_slice_7\n",
              "                    %\"slice_7\"<FLOAT,[s72,12,(s53//s72),32]> ⬅️ ::Slice(%\"getitem_1\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "              51 |  # node_neg_1\n",
              "                    %\"neg_1\"<FLOAT,[s72,12,(s53//s72),32]> ⬅️ ::Neg(%\"slice_7\")\n",
              "              52 |  # node_cat_2\n",
              "                    %\"cat_2\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Concat(%\"neg_1\", %\"slice_6\") {axis=-1}\n",
              "              53 |  # node_mul_166\n",
              "                    %\"mul_166\"<FLOAT,[1,12,(s53//s72),64]> ⬅️ ::Mul(%\"cat_2\", %\"unsqueeze_10\")\n",
              "              54 |  # node_add_214\n",
              "                    %\"add_214\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Add(%\"mul_149\", %\"mul_166\")\n",
              "              55 |  # node_Shape_131\n",
              "                    %\"val_133\"<INT64,[4]> ⬅️ ::Shape(%\"add_214\") {start=0}\n",
              "              56 |  # node_Slice_134\n",
              "                    %\"val_136\"<INT64,[1]> ⬅️ ::Slice(%\"val_133\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "              57 |  # node_Slice_136\n",
              "                    %\"val_138\"<INT64,[1]> ⬅️ ::Slice(%\"val_133\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "              58 |  # node_Slice_138\n",
              "                    %\"val_140\"<INT64,[2]> ⬅️ ::Slice(%\"val_133\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "              59 |  # node_Concat_140\n",
              "                    %\"val_142\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_138\", %\"val_136\") {axis=0}\n",
              "              60 |  # node_Reshape_141\n",
              "                    %\"val_143\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_214\", %\"val_142\") {allowzero=0}\n",
              "              61 |  # node_Transpose_142\n",
              "                    %\"val_144\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_143\") {perm=(0, 2, 1)}\n",
              "              62 |  # node_Concat_143\n",
              "                    %\"val_145\"<INT64,[4]> ⬅️ ::Concat(%\"val_140\", %\"val_136\", %\"val_138\") {axis=0}\n",
              "              63 |  # node_Reshape_144\n",
              "                    %\"val_146\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_144\", %\"val_145\") {allowzero=0}\n",
              "              64 |  # node_Mul_146\n",
              "                    %\"val_148\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::Mul(%\"add_179\", %\"val_147\"{[0.3535533845424652]})\n",
              "              65 |  # node_Mul_148\n",
              "                    %\"val_150\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_146\", %\"val_147\"{[0.3535533845424652]})\n",
              "              66 |  # node_MatMul_149\n",
              "                    %\"val_151\"<FLOAT,[None,12,(s53//s72),None]> ⬅️ ::MatMul(%\"val_148\", %\"val_150\")\n",
              "              67 |  # node_Add_150\n",
              "                    %\"val_152\"<FLOAT,[None,12,None,None]> ⬅️ ::Add(%\"val_151\", %\"masked_fill\")\n",
              "              68 |  # node_Softmax_151\n",
              "                    %\"val_153\"<FLOAT,[None,12,None,None]> ⬅️ ::Softmax(%\"val_152\") {axis=-1}\n",
              "              69 |  # node_scaled_dot_product_attention\n",
              "                    %\"scaled_dot_product_attention\"<FLOAT,[s72,12,(s53//s72),64]> ⬅️ ::MatMul(%\"val_153\", %\"getitem_2\")\n",
              "              70 |  # node_transpose_2\n",
              "                    %\"transpose_2\"<FLOAT,[s72,(s53//s72),12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention\") {perm=(0, 2, 1, 3)}\n",
              "              71 |  # node_Concat_156\n",
              "                    %\"val_158\"<INT64,[3]> ⬅️ ::Concat(%\"val_0\", %\"val_50\"{[-1]}, %\"val_157\"{[768]}) {axis=0}\n",
              "              72 |  # node_view_1\n",
              "                    %\"view_1\"<FLOAT,[s72,(s53//s72),768]> ⬅️ ::Reshape(%\"transpose_2\", %\"val_158\") {allowzero=1}\n",
              "              73 |  # node_linear_1\n",
              "                    %\"linear_1\"<FLOAT,[s72,(s53//(s72**2)),768]> ⬅️ ::MatMul(%\"view_1\", %\"val_159\"{...})\n",
              "              74 |  # node_add_238\n",
              "                    %\"add_238\"<FLOAT,[s72,s53,768]> ⬅️ ::Add(%\"layer_norm\", %\"linear_1\")\n",
              "              75 |  # node_layer_norm_1\n",
              "                    %\"layer_norm_1\"<FLOAT,[s72,s53,768]> ⬅️ ::LayerNormalization(%\"add_238\", %\"model.layers.0.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "              76 |  # node_linear_2\n",
              "                    %\"linear_2\"<FLOAT,[s72,(s53//s72),2304]> ⬅️ ::MatMul(%\"layer_norm_1\", %\"val_162\"{...})\n",
              "              77 |  # node_Split_2691\n",
              "                    %\"split_split_0\"<FLOAT,[s72,(s53//s72),1152]>, %\"split_split_1\"<FLOAT,[s72,(s53//s72),1152]> ⬅️ ::Split(%\"linear_2\") {axis=2, num_outputs=2}\n",
              "              78 |  # node_Div_162\n",
              "                    %\"val_166\"<FLOAT,[s72,(s53//s72),1152]> ⬅️ ::Div(%\"split_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "              79 |  # node_Erf_163\n",
              "                    %\"val_167\"<FLOAT,[s72,(s53//s72),1152]> ⬅️ ::Erf(%\"val_166\")\n",
              "              80 |  # node_Add_165\n",
              "                    %\"val_169\"<FLOAT,[s72,(s53//s72),1152]> ⬅️ ::Add(%\"val_167\", %\"clone\"{1.0})\n",
              "              81 |  # node_Mul_167\n",
              "                    %\"val_171\"<FLOAT,[s72,(s53//s72),1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_169\")\n",
              "              82 |  # node_gelu\n",
              "                    %\"gelu\"<FLOAT,[1,(s53//s72),1152]> ⬅️ ::Mul(%\"split_split_0\", %\"val_171\")\n",
              "              83 |  # node_mul_204\n",
              "                    %\"mul_204\"<FLOAT,[1,(s53//s72),1152]> ⬅️ ::Mul(%\"gelu\", %\"split_split_1\")\n",
              "              84 |  # node_linear_3\n",
              "                    %\"linear_3\"<FLOAT,[1,(s53//s72),768]> ⬅️ ::MatMul(%\"mul_204\", %\"val_172\"{...})\n",
              "              85 |  # node_add_271\n",
              "                    %\"add_271\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_238\", %\"linear_3\")\n",
              "              86 |  # node_layer_norm_2\n",
              "                    %\"layer_norm_2\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_271\", %\"model.layers.1.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "              87 |  # node_linear_4\n",
              "                    %\"linear_4\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_2\", %\"val_175\"{...})\n",
              "              88 |  # node_view_2\n",
              "                    %\"view_2\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_4\", %\"val_54\") {allowzero=1}\n",
              "              89 |  # node_matmul_1\n",
              "                    %\"matmul_1\"<FLOAT,[1,32,s53]> ⬅️ ::MatMul(%\"expand_2\"{...}, %\"_to_copy_2\")\n",
              "              90 |  # node_transpose_3\n",
              "                    %\"transpose_3\"<FLOAT,[1,s53,32]> ⬅️ ::Transpose(%\"matmul_1\") {perm=(0, 2, 1)}\n",
              "              91 |  # node_cat_3\n",
              "                    %\"cat_3\"<FLOAT,[1,s53,64]> ⬅️ ::Concat(%\"transpose_3\", %\"transpose_3\") {axis=-1}\n",
              "              92 |  # node_cos_1\n",
              "                    %\"cos_1\"<FLOAT,[1,s53,64]> ⬅️ ::Cos(%\"cat_3\")\n",
              "              93 |  # node_sin_1\n",
              "                    %\"sin_1\"<FLOAT,[1,s53,64]> ⬅️ ::Sin(%\"cat_3\")\n",
              "              94 |  # node_transpose_4\n",
              "                    %\"transpose_4\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_2\") {perm=(0, 3, 2, 1, 4)}\n",
              "              95 |  # node_Slice_195\n",
              "                    %\"val_201\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_4\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "              96 |  # node_unbind_1__0\n",
              "                    %\"getitem_5\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_201\", %\"val_21\"{[2]})\n",
              "              97 |  # node_Slice_199\n",
              "                    %\"val_205\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_4\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "              98 |  # node_unbind_1__1\n",
              "                    %\"getitem_6\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_205\", %\"val_21\"{[2]})\n",
              "              99 |  # node_Slice_203\n",
              "                    %\"val_209\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_4\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             100 |  # node_unbind_1__2\n",
              "                    %\"getitem_7\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_209\", %\"val_21\"{[2]})\n",
              "             101 |  # node_unsqueeze_14\n",
              "                    %\"unsqueeze_14\"<FLOAT,[1,1,s53,64]> ⬅️ ::Unsqueeze(%\"cos_1\", %\"val_2739\"{[1]})\n",
              "             102 |  # node_unsqueeze_15\n",
              "                    %\"unsqueeze_15\"<FLOAT,[1,1,s53,64]> ⬅️ ::Unsqueeze(%\"sin_1\", %\"val_2739\"{[1]})\n",
              "             103 |  # node_mul_278\n",
              "                    %\"mul_278\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_5\", %\"unsqueeze_14\")\n",
              "             104 |  # node_slice_9\n",
              "                    %\"slice_9\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_5\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             105 |  # node_slice_10\n",
              "                    %\"slice_10\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_5\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             106 |  # node_neg_2\n",
              "                    %\"neg_2\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_10\")\n",
              "             107 |  # node_cat_4\n",
              "                    %\"cat_4\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_2\", %\"slice_9\") {axis=-1}\n",
              "             108 |  # node_mul_295\n",
              "                    %\"mul_295\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_4\", %\"unsqueeze_15\")\n",
              "             109 |  # node_add_351\n",
              "                    %\"add_351\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_278\", %\"mul_295\")\n",
              "             110 |  # node_mul_303\n",
              "                    %\"mul_303\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_6\", %\"unsqueeze_14\")\n",
              "             111 |  # node_slice_11\n",
              "                    %\"slice_11\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_6\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             112 |  # node_slice_12\n",
              "                    %\"slice_12\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_6\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             113 |  # node_neg_3\n",
              "                    %\"neg_3\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_12\")\n",
              "             114 |  # node_cat_5\n",
              "                    %\"cat_5\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_3\", %\"slice_11\") {axis=-1}\n",
              "             115 |  # node_mul_320\n",
              "                    %\"mul_320\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_5\", %\"unsqueeze_15\")\n",
              "             116 |  # node_add_375\n",
              "                    %\"add_375\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_303\", %\"mul_320\")\n",
              "             117 |  # node_Shape_253\n",
              "                    %\"val_259\"<INT64,[4]> ⬅️ ::Shape(%\"add_375\") {start=0}\n",
              "             118 |  # node_Slice_255\n",
              "                    %\"val_261\"<INT64,[1]> ⬅️ ::Slice(%\"val_259\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             119 |  # node_Slice_256\n",
              "                    %\"val_262\"<INT64,[1]> ⬅️ ::Slice(%\"val_259\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             120 |  # node_Slice_258\n",
              "                    %\"val_264\"<INT64,[2]> ⬅️ ::Slice(%\"val_259\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             121 |  # node_Concat_260\n",
              "                    %\"val_266\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_262\", %\"val_261\") {axis=0}\n",
              "             122 |  # node_Reshape_261\n",
              "                    %\"val_267\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_375\", %\"val_266\") {allowzero=0}\n",
              "             123 |  # node_Transpose_262\n",
              "                    %\"val_268\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_267\") {perm=(0, 2, 1)}\n",
              "             124 |  # node_Concat_263\n",
              "                    %\"val_269\"<INT64,[4]> ⬅️ ::Concat(%\"val_264\", %\"val_261\", %\"val_262\") {axis=0}\n",
              "             125 |  # node_Reshape_264\n",
              "                    %\"val_270\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_268\", %\"val_269\") {allowzero=0}\n",
              "             126 |  # node_Mul_266\n",
              "                    %\"val_272\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_351\", %\"val_147\"{[0.3535533845424652]})\n",
              "             127 |  # node_Mul_268\n",
              "                    %\"val_274\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_270\", %\"val_147\"{[0.3535533845424652]})\n",
              "             128 |  # node_MatMul_269\n",
              "                    %\"val_275\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_272\", %\"val_274\")\n",
              "             129 |  # node_Add_270\n",
              "                    %\"val_276\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_275\", %\"masked_fill_1\")\n",
              "             130 |  # node_Softmax_271\n",
              "                    %\"val_277\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_276\") {axis=-1}\n",
              "             131 |  # node_scaled_dot_product_attention_1\n",
              "                    %\"scaled_dot_product_attention_1\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_277\", %\"getitem_7\")\n",
              "             132 |  # node_transpose_5\n",
              "                    %\"transpose_5\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_1\") {perm=(0, 2, 1, 3)}\n",
              "             133 |  # node_view_3\n",
              "                    %\"view_3\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_5\", %\"val_158\") {allowzero=1}\n",
              "             134 |  # node_linear_5\n",
              "                    %\"linear_5\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_3\", %\"val_283\"{...})\n",
              "             135 |  # node_add_392\n",
              "                    %\"add_392\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_271\", %\"linear_5\")\n",
              "             136 |  # node_layer_norm_3\n",
              "                    %\"layer_norm_3\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_392\", %\"model.layers.1.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             137 |  # node_linear_6\n",
              "                    %\"linear_6\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_3\", %\"val_286\"{...})\n",
              "             138 |  # node_Split_2714\n",
              "                    %\"split_1_split_0\"<FLOAT,[1,s53,1152]>, %\"split_1_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_6\") {axis=2, num_outputs=2}\n",
              "             139 |  # node_Div_280\n",
              "                    %\"val_288\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_1_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             140 |  # node_Erf_281\n",
              "                    %\"val_289\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_288\")\n",
              "             141 |  # node_Add_283\n",
              "                    %\"val_291\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_289\", %\"clone\"{1.0})\n",
              "             142 |  # node_Mul_285\n",
              "                    %\"val_293\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_291\")\n",
              "             143 |  # node_gelu_1\n",
              "                    %\"gelu_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_1_split_0\", %\"val_293\")\n",
              "             144 |  # node_mul_358\n",
              "                    %\"mul_358\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_1\", %\"split_1_split_1\")\n",
              "             145 |  # node_linear_7\n",
              "                    %\"linear_7\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_358\", %\"val_294\"{...})\n",
              "             146 |  # node_add_420\n",
              "                    %\"add_420\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_392\", %\"linear_7\")\n",
              "             147 |  # node_layer_norm_4\n",
              "                    %\"layer_norm_4\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_420\", %\"model.layers.2.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             148 |  # node_linear_8\n",
              "                    %\"linear_8\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_4\", %\"val_297\"{...})\n",
              "             149 |  # node_view_4\n",
              "                    %\"view_4\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_8\", %\"val_54\") {allowzero=1}\n",
              "             150 |  # node_transpose_7\n",
              "                    %\"transpose_7\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_4\") {perm=(0, 3, 2, 1, 4)}\n",
              "             151 |  # node_Slice_313\n",
              "                    %\"val_323\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_7\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             152 |  # node_unbind_2__0\n",
              "                    %\"getitem_10\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_323\", %\"val_21\"{[2]})\n",
              "             153 |  # node_Slice_317\n",
              "                    %\"val_327\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_7\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             154 |  # node_unbind_2__1\n",
              "                    %\"getitem_11\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_327\", %\"val_21\"{[2]})\n",
              "             155 |  # node_Slice_321\n",
              "                    %\"val_331\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_7\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             156 |  # node_unbind_2__2\n",
              "                    %\"getitem_12\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_331\", %\"val_21\"{[2]})\n",
              "             157 |  # node_mul_432\n",
              "                    %\"mul_432\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_10\", %\"unsqueeze_14\")\n",
              "             158 |  # node_slice_14\n",
              "                    %\"slice_14\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_10\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             159 |  # node_slice_15\n",
              "                    %\"slice_15\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_10\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             160 |  # node_neg_4\n",
              "                    %\"neg_4\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_15\")\n",
              "             161 |  # node_cat_7\n",
              "                    %\"cat_7\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_4\", %\"slice_14\") {axis=-1}\n",
              "             162 |  # node_mul_449\n",
              "                    %\"mul_449\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_7\", %\"unsqueeze_15\")\n",
              "             163 |  # node_add_500\n",
              "                    %\"add_500\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_432\", %\"mul_449\")\n",
              "             164 |  # node_mul_457\n",
              "                    %\"mul_457\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_11\", %\"unsqueeze_14\")\n",
              "             165 |  # node_slice_16\n",
              "                    %\"slice_16\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_11\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             166 |  # node_slice_17\n",
              "                    %\"slice_17\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_11\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             167 |  # node_neg_5\n",
              "                    %\"neg_5\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_17\")\n",
              "             168 |  # node_cat_8\n",
              "                    %\"cat_8\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_5\", %\"slice_16\") {axis=-1}\n",
              "             169 |  # node_mul_474\n",
              "                    %\"mul_474\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_8\", %\"unsqueeze_15\")\n",
              "             170 |  # node_add_524\n",
              "                    %\"add_524\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_457\", %\"mul_474\")\n",
              "             171 |  # node_Shape_371\n",
              "                    %\"val_381\"<INT64,[4]> ⬅️ ::Shape(%\"add_524\") {start=0}\n",
              "             172 |  # node_Slice_373\n",
              "                    %\"val_383\"<INT64,[1]> ⬅️ ::Slice(%\"val_381\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             173 |  # node_Slice_374\n",
              "                    %\"val_384\"<INT64,[1]> ⬅️ ::Slice(%\"val_381\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             174 |  # node_Slice_376\n",
              "                    %\"val_386\"<INT64,[2]> ⬅️ ::Slice(%\"val_381\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             175 |  # node_Concat_378\n",
              "                    %\"val_388\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_384\", %\"val_383\") {axis=0}\n",
              "             176 |  # node_Reshape_379\n",
              "                    %\"val_389\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_524\", %\"val_388\") {allowzero=0}\n",
              "             177 |  # node_Transpose_380\n",
              "                    %\"val_390\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_389\") {perm=(0, 2, 1)}\n",
              "             178 |  # node_Concat_381\n",
              "                    %\"val_391\"<INT64,[4]> ⬅️ ::Concat(%\"val_386\", %\"val_383\", %\"val_384\") {axis=0}\n",
              "             179 |  # node_Reshape_382\n",
              "                    %\"val_392\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_390\", %\"val_391\") {allowzero=0}\n",
              "             180 |  # node_Mul_384\n",
              "                    %\"val_394\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_500\", %\"val_147\"{[0.3535533845424652]})\n",
              "             181 |  # node_Mul_386\n",
              "                    %\"val_396\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_392\", %\"val_147\"{[0.3535533845424652]})\n",
              "             182 |  # node_MatMul_387\n",
              "                    %\"val_397\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_394\", %\"val_396\")\n",
              "             183 |  # node_Add_388\n",
              "                    %\"val_398\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_397\", %\"masked_fill_1\")\n",
              "             184 |  # node_Softmax_389\n",
              "                    %\"val_399\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_398\") {axis=-1}\n",
              "             185 |  # node_scaled_dot_product_attention_2\n",
              "                    %\"scaled_dot_product_attention_2\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_399\", %\"getitem_12\")\n",
              "             186 |  # node_transpose_8\n",
              "                    %\"transpose_8\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_2\") {perm=(0, 2, 1, 3)}\n",
              "             187 |  # node_view_5\n",
              "                    %\"view_5\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_8\", %\"val_158\") {allowzero=1}\n",
              "             188 |  # node_linear_9\n",
              "                    %\"linear_9\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_5\", %\"val_405\"{...})\n",
              "             189 |  # node_add_541\n",
              "                    %\"add_541\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_420\", %\"linear_9\")\n",
              "             190 |  # node_layer_norm_5\n",
              "                    %\"layer_norm_5\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_541\", %\"model.layers.2.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             191 |  # node_linear_10\n",
              "                    %\"linear_10\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_5\", %\"val_408\"{...})\n",
              "             192 |  # node_Split_2737\n",
              "                    %\"split_2_split_0\"<FLOAT,[1,s53,1152]>, %\"split_2_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_10\") {axis=2, num_outputs=2}\n",
              "             193 |  # node_Div_398\n",
              "                    %\"val_410\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_2_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             194 |  # node_Erf_399\n",
              "                    %\"val_411\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_410\")\n",
              "             195 |  # node_Add_401\n",
              "                    %\"val_413\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_411\", %\"clone\"{1.0})\n",
              "             196 |  # node_Mul_403\n",
              "                    %\"val_415\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_413\")\n",
              "             197 |  # node_gelu_2\n",
              "                    %\"gelu_2\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_2_split_0\", %\"val_415\")\n",
              "             198 |  # node_mul_512\n",
              "                    %\"mul_512\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_2\", %\"split_2_split_1\")\n",
              "             199 |  # node_linear_11\n",
              "                    %\"linear_11\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_512\", %\"val_416\"{...})\n",
              "             200 |  # node_add_569\n",
              "                    %\"add_569\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_541\", %\"linear_11\")\n",
              "             201 |  # node_layer_norm_6\n",
              "                    %\"layer_norm_6\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_569\", %\"model.layers.3.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             202 |  # node_linear_12\n",
              "                    %\"linear_12\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_6\", %\"val_419\"{...})\n",
              "             203 |  # node_view_6\n",
              "                    %\"view_6\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_12\", %\"val_54\") {allowzero=1}\n",
              "             204 |  # node_transpose_10\n",
              "                    %\"transpose_10\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_6\") {perm=(0, 3, 2, 1, 4)}\n",
              "             205 |  # node_Slice_431\n",
              "                    %\"val_445\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_10\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             206 |  # node_unbind_3__0\n",
              "                    %\"getitem_15\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_445\", %\"val_21\"{[2]})\n",
              "             207 |  # node_Slice_435\n",
              "                    %\"val_449\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_10\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             208 |  # node_unbind_3__1\n",
              "                    %\"getitem_16\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_449\", %\"val_21\"{[2]})\n",
              "             209 |  # node_Slice_439\n",
              "                    %\"val_453\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_10\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             210 |  # node_unbind_3__2\n",
              "                    %\"getitem_17\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_453\", %\"val_21\"{[2]})\n",
              "             211 |  # node_mul_586\n",
              "                    %\"mul_586\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_15\", %\"unsqueeze_9\")\n",
              "             212 |  # node_slice_19\n",
              "                    %\"slice_19\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_15\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             213 |  # node_slice_20\n",
              "                    %\"slice_20\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_15\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             214 |  # node_neg_6\n",
              "                    %\"neg_6\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_20\")\n",
              "             215 |  # node_cat_10\n",
              "                    %\"cat_10\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_6\", %\"slice_19\") {axis=-1}\n",
              "             216 |  # node_mul_603\n",
              "                    %\"mul_603\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_10\", %\"unsqueeze_10\")\n",
              "             217 |  # node_add_649\n",
              "                    %\"add_649\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_586\", %\"mul_603\")\n",
              "             218 |  # node_mul_611\n",
              "                    %\"mul_611\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_16\", %\"unsqueeze_9\")\n",
              "             219 |  # node_slice_21\n",
              "                    %\"slice_21\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_16\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             220 |  # node_slice_22\n",
              "                    %\"slice_22\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_16\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             221 |  # node_neg_7\n",
              "                    %\"neg_7\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_22\")\n",
              "             222 |  # node_cat_11\n",
              "                    %\"cat_11\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_7\", %\"slice_21\") {axis=-1}\n",
              "             223 |  # node_mul_628\n",
              "                    %\"mul_628\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_11\", %\"unsqueeze_10\")\n",
              "             224 |  # node_add_673\n",
              "                    %\"add_673\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_611\", %\"mul_628\")\n",
              "             225 |  # node_Shape_489\n",
              "                    %\"val_503\"<INT64,[4]> ⬅️ ::Shape(%\"add_673\") {start=0}\n",
              "             226 |  # node_Slice_491\n",
              "                    %\"val_505\"<INT64,[1]> ⬅️ ::Slice(%\"val_503\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             227 |  # node_Slice_492\n",
              "                    %\"val_506\"<INT64,[1]> ⬅️ ::Slice(%\"val_503\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             228 |  # node_Slice_494\n",
              "                    %\"val_508\"<INT64,[2]> ⬅️ ::Slice(%\"val_503\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             229 |  # node_Concat_496\n",
              "                    %\"val_510\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_506\", %\"val_505\") {axis=0}\n",
              "             230 |  # node_Reshape_497\n",
              "                    %\"val_511\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_673\", %\"val_510\") {allowzero=0}\n",
              "             231 |  # node_Transpose_498\n",
              "                    %\"val_512\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_511\") {perm=(0, 2, 1)}\n",
              "             232 |  # node_Concat_499\n",
              "                    %\"val_513\"<INT64,[4]> ⬅️ ::Concat(%\"val_508\", %\"val_505\", %\"val_506\") {axis=0}\n",
              "             233 |  # node_Reshape_500\n",
              "                    %\"val_514\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_512\", %\"val_513\") {allowzero=0}\n",
              "             234 |  # node_Mul_502\n",
              "                    %\"val_516\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_649\", %\"val_147\"{[0.3535533845424652]})\n",
              "             235 |  # node_Mul_504\n",
              "                    %\"val_518\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_514\", %\"val_147\"{[0.3535533845424652]})\n",
              "             236 |  # node_MatMul_505\n",
              "                    %\"val_519\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_516\", %\"val_518\")\n",
              "             237 |  # node_Add_506\n",
              "                    %\"val_520\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_519\", %\"masked_fill\")\n",
              "             238 |  # node_Softmax_507\n",
              "                    %\"val_521\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_520\") {axis=-1}\n",
              "             239 |  # node_scaled_dot_product_attention_3\n",
              "                    %\"scaled_dot_product_attention_3\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_521\", %\"getitem_17\")\n",
              "             240 |  # node_transpose_11\n",
              "                    %\"transpose_11\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_3\") {perm=(0, 2, 1, 3)}\n",
              "             241 |  # node_view_7\n",
              "                    %\"view_7\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_11\", %\"val_158\") {allowzero=1}\n",
              "             242 |  # node_linear_13\n",
              "                    %\"linear_13\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_7\", %\"val_527\"{...})\n",
              "             243 |  # node_add_690\n",
              "                    %\"add_690\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_569\", %\"linear_13\")\n",
              "             244 |  # node_layer_norm_7\n",
              "                    %\"layer_norm_7\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_690\", %\"model.layers.3.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             245 |  # node_linear_14\n",
              "                    %\"linear_14\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_7\", %\"val_530\"{...})\n",
              "             246 |  # node_Split_2760\n",
              "                    %\"split_3_split_0\"<FLOAT,[1,s53,1152]>, %\"split_3_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_14\") {axis=2, num_outputs=2}\n",
              "             247 |  # node_Div_516\n",
              "                    %\"val_532\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_3_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             248 |  # node_Erf_517\n",
              "                    %\"val_533\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_532\")\n",
              "             249 |  # node_Add_519\n",
              "                    %\"val_535\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_533\", %\"clone\"{1.0})\n",
              "             250 |  # node_Mul_521\n",
              "                    %\"val_537\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_535\")\n",
              "             251 |  # node_gelu_3\n",
              "                    %\"gelu_3\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_3_split_0\", %\"val_537\")\n",
              "             252 |  # node_mul_666\n",
              "                    %\"mul_666\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_3\", %\"split_3_split_1\")\n",
              "             253 |  # node_linear_15\n",
              "                    %\"linear_15\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_666\", %\"val_538\"{...})\n",
              "             254 |  # node_add_718\n",
              "                    %\"add_718\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_690\", %\"linear_15\")\n",
              "             255 |  # node_layer_norm_8\n",
              "                    %\"layer_norm_8\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_718\", %\"model.layers.4.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             256 |  # node_linear_16\n",
              "                    %\"linear_16\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_8\", %\"val_541\"{...})\n",
              "             257 |  # node_view_8\n",
              "                    %\"view_8\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_16\", %\"val_54\") {allowzero=1}\n",
              "             258 |  # node_transpose_13\n",
              "                    %\"transpose_13\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_8\") {perm=(0, 3, 2, 1, 4)}\n",
              "             259 |  # node_Slice_549\n",
              "                    %\"val_567\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_13\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             260 |  # node_unbind_4__0\n",
              "                    %\"getitem_20\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_567\", %\"val_21\"{[2]})\n",
              "             261 |  # node_Slice_553\n",
              "                    %\"val_571\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_13\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             262 |  # node_unbind_4__1\n",
              "                    %\"getitem_21\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_571\", %\"val_21\"{[2]})\n",
              "             263 |  # node_Slice_557\n",
              "                    %\"val_575\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_13\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             264 |  # node_unbind_4__2\n",
              "                    %\"getitem_22\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_575\", %\"val_21\"{[2]})\n",
              "             265 |  # node_mul_740\n",
              "                    %\"mul_740\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_20\", %\"unsqueeze_14\")\n",
              "             266 |  # node_slice_24\n",
              "                    %\"slice_24\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_20\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             267 |  # node_slice_25\n",
              "                    %\"slice_25\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_20\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             268 |  # node_neg_8\n",
              "                    %\"neg_8\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_25\")\n",
              "             269 |  # node_cat_13\n",
              "                    %\"cat_13\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_8\", %\"slice_24\") {axis=-1}\n",
              "             270 |  # node_mul_757\n",
              "                    %\"mul_757\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_13\", %\"unsqueeze_15\")\n",
              "             271 |  # node_add_798\n",
              "                    %\"add_798\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_740\", %\"mul_757\")\n",
              "             272 |  # node_mul_765\n",
              "                    %\"mul_765\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_21\", %\"unsqueeze_14\")\n",
              "             273 |  # node_slice_26\n",
              "                    %\"slice_26\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_21\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             274 |  # node_slice_27\n",
              "                    %\"slice_27\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_21\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             275 |  # node_neg_9\n",
              "                    %\"neg_9\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_27\")\n",
              "             276 |  # node_cat_14\n",
              "                    %\"cat_14\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_9\", %\"slice_26\") {axis=-1}\n",
              "             277 |  # node_mul_782\n",
              "                    %\"mul_782\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_14\", %\"unsqueeze_15\")\n",
              "             278 |  # node_add_822\n",
              "                    %\"add_822\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_765\", %\"mul_782\")\n",
              "             279 |  # node_Shape_607\n",
              "                    %\"val_625\"<INT64,[4]> ⬅️ ::Shape(%\"add_822\") {start=0}\n",
              "             280 |  # node_Slice_609\n",
              "                    %\"val_627\"<INT64,[1]> ⬅️ ::Slice(%\"val_625\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             281 |  # node_Slice_610\n",
              "                    %\"val_628\"<INT64,[1]> ⬅️ ::Slice(%\"val_625\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             282 |  # node_Slice_612\n",
              "                    %\"val_630\"<INT64,[2]> ⬅️ ::Slice(%\"val_625\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             283 |  # node_Concat_614\n",
              "                    %\"val_632\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_628\", %\"val_627\") {axis=0}\n",
              "             284 |  # node_Reshape_615\n",
              "                    %\"val_633\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_822\", %\"val_632\") {allowzero=0}\n",
              "             285 |  # node_Transpose_616\n",
              "                    %\"val_634\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_633\") {perm=(0, 2, 1)}\n",
              "             286 |  # node_Concat_617\n",
              "                    %\"val_635\"<INT64,[4]> ⬅️ ::Concat(%\"val_630\", %\"val_627\", %\"val_628\") {axis=0}\n",
              "             287 |  # node_Reshape_618\n",
              "                    %\"val_636\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_634\", %\"val_635\") {allowzero=0}\n",
              "             288 |  # node_Mul_620\n",
              "                    %\"val_638\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_798\", %\"val_147\"{[0.3535533845424652]})\n",
              "             289 |  # node_Mul_622\n",
              "                    %\"val_640\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_636\", %\"val_147\"{[0.3535533845424652]})\n",
              "             290 |  # node_MatMul_623\n",
              "                    %\"val_641\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_638\", %\"val_640\")\n",
              "             291 |  # node_Add_624\n",
              "                    %\"val_642\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_641\", %\"masked_fill_1\")\n",
              "             292 |  # node_Softmax_625\n",
              "                    %\"val_643\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_642\") {axis=-1}\n",
              "             293 |  # node_scaled_dot_product_attention_4\n",
              "                    %\"scaled_dot_product_attention_4\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_643\", %\"getitem_22\")\n",
              "             294 |  # node_transpose_14\n",
              "                    %\"transpose_14\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_4\") {perm=(0, 2, 1, 3)}\n",
              "             295 |  # node_view_9\n",
              "                    %\"view_9\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_14\", %\"val_158\") {allowzero=1}\n",
              "             296 |  # node_linear_17\n",
              "                    %\"linear_17\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_9\", %\"val_649\"{...})\n",
              "             297 |  # node_add_839\n",
              "                    %\"add_839\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_718\", %\"linear_17\")\n",
              "             298 |  # node_layer_norm_9\n",
              "                    %\"layer_norm_9\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_839\", %\"model.layers.4.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             299 |  # node_linear_18\n",
              "                    %\"linear_18\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_9\", %\"val_652\"{...})\n",
              "             300 |  # node_Split_2783\n",
              "                    %\"split_4_split_0\"<FLOAT,[1,s53,1152]>, %\"split_4_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_18\") {axis=2, num_outputs=2}\n",
              "             301 |  # node_Div_634\n",
              "                    %\"val_654\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_4_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             302 |  # node_Erf_635\n",
              "                    %\"val_655\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_654\")\n",
              "             303 |  # node_Add_637\n",
              "                    %\"val_657\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_655\", %\"clone\"{1.0})\n",
              "             304 |  # node_Mul_639\n",
              "                    %\"val_659\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_657\")\n",
              "             305 |  # node_gelu_4\n",
              "                    %\"gelu_4\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_4_split_0\", %\"val_659\")\n",
              "             306 |  # node_mul_820\n",
              "                    %\"mul_820\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_4\", %\"split_4_split_1\")\n",
              "             307 |  # node_linear_19\n",
              "                    %\"linear_19\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_820\", %\"val_660\"{...})\n",
              "             308 |  # node_add_867\n",
              "                    %\"add_867\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_839\", %\"linear_19\")\n",
              "             309 |  # node_layer_norm_10\n",
              "                    %\"layer_norm_10\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_867\", %\"model.layers.5.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             310 |  # node_linear_20\n",
              "                    %\"linear_20\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_10\", %\"val_663\"{...})\n",
              "             311 |  # node_view_10\n",
              "                    %\"view_10\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_20\", %\"val_54\") {allowzero=1}\n",
              "             312 |  # node_transpose_16\n",
              "                    %\"transpose_16\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_10\") {perm=(0, 3, 2, 1, 4)}\n",
              "             313 |  # node_Slice_667\n",
              "                    %\"val_689\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_16\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             314 |  # node_unbind_5__0\n",
              "                    %\"getitem_25\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_689\", %\"val_21\"{[2]})\n",
              "             315 |  # node_Slice_671\n",
              "                    %\"val_693\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_16\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             316 |  # node_unbind_5__1\n",
              "                    %\"getitem_26\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_693\", %\"val_21\"{[2]})\n",
              "             317 |  # node_Slice_675\n",
              "                    %\"val_697\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_16\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             318 |  # node_unbind_5__2\n",
              "                    %\"getitem_27\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_697\", %\"val_21\"{[2]})\n",
              "             319 |  # node_mul_894\n",
              "                    %\"mul_894\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_25\", %\"unsqueeze_14\")\n",
              "             320 |  # node_slice_29\n",
              "                    %\"slice_29\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_25\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             321 |  # node_slice_30\n",
              "                    %\"slice_30\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_25\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             322 |  # node_neg_10\n",
              "                    %\"neg_10\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_30\")\n",
              "             323 |  # node_cat_16\n",
              "                    %\"cat_16\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_10\", %\"slice_29\") {axis=-1}\n",
              "             324 |  # node_mul_911\n",
              "                    %\"mul_911\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_16\", %\"unsqueeze_15\")\n",
              "             325 |  # node_add_947\n",
              "                    %\"add_947\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_894\", %\"mul_911\")\n",
              "             326 |  # node_mul_919\n",
              "                    %\"mul_919\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_26\", %\"unsqueeze_14\")\n",
              "             327 |  # node_slice_31\n",
              "                    %\"slice_31\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_26\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             328 |  # node_slice_32\n",
              "                    %\"slice_32\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_26\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             329 |  # node_neg_11\n",
              "                    %\"neg_11\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_32\")\n",
              "             330 |  # node_cat_17\n",
              "                    %\"cat_17\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_11\", %\"slice_31\") {axis=-1}\n",
              "             331 |  # node_mul_936\n",
              "                    %\"mul_936\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_17\", %\"unsqueeze_15\")\n",
              "             332 |  # node_add_971\n",
              "                    %\"add_971\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_919\", %\"mul_936\")\n",
              "             333 |  # node_Shape_725\n",
              "                    %\"val_747\"<INT64,[4]> ⬅️ ::Shape(%\"add_971\") {start=0}\n",
              "             334 |  # node_Slice_727\n",
              "                    %\"val_749\"<INT64,[1]> ⬅️ ::Slice(%\"val_747\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             335 |  # node_Slice_728\n",
              "                    %\"val_750\"<INT64,[1]> ⬅️ ::Slice(%\"val_747\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             336 |  # node_Slice_730\n",
              "                    %\"val_752\"<INT64,[2]> ⬅️ ::Slice(%\"val_747\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             337 |  # node_Concat_732\n",
              "                    %\"val_754\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_750\", %\"val_749\") {axis=0}\n",
              "             338 |  # node_Reshape_733\n",
              "                    %\"val_755\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_971\", %\"val_754\") {allowzero=0}\n",
              "             339 |  # node_Transpose_734\n",
              "                    %\"val_756\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_755\") {perm=(0, 2, 1)}\n",
              "             340 |  # node_Concat_735\n",
              "                    %\"val_757\"<INT64,[4]> ⬅️ ::Concat(%\"val_752\", %\"val_749\", %\"val_750\") {axis=0}\n",
              "             341 |  # node_Reshape_736\n",
              "                    %\"val_758\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_756\", %\"val_757\") {allowzero=0}\n",
              "             342 |  # node_Mul_738\n",
              "                    %\"val_760\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_947\", %\"val_147\"{[0.3535533845424652]})\n",
              "             343 |  # node_Mul_740\n",
              "                    %\"val_762\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_758\", %\"val_147\"{[0.3535533845424652]})\n",
              "             344 |  # node_MatMul_741\n",
              "                    %\"val_763\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_760\", %\"val_762\")\n",
              "             345 |  # node_Add_742\n",
              "                    %\"val_764\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_763\", %\"masked_fill_1\")\n",
              "             346 |  # node_Softmax_743\n",
              "                    %\"val_765\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_764\") {axis=-1}\n",
              "             347 |  # node_scaled_dot_product_attention_5\n",
              "                    %\"scaled_dot_product_attention_5\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_765\", %\"getitem_27\")\n",
              "             348 |  # node_transpose_17\n",
              "                    %\"transpose_17\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_5\") {perm=(0, 2, 1, 3)}\n",
              "             349 |  # node_view_11\n",
              "                    %\"view_11\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_17\", %\"val_158\") {allowzero=1}\n",
              "             350 |  # node_linear_21\n",
              "                    %\"linear_21\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_11\", %\"val_771\"{...})\n",
              "             351 |  # node_add_988\n",
              "                    %\"add_988\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_867\", %\"linear_21\")\n",
              "             352 |  # node_layer_norm_11\n",
              "                    %\"layer_norm_11\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_988\", %\"model.layers.5.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             353 |  # node_linear_22\n",
              "                    %\"linear_22\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_11\", %\"val_774\"{...})\n",
              "             354 |  # node_Split_2806\n",
              "                    %\"split_5_split_0\"<FLOAT,[1,s53,1152]>, %\"split_5_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_22\") {axis=2, num_outputs=2}\n",
              "             355 |  # node_Div_752\n",
              "                    %\"val_776\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_5_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             356 |  # node_Erf_753\n",
              "                    %\"val_777\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_776\")\n",
              "             357 |  # node_Add_755\n",
              "                    %\"val_779\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_777\", %\"clone\"{1.0})\n",
              "             358 |  # node_Mul_757\n",
              "                    %\"val_781\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_779\")\n",
              "             359 |  # node_gelu_5\n",
              "                    %\"gelu_5\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_5_split_0\", %\"val_781\")\n",
              "             360 |  # node_mul_974\n",
              "                    %\"mul_974\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_5\", %\"split_5_split_1\")\n",
              "             361 |  # node_linear_23\n",
              "                    %\"linear_23\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_974\", %\"val_782\"{...})\n",
              "             362 |  # node_add_1016\n",
              "                    %\"add_1016\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_988\", %\"linear_23\")\n",
              "             363 |  # node_layer_norm_12\n",
              "                    %\"layer_norm_12\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1016\", %\"model.layers.6.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             364 |  # node_linear_24\n",
              "                    %\"linear_24\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_12\", %\"val_785\"{...})\n",
              "             365 |  # node_view_12\n",
              "                    %\"view_12\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_24\", %\"val_54\") {allowzero=1}\n",
              "             366 |  # node_transpose_19\n",
              "                    %\"transpose_19\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_12\") {perm=(0, 3, 2, 1, 4)}\n",
              "             367 |  # node_Slice_785\n",
              "                    %\"val_811\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_19\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             368 |  # node_unbind_6__0\n",
              "                    %\"getitem_30\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_811\", %\"val_21\"{[2]})\n",
              "             369 |  # node_Slice_789\n",
              "                    %\"val_815\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_19\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             370 |  # node_unbind_6__1\n",
              "                    %\"getitem_31\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_815\", %\"val_21\"{[2]})\n",
              "             371 |  # node_Slice_793\n",
              "                    %\"val_819\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_19\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             372 |  # node_unbind_6__2\n",
              "                    %\"getitem_32\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_819\", %\"val_21\"{[2]})\n",
              "             373 |  # node_mul_1048\n",
              "                    %\"mul_1048\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_30\", %\"unsqueeze_9\")\n",
              "             374 |  # node_slice_34\n",
              "                    %\"slice_34\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_30\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             375 |  # node_slice_35\n",
              "                    %\"slice_35\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_30\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             376 |  # node_neg_12\n",
              "                    %\"neg_12\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_35\")\n",
              "             377 |  # node_cat_19\n",
              "                    %\"cat_19\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_12\", %\"slice_34\") {axis=-1}\n",
              "             378 |  # node_mul_1065\n",
              "                    %\"mul_1065\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_19\", %\"unsqueeze_10\")\n",
              "             379 |  # node_add_1096\n",
              "                    %\"add_1096\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1048\", %\"mul_1065\")\n",
              "             380 |  # node_mul_1073\n",
              "                    %\"mul_1073\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_31\", %\"unsqueeze_9\")\n",
              "             381 |  # node_slice_36\n",
              "                    %\"slice_36\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_31\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             382 |  # node_slice_37\n",
              "                    %\"slice_37\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_31\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             383 |  # node_neg_13\n",
              "                    %\"neg_13\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_37\")\n",
              "             384 |  # node_cat_20\n",
              "                    %\"cat_20\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_13\", %\"slice_36\") {axis=-1}\n",
              "             385 |  # node_mul_1090\n",
              "                    %\"mul_1090\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_20\", %\"unsqueeze_10\")\n",
              "             386 |  # node_add_1120\n",
              "                    %\"add_1120\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1073\", %\"mul_1090\")\n",
              "             387 |  # node_Shape_843\n",
              "                    %\"val_869\"<INT64,[4]> ⬅️ ::Shape(%\"add_1120\") {start=0}\n",
              "             388 |  # node_Slice_845\n",
              "                    %\"val_871\"<INT64,[1]> ⬅️ ::Slice(%\"val_869\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             389 |  # node_Slice_846\n",
              "                    %\"val_872\"<INT64,[1]> ⬅️ ::Slice(%\"val_869\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             390 |  # node_Slice_848\n",
              "                    %\"val_874\"<INT64,[2]> ⬅️ ::Slice(%\"val_869\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             391 |  # node_Concat_850\n",
              "                    %\"val_876\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_872\", %\"val_871\") {axis=0}\n",
              "             392 |  # node_Reshape_851\n",
              "                    %\"val_877\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_1120\", %\"val_876\") {allowzero=0}\n",
              "             393 |  # node_Transpose_852\n",
              "                    %\"val_878\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_877\") {perm=(0, 2, 1)}\n",
              "             394 |  # node_Concat_853\n",
              "                    %\"val_879\"<INT64,[4]> ⬅️ ::Concat(%\"val_874\", %\"val_871\", %\"val_872\") {axis=0}\n",
              "             395 |  # node_Reshape_854\n",
              "                    %\"val_880\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_878\", %\"val_879\") {allowzero=0}\n",
              "             396 |  # node_Mul_856\n",
              "                    %\"val_882\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1096\", %\"val_147\"{[0.3535533845424652]})\n",
              "             397 |  # node_Mul_858\n",
              "                    %\"val_884\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_880\", %\"val_147\"{[0.3535533845424652]})\n",
              "             398 |  # node_MatMul_859\n",
              "                    %\"val_885\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_882\", %\"val_884\")\n",
              "             399 |  # node_Add_860\n",
              "                    %\"val_886\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_885\", %\"masked_fill\")\n",
              "             400 |  # node_Softmax_861\n",
              "                    %\"val_887\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_886\") {axis=-1}\n",
              "             401 |  # node_scaled_dot_product_attention_6\n",
              "                    %\"scaled_dot_product_attention_6\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_887\", %\"getitem_32\")\n",
              "             402 |  # node_transpose_20\n",
              "                    %\"transpose_20\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_6\") {perm=(0, 2, 1, 3)}\n",
              "             403 |  # node_view_13\n",
              "                    %\"view_13\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_20\", %\"val_158\") {allowzero=1}\n",
              "             404 |  # node_linear_25\n",
              "                    %\"linear_25\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_13\", %\"val_893\"{...})\n",
              "             405 |  # node_add_1137\n",
              "                    %\"add_1137\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1016\", %\"linear_25\")\n",
              "             406 |  # node_layer_norm_13\n",
              "                    %\"layer_norm_13\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1137\", %\"model.layers.6.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             407 |  # node_linear_26\n",
              "                    %\"linear_26\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_13\", %\"val_896\"{...})\n",
              "             408 |  # node_Split_2829\n",
              "                    %\"split_6_split_0\"<FLOAT,[1,s53,1152]>, %\"split_6_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_26\") {axis=2, num_outputs=2}\n",
              "             409 |  # node_Div_870\n",
              "                    %\"val_898\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_6_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             410 |  # node_Erf_871\n",
              "                    %\"val_899\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_898\")\n",
              "             411 |  # node_Add_873\n",
              "                    %\"val_901\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_899\", %\"clone\"{1.0})\n",
              "             412 |  # node_Mul_875\n",
              "                    %\"val_903\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_901\")\n",
              "             413 |  # node_gelu_6\n",
              "                    %\"gelu_6\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_6_split_0\", %\"val_903\")\n",
              "             414 |  # node_mul_1128\n",
              "                    %\"mul_1128\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_6\", %\"split_6_split_1\")\n",
              "             415 |  # node_linear_27\n",
              "                    %\"linear_27\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_1128\", %\"val_904\"{...})\n",
              "             416 |  # node_add_1165\n",
              "                    %\"add_1165\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1137\", %\"linear_27\")\n",
              "             417 |  # node_layer_norm_14\n",
              "                    %\"layer_norm_14\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1165\", %\"model.layers.7.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             418 |  # node_linear_28\n",
              "                    %\"linear_28\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_14\", %\"val_907\"{...})\n",
              "             419 |  # node_view_14\n",
              "                    %\"view_14\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_28\", %\"val_54\") {allowzero=1}\n",
              "             420 |  # node_transpose_22\n",
              "                    %\"transpose_22\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_14\") {perm=(0, 3, 2, 1, 4)}\n",
              "             421 |  # node_Slice_903\n",
              "                    %\"val_933\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_22\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             422 |  # node_unbind_7__0\n",
              "                    %\"getitem_35\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_933\", %\"val_21\"{[2]})\n",
              "             423 |  # node_Slice_907\n",
              "                    %\"val_937\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_22\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             424 |  # node_unbind_7__1\n",
              "                    %\"getitem_36\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_937\", %\"val_21\"{[2]})\n",
              "             425 |  # node_Slice_911\n",
              "                    %\"val_941\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_22\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             426 |  # node_unbind_7__2\n",
              "                    %\"getitem_37\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_941\", %\"val_21\"{[2]})\n",
              "             427 |  # node_mul_1202\n",
              "                    %\"mul_1202\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_35\", %\"unsqueeze_14\")\n",
              "             428 |  # node_slice_39\n",
              "                    %\"slice_39\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_35\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             429 |  # node_slice_40\n",
              "                    %\"slice_40\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_35\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             430 |  # node_neg_14\n",
              "                    %\"neg_14\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_40\")\n",
              "             431 |  # node_cat_22\n",
              "                    %\"cat_22\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_14\", %\"slice_39\") {axis=-1}\n",
              "             432 |  # node_mul_1219\n",
              "                    %\"mul_1219\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_22\", %\"unsqueeze_15\")\n",
              "             433 |  # node_add_1245\n",
              "                    %\"add_1245\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1202\", %\"mul_1219\")\n",
              "             434 |  # node_mul_1227\n",
              "                    %\"mul_1227\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_36\", %\"unsqueeze_14\")\n",
              "             435 |  # node_slice_41\n",
              "                    %\"slice_41\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_36\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             436 |  # node_slice_42\n",
              "                    %\"slice_42\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_36\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             437 |  # node_neg_15\n",
              "                    %\"neg_15\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_42\")\n",
              "             438 |  # node_cat_23\n",
              "                    %\"cat_23\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_15\", %\"slice_41\") {axis=-1}\n",
              "             439 |  # node_mul_1244\n",
              "                    %\"mul_1244\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_23\", %\"unsqueeze_15\")\n",
              "             440 |  # node_add_1269\n",
              "                    %\"add_1269\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1227\", %\"mul_1244\")\n",
              "             441 |  # node_Shape_961\n",
              "                    %\"val_991\"<INT64,[4]> ⬅️ ::Shape(%\"add_1269\") {start=0}\n",
              "             442 |  # node_Slice_963\n",
              "                    %\"val_993\"<INT64,[1]> ⬅️ ::Slice(%\"val_991\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             443 |  # node_Slice_964\n",
              "                    %\"val_994\"<INT64,[1]> ⬅️ ::Slice(%\"val_991\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             444 |  # node_Slice_966\n",
              "                    %\"val_996\"<INT64,[2]> ⬅️ ::Slice(%\"val_991\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             445 |  # node_Concat_968\n",
              "                    %\"val_998\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_994\", %\"val_993\") {axis=0}\n",
              "             446 |  # node_Reshape_969\n",
              "                    %\"val_999\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_1269\", %\"val_998\") {allowzero=0}\n",
              "             447 |  # node_Transpose_970\n",
              "                    %\"val_1000\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_999\") {perm=(0, 2, 1)}\n",
              "             448 |  # node_Concat_971\n",
              "                    %\"val_1001\"<INT64,[4]> ⬅️ ::Concat(%\"val_996\", %\"val_993\", %\"val_994\") {axis=0}\n",
              "             449 |  # node_Reshape_972\n",
              "                    %\"val_1002\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1000\", %\"val_1001\") {allowzero=0}\n",
              "             450 |  # node_Mul_974\n",
              "                    %\"val_1004\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1245\", %\"val_147\"{[0.3535533845424652]})\n",
              "             451 |  # node_Mul_976\n",
              "                    %\"val_1006\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1002\", %\"val_147\"{[0.3535533845424652]})\n",
              "             452 |  # node_MatMul_977\n",
              "                    %\"val_1007\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1004\", %\"val_1006\")\n",
              "             453 |  # node_Add_978\n",
              "                    %\"val_1008\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1007\", %\"masked_fill_1\")\n",
              "             454 |  # node_Softmax_979\n",
              "                    %\"val_1009\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1008\") {axis=-1}\n",
              "             455 |  # node_scaled_dot_product_attention_7\n",
              "                    %\"scaled_dot_product_attention_7\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1009\", %\"getitem_37\")\n",
              "             456 |  # node_transpose_23\n",
              "                    %\"transpose_23\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_7\") {perm=(0, 2, 1, 3)}\n",
              "             457 |  # node_view_15\n",
              "                    %\"view_15\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_23\", %\"val_158\") {allowzero=1}\n",
              "             458 |  # node_linear_29\n",
              "                    %\"linear_29\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_15\", %\"val_1015\"{...})\n",
              "             459 |  # node_add_1286\n",
              "                    %\"add_1286\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1165\", %\"linear_29\")\n",
              "             460 |  # node_layer_norm_15\n",
              "                    %\"layer_norm_15\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1286\", %\"model.layers.7.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             461 |  # node_linear_30\n",
              "                    %\"linear_30\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_15\", %\"val_1018\"{...})\n",
              "             462 |  # node_Split_2852\n",
              "                    %\"split_7_split_0\"<FLOAT,[1,s53,1152]>, %\"split_7_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_30\") {axis=2, num_outputs=2}\n",
              "             463 |  # node_Div_988\n",
              "                    %\"val_1020\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_7_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             464 |  # node_Erf_989\n",
              "                    %\"val_1021\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1020\")\n",
              "             465 |  # node_Add_991\n",
              "                    %\"val_1023\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1021\", %\"clone\"{1.0})\n",
              "             466 |  # node_Mul_993\n",
              "                    %\"val_1025\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1023\")\n",
              "             467 |  # node_gelu_7\n",
              "                    %\"gelu_7\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_7_split_0\", %\"val_1025\")\n",
              "             468 |  # node_mul_1282\n",
              "                    %\"mul_1282\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_7\", %\"split_7_split_1\")\n",
              "             469 |  # node_linear_31\n",
              "                    %\"linear_31\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_1282\", %\"val_1026\"{...})\n",
              "             470 |  # node_add_1314\n",
              "                    %\"add_1314\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1286\", %\"linear_31\")\n",
              "             471 |  # node_layer_norm_16\n",
              "                    %\"layer_norm_16\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1314\", %\"model.layers.8.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             472 |  # node_linear_32\n",
              "                    %\"linear_32\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_16\", %\"val_1029\"{...})\n",
              "             473 |  # node_view_16\n",
              "                    %\"view_16\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_32\", %\"val_54\") {allowzero=1}\n",
              "             474 |  # node_transpose_25\n",
              "                    %\"transpose_25\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_16\") {perm=(0, 3, 2, 1, 4)}\n",
              "             475 |  # node_Slice_1021\n",
              "                    %\"val_1055\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_25\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             476 |  # node_unbind_8__0\n",
              "                    %\"getitem_40\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1055\", %\"val_21\"{[2]})\n",
              "             477 |  # node_Slice_1025\n",
              "                    %\"val_1059\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_25\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             478 |  # node_unbind_8__1\n",
              "                    %\"getitem_41\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1059\", %\"val_21\"{[2]})\n",
              "             479 |  # node_Slice_1029\n",
              "                    %\"val_1063\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_25\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             480 |  # node_unbind_8__2\n",
              "                    %\"getitem_42\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1063\", %\"val_21\"{[2]})\n",
              "             481 |  # node_mul_1356\n",
              "                    %\"mul_1356\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_40\", %\"unsqueeze_14\")\n",
              "             482 |  # node_slice_44\n",
              "                    %\"slice_44\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_40\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             483 |  # node_slice_45\n",
              "                    %\"slice_45\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_40\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             484 |  # node_neg_16\n",
              "                    %\"neg_16\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_45\")\n",
              "             485 |  # node_cat_25\n",
              "                    %\"cat_25\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_16\", %\"slice_44\") {axis=-1}\n",
              "             486 |  # node_mul_1373\n",
              "                    %\"mul_1373\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_25\", %\"unsqueeze_15\")\n",
              "             487 |  # node_add_1394\n",
              "                    %\"add_1394\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1356\", %\"mul_1373\")\n",
              "             488 |  # node_mul_1381\n",
              "                    %\"mul_1381\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_41\", %\"unsqueeze_14\")\n",
              "             489 |  # node_slice_46\n",
              "                    %\"slice_46\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_41\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             490 |  # node_slice_47\n",
              "                    %\"slice_47\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_41\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             491 |  # node_neg_17\n",
              "                    %\"neg_17\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_47\")\n",
              "             492 |  # node_cat_26\n",
              "                    %\"cat_26\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_17\", %\"slice_46\") {axis=-1}\n",
              "             493 |  # node_mul_1398\n",
              "                    %\"mul_1398\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_26\", %\"unsqueeze_15\")\n",
              "             494 |  # node_add_1418\n",
              "                    %\"add_1418\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1381\", %\"mul_1398\")\n",
              "             495 |  # node_Shape_1079\n",
              "                    %\"val_1113\"<INT64,[4]> ⬅️ ::Shape(%\"add_1418\") {start=0}\n",
              "             496 |  # node_Slice_1081\n",
              "                    %\"val_1115\"<INT64,[1]> ⬅️ ::Slice(%\"val_1113\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             497 |  # node_Slice_1082\n",
              "                    %\"val_1116\"<INT64,[1]> ⬅️ ::Slice(%\"val_1113\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             498 |  # node_Slice_1084\n",
              "                    %\"val_1118\"<INT64,[2]> ⬅️ ::Slice(%\"val_1113\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             499 |  # node_Concat_1086\n",
              "                    %\"val_1120\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1116\", %\"val_1115\") {axis=0}\n",
              "             500 |  # node_Reshape_1087\n",
              "                    %\"val_1121\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_1418\", %\"val_1120\") {allowzero=0}\n",
              "             501 |  # node_Transpose_1088\n",
              "                    %\"val_1122\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1121\") {perm=(0, 2, 1)}\n",
              "             502 |  # node_Concat_1089\n",
              "                    %\"val_1123\"<INT64,[4]> ⬅️ ::Concat(%\"val_1118\", %\"val_1115\", %\"val_1116\") {axis=0}\n",
              "             503 |  # node_Reshape_1090\n",
              "                    %\"val_1124\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1122\", %\"val_1123\") {allowzero=0}\n",
              "             504 |  # node_Mul_1092\n",
              "                    %\"val_1126\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1394\", %\"val_147\"{[0.3535533845424652]})\n",
              "             505 |  # node_Mul_1094\n",
              "                    %\"val_1128\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1124\", %\"val_147\"{[0.3535533845424652]})\n",
              "             506 |  # node_MatMul_1095\n",
              "                    %\"val_1129\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1126\", %\"val_1128\")\n",
              "             507 |  # node_Add_1096\n",
              "                    %\"val_1130\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1129\", %\"masked_fill_1\")\n",
              "             508 |  # node_Softmax_1097\n",
              "                    %\"val_1131\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1130\") {axis=-1}\n",
              "             509 |  # node_scaled_dot_product_attention_8\n",
              "                    %\"scaled_dot_product_attention_8\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1131\", %\"getitem_42\")\n",
              "             510 |  # node_transpose_26\n",
              "                    %\"transpose_26\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_8\") {perm=(0, 2, 1, 3)}\n",
              "             511 |  # node_view_17\n",
              "                    %\"view_17\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_26\", %\"val_158\") {allowzero=1}\n",
              "             512 |  # node_linear_33\n",
              "                    %\"linear_33\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_17\", %\"val_1137\"{...})\n",
              "             513 |  # node_add_1435\n",
              "                    %\"add_1435\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1314\", %\"linear_33\")\n",
              "             514 |  # node_layer_norm_17\n",
              "                    %\"layer_norm_17\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1435\", %\"model.layers.8.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             515 |  # node_linear_34\n",
              "                    %\"linear_34\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_17\", %\"val_1140\"{...})\n",
              "             516 |  # node_Split_2875\n",
              "                    %\"split_8_split_0\"<FLOAT,[1,s53,1152]>, %\"split_8_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_34\") {axis=2, num_outputs=2}\n",
              "             517 |  # node_Div_1106\n",
              "                    %\"val_1142\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_8_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             518 |  # node_Erf_1107\n",
              "                    %\"val_1143\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1142\")\n",
              "             519 |  # node_Add_1109\n",
              "                    %\"val_1145\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1143\", %\"clone\"{1.0})\n",
              "             520 |  # node_Mul_1111\n",
              "                    %\"val_1147\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1145\")\n",
              "             521 |  # node_gelu_8\n",
              "                    %\"gelu_8\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_8_split_0\", %\"val_1147\")\n",
              "             522 |  # node_mul_1436\n",
              "                    %\"mul_1436\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_8\", %\"split_8_split_1\")\n",
              "             523 |  # node_linear_35\n",
              "                    %\"linear_35\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_1436\", %\"val_1148\"{...})\n",
              "             524 |  # node_add_1463\n",
              "                    %\"add_1463\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1435\", %\"linear_35\")\n",
              "             525 |  # node_layer_norm_18\n",
              "                    %\"layer_norm_18\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1463\", %\"model.layers.9.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             526 |  # node_linear_36\n",
              "                    %\"linear_36\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_18\", %\"val_1151\"{...})\n",
              "             527 |  # node_view_18\n",
              "                    %\"view_18\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_36\", %\"val_54\") {allowzero=1}\n",
              "             528 |  # node_transpose_28\n",
              "                    %\"transpose_28\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_18\") {perm=(0, 3, 2, 1, 4)}\n",
              "             529 |  # node_Slice_1139\n",
              "                    %\"val_1177\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_28\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             530 |  # node_unbind_9__0\n",
              "                    %\"getitem_45\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1177\", %\"val_21\"{[2]})\n",
              "             531 |  # node_Slice_1143\n",
              "                    %\"val_1181\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_28\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             532 |  # node_unbind_9__1\n",
              "                    %\"getitem_46\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1181\", %\"val_21\"{[2]})\n",
              "             533 |  # node_Slice_1147\n",
              "                    %\"val_1185\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_28\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             534 |  # node_unbind_9__2\n",
              "                    %\"getitem_47\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1185\", %\"val_21\"{[2]})\n",
              "             535 |  # node_mul_1510\n",
              "                    %\"mul_1510\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_45\", %\"unsqueeze_9\")\n",
              "             536 |  # node_slice_49\n",
              "                    %\"slice_49\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_45\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             537 |  # node_slice_50\n",
              "                    %\"slice_50\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_45\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             538 |  # node_neg_18\n",
              "                    %\"neg_18\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_50\")\n",
              "             539 |  # node_cat_28\n",
              "                    %\"cat_28\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_18\", %\"slice_49\") {axis=-1}\n",
              "             540 |  # node_mul_1527\n",
              "                    %\"mul_1527\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_28\", %\"unsqueeze_10\")\n",
              "             541 |  # node_add_1543\n",
              "                    %\"add_1543\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1510\", %\"mul_1527\")\n",
              "             542 |  # node_mul_1535\n",
              "                    %\"mul_1535\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_46\", %\"unsqueeze_9\")\n",
              "             543 |  # node_slice_51\n",
              "                    %\"slice_51\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_46\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             544 |  # node_slice_52\n",
              "                    %\"slice_52\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_46\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             545 |  # node_neg_19\n",
              "                    %\"neg_19\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_52\")\n",
              "             546 |  # node_cat_29\n",
              "                    %\"cat_29\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_19\", %\"slice_51\") {axis=-1}\n",
              "             547 |  # node_mul_1552\n",
              "                    %\"mul_1552\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_29\", %\"unsqueeze_10\")\n",
              "             548 |  # node_add_1567\n",
              "                    %\"add_1567\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1535\", %\"mul_1552\")\n",
              "             549 |  # node_Shape_1197\n",
              "                    %\"val_1235\"<INT64,[4]> ⬅️ ::Shape(%\"add_1567\") {start=0}\n",
              "             550 |  # node_Slice_1199\n",
              "                    %\"val_1237\"<INT64,[1]> ⬅️ ::Slice(%\"val_1235\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             551 |  # node_Slice_1200\n",
              "                    %\"val_1238\"<INT64,[1]> ⬅️ ::Slice(%\"val_1235\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             552 |  # node_Slice_1202\n",
              "                    %\"val_1240\"<INT64,[2]> ⬅️ ::Slice(%\"val_1235\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             553 |  # node_Concat_1204\n",
              "                    %\"val_1242\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1238\", %\"val_1237\") {axis=0}\n",
              "             554 |  # node_Reshape_1205\n",
              "                    %\"val_1243\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_1567\", %\"val_1242\") {allowzero=0}\n",
              "             555 |  # node_Transpose_1206\n",
              "                    %\"val_1244\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1243\") {perm=(0, 2, 1)}\n",
              "             556 |  # node_Concat_1207\n",
              "                    %\"val_1245\"<INT64,[4]> ⬅️ ::Concat(%\"val_1240\", %\"val_1237\", %\"val_1238\") {axis=0}\n",
              "             557 |  # node_Reshape_1208\n",
              "                    %\"val_1246\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1244\", %\"val_1245\") {allowzero=0}\n",
              "             558 |  # node_Mul_1210\n",
              "                    %\"val_1248\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1543\", %\"val_147\"{[0.3535533845424652]})\n",
              "             559 |  # node_Mul_1212\n",
              "                    %\"val_1250\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1246\", %\"val_147\"{[0.3535533845424652]})\n",
              "             560 |  # node_MatMul_1213\n",
              "                    %\"val_1251\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1248\", %\"val_1250\")\n",
              "             561 |  # node_Add_1214\n",
              "                    %\"val_1252\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1251\", %\"masked_fill\")\n",
              "             562 |  # node_Softmax_1215\n",
              "                    %\"val_1253\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1252\") {axis=-1}\n",
              "             563 |  # node_scaled_dot_product_attention_9\n",
              "                    %\"scaled_dot_product_attention_9\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1253\", %\"getitem_47\")\n",
              "             564 |  # node_transpose_29\n",
              "                    %\"transpose_29\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_9\") {perm=(0, 2, 1, 3)}\n",
              "             565 |  # node_view_19\n",
              "                    %\"view_19\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_29\", %\"val_158\") {allowzero=1}\n",
              "             566 |  # node_linear_37\n",
              "                    %\"linear_37\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_19\", %\"val_1259\"{...})\n",
              "             567 |  # node_add_1584\n",
              "                    %\"add_1584\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1463\", %\"linear_37\")\n",
              "             568 |  # node_layer_norm_19\n",
              "                    %\"layer_norm_19\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1584\", %\"model.layers.9.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             569 |  # node_linear_38\n",
              "                    %\"linear_38\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_19\", %\"val_1262\"{...})\n",
              "             570 |  # node_Split_2898\n",
              "                    %\"split_9_split_0\"<FLOAT,[1,s53,1152]>, %\"split_9_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_38\") {axis=2, num_outputs=2}\n",
              "             571 |  # node_Div_1224\n",
              "                    %\"val_1264\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_9_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             572 |  # node_Erf_1225\n",
              "                    %\"val_1265\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1264\")\n",
              "             573 |  # node_Add_1227\n",
              "                    %\"val_1267\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1265\", %\"clone\"{1.0})\n",
              "             574 |  # node_Mul_1229\n",
              "                    %\"val_1269\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1267\")\n",
              "             575 |  # node_gelu_9\n",
              "                    %\"gelu_9\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_9_split_0\", %\"val_1269\")\n",
              "             576 |  # node_mul_1590\n",
              "                    %\"mul_1590\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_9\", %\"split_9_split_1\")\n",
              "             577 |  # node_linear_39\n",
              "                    %\"linear_39\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_1590\", %\"val_1270\"{...})\n",
              "             578 |  # node_add_1612\n",
              "                    %\"add_1612\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1584\", %\"linear_39\")\n",
              "             579 |  # node_layer_norm_20\n",
              "                    %\"layer_norm_20\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1612\", %\"model.layers.10.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             580 |  # node_linear_40\n",
              "                    %\"linear_40\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_20\", %\"val_1273\"{...})\n",
              "             581 |  # node_view_20\n",
              "                    %\"view_20\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_40\", %\"val_54\") {allowzero=1}\n",
              "             582 |  # node_transpose_31\n",
              "                    %\"transpose_31\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_20\") {perm=(0, 3, 2, 1, 4)}\n",
              "             583 |  # node_Slice_1257\n",
              "                    %\"val_1299\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_31\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             584 |  # node_unbind_10__0\n",
              "                    %\"getitem_50\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1299\", %\"val_21\"{[2]})\n",
              "             585 |  # node_Slice_1261\n",
              "                    %\"val_1303\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_31\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             586 |  # node_unbind_10__1\n",
              "                    %\"getitem_51\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1303\", %\"val_21\"{[2]})\n",
              "             587 |  # node_Slice_1265\n",
              "                    %\"val_1307\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_31\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             588 |  # node_unbind_10__2\n",
              "                    %\"getitem_52\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1307\", %\"val_21\"{[2]})\n",
              "             589 |  # node_mul_1664\n",
              "                    %\"mul_1664\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_50\", %\"unsqueeze_14\")\n",
              "             590 |  # node_slice_54\n",
              "                    %\"slice_54\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_50\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             591 |  # node_slice_55\n",
              "                    %\"slice_55\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_50\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             592 |  # node_neg_20\n",
              "                    %\"neg_20\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_55\")\n",
              "             593 |  # node_cat_31\n",
              "                    %\"cat_31\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_20\", %\"slice_54\") {axis=-1}\n",
              "             594 |  # node_mul_1681\n",
              "                    %\"mul_1681\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_31\", %\"unsqueeze_15\")\n",
              "             595 |  # node_add_1692\n",
              "                    %\"add_1692\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1664\", %\"mul_1681\")\n",
              "             596 |  # node_mul_1689\n",
              "                    %\"mul_1689\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_51\", %\"unsqueeze_14\")\n",
              "             597 |  # node_slice_56\n",
              "                    %\"slice_56\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_51\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             598 |  # node_slice_57\n",
              "                    %\"slice_57\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_51\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             599 |  # node_neg_21\n",
              "                    %\"neg_21\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_57\")\n",
              "             600 |  # node_cat_32\n",
              "                    %\"cat_32\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_21\", %\"slice_56\") {axis=-1}\n",
              "             601 |  # node_mul_1706\n",
              "                    %\"mul_1706\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_32\", %\"unsqueeze_15\")\n",
              "             602 |  # node_add_1716\n",
              "                    %\"add_1716\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1689\", %\"mul_1706\")\n",
              "             603 |  # node_Shape_1315\n",
              "                    %\"val_1357\"<INT64,[4]> ⬅️ ::Shape(%\"add_1716\") {start=0}\n",
              "             604 |  # node_Slice_1317\n",
              "                    %\"val_1359\"<INT64,[1]> ⬅️ ::Slice(%\"val_1357\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             605 |  # node_Slice_1318\n",
              "                    %\"val_1360\"<INT64,[1]> ⬅️ ::Slice(%\"val_1357\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             606 |  # node_Slice_1320\n",
              "                    %\"val_1362\"<INT64,[2]> ⬅️ ::Slice(%\"val_1357\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             607 |  # node_Concat_1322\n",
              "                    %\"val_1364\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1360\", %\"val_1359\") {axis=0}\n",
              "             608 |  # node_Reshape_1323\n",
              "                    %\"val_1365\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_1716\", %\"val_1364\") {allowzero=0}\n",
              "             609 |  # node_Transpose_1324\n",
              "                    %\"val_1366\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1365\") {perm=(0, 2, 1)}\n",
              "             610 |  # node_Concat_1325\n",
              "                    %\"val_1367\"<INT64,[4]> ⬅️ ::Concat(%\"val_1362\", %\"val_1359\", %\"val_1360\") {axis=0}\n",
              "             611 |  # node_Reshape_1326\n",
              "                    %\"val_1368\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1366\", %\"val_1367\") {allowzero=0}\n",
              "             612 |  # node_Mul_1328\n",
              "                    %\"val_1370\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1692\", %\"val_147\"{[0.3535533845424652]})\n",
              "             613 |  # node_Mul_1330\n",
              "                    %\"val_1372\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1368\", %\"val_147\"{[0.3535533845424652]})\n",
              "             614 |  # node_MatMul_1331\n",
              "                    %\"val_1373\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1370\", %\"val_1372\")\n",
              "             615 |  # node_Add_1332\n",
              "                    %\"val_1374\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1373\", %\"masked_fill_1\")\n",
              "             616 |  # node_Softmax_1333\n",
              "                    %\"val_1375\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1374\") {axis=-1}\n",
              "             617 |  # node_scaled_dot_product_attention_10\n",
              "                    %\"scaled_dot_product_attention_10\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1375\", %\"getitem_52\")\n",
              "             618 |  # node_transpose_32\n",
              "                    %\"transpose_32\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_10\") {perm=(0, 2, 1, 3)}\n",
              "             619 |  # node_view_21\n",
              "                    %\"view_21\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_32\", %\"val_158\") {allowzero=1}\n",
              "             620 |  # node_linear_41\n",
              "                    %\"linear_41\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_21\", %\"val_1381\"{...})\n",
              "             621 |  # node_add_1733\n",
              "                    %\"add_1733\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1612\", %\"linear_41\")\n",
              "             622 |  # node_layer_norm_21\n",
              "                    %\"layer_norm_21\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1733\", %\"model.layers.10.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             623 |  # node_linear_42\n",
              "                    %\"linear_42\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_21\", %\"val_1384\"{...})\n",
              "             624 |  # node_Split_2921\n",
              "                    %\"split_10_split_0\"<FLOAT,[1,s53,1152]>, %\"split_10_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_42\") {axis=2, num_outputs=2}\n",
              "             625 |  # node_Div_1342\n",
              "                    %\"val_1386\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_10_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             626 |  # node_Erf_1343\n",
              "                    %\"val_1387\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1386\")\n",
              "             627 |  # node_Add_1345\n",
              "                    %\"val_1389\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1387\", %\"clone\"{1.0})\n",
              "             628 |  # node_Mul_1347\n",
              "                    %\"val_1391\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1389\")\n",
              "             629 |  # node_gelu_10\n",
              "                    %\"gelu_10\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_10_split_0\", %\"val_1391\")\n",
              "             630 |  # node_mul_1744\n",
              "                    %\"mul_1744\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_10\", %\"split_10_split_1\")\n",
              "             631 |  # node_linear_43\n",
              "                    %\"linear_43\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_1744\", %\"val_1392\"{...})\n",
              "             632 |  # node_add_1761\n",
              "                    %\"add_1761\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1733\", %\"linear_43\")\n",
              "             633 |  # node_layer_norm_22\n",
              "                    %\"layer_norm_22\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1761\", %\"model.layers.11.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             634 |  # node_linear_44\n",
              "                    %\"linear_44\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_22\", %\"val_1395\"{...})\n",
              "             635 |  # node_view_22\n",
              "                    %\"view_22\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_44\", %\"val_54\") {allowzero=1}\n",
              "             636 |  # node_transpose_34\n",
              "                    %\"transpose_34\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_22\") {perm=(0, 3, 2, 1, 4)}\n",
              "             637 |  # node_Slice_1375\n",
              "                    %\"val_1421\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_34\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             638 |  # node_unbind_11__0\n",
              "                    %\"getitem_55\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1421\", %\"val_21\"{[2]})\n",
              "             639 |  # node_Slice_1379\n",
              "                    %\"val_1425\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_34\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             640 |  # node_unbind_11__1\n",
              "                    %\"getitem_56\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1425\", %\"val_21\"{[2]})\n",
              "             641 |  # node_Slice_1383\n",
              "                    %\"val_1429\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_34\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             642 |  # node_unbind_11__2\n",
              "                    %\"getitem_57\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1429\", %\"val_21\"{[2]})\n",
              "             643 |  # node_mul_1818\n",
              "                    %\"mul_1818\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_55\", %\"unsqueeze_14\")\n",
              "             644 |  # node_slice_59\n",
              "                    %\"slice_59\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_55\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             645 |  # node_slice_60\n",
              "                    %\"slice_60\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_55\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             646 |  # node_neg_22\n",
              "                    %\"neg_22\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_60\")\n",
              "             647 |  # node_cat_34\n",
              "                    %\"cat_34\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_22\", %\"slice_59\") {axis=-1}\n",
              "             648 |  # node_mul_1835\n",
              "                    %\"mul_1835\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_34\", %\"unsqueeze_15\")\n",
              "             649 |  # node_add_1841\n",
              "                    %\"add_1841\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1818\", %\"mul_1835\")\n",
              "             650 |  # node_mul_1843\n",
              "                    %\"mul_1843\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_56\", %\"unsqueeze_14\")\n",
              "             651 |  # node_slice_61\n",
              "                    %\"slice_61\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_56\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             652 |  # node_slice_62\n",
              "                    %\"slice_62\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_56\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             653 |  # node_neg_23\n",
              "                    %\"neg_23\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_62\")\n",
              "             654 |  # node_cat_35\n",
              "                    %\"cat_35\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_23\", %\"slice_61\") {axis=-1}\n",
              "             655 |  # node_mul_1860\n",
              "                    %\"mul_1860\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_35\", %\"unsqueeze_15\")\n",
              "             656 |  # node_add_1865\n",
              "                    %\"add_1865\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1843\", %\"mul_1860\")\n",
              "             657 |  # node_Shape_1433\n",
              "                    %\"val_1479\"<INT64,[4]> ⬅️ ::Shape(%\"add_1865\") {start=0}\n",
              "             658 |  # node_Slice_1435\n",
              "                    %\"val_1481\"<INT64,[1]> ⬅️ ::Slice(%\"val_1479\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             659 |  # node_Slice_1436\n",
              "                    %\"val_1482\"<INT64,[1]> ⬅️ ::Slice(%\"val_1479\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             660 |  # node_Slice_1438\n",
              "                    %\"val_1484\"<INT64,[2]> ⬅️ ::Slice(%\"val_1479\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             661 |  # node_Concat_1440\n",
              "                    %\"val_1486\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1482\", %\"val_1481\") {axis=0}\n",
              "             662 |  # node_Reshape_1441\n",
              "                    %\"val_1487\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_1865\", %\"val_1486\") {allowzero=0}\n",
              "             663 |  # node_Transpose_1442\n",
              "                    %\"val_1488\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1487\") {perm=(0, 2, 1)}\n",
              "             664 |  # node_Concat_1443\n",
              "                    %\"val_1489\"<INT64,[4]> ⬅️ ::Concat(%\"val_1484\", %\"val_1481\", %\"val_1482\") {axis=0}\n",
              "             665 |  # node_Reshape_1444\n",
              "                    %\"val_1490\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1488\", %\"val_1489\") {allowzero=0}\n",
              "             666 |  # node_Mul_1446\n",
              "                    %\"val_1492\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1841\", %\"val_147\"{[0.3535533845424652]})\n",
              "             667 |  # node_Mul_1448\n",
              "                    %\"val_1494\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1490\", %\"val_147\"{[0.3535533845424652]})\n",
              "             668 |  # node_MatMul_1449\n",
              "                    %\"val_1495\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1492\", %\"val_1494\")\n",
              "             669 |  # node_Add_1450\n",
              "                    %\"val_1496\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1495\", %\"masked_fill_1\")\n",
              "             670 |  # node_Softmax_1451\n",
              "                    %\"val_1497\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1496\") {axis=-1}\n",
              "             671 |  # node_scaled_dot_product_attention_11\n",
              "                    %\"scaled_dot_product_attention_11\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1497\", %\"getitem_57\")\n",
              "             672 |  # node_transpose_35\n",
              "                    %\"transpose_35\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_11\") {perm=(0, 2, 1, 3)}\n",
              "             673 |  # node_view_23\n",
              "                    %\"view_23\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_35\", %\"val_158\") {allowzero=1}\n",
              "             674 |  # node_linear_45\n",
              "                    %\"linear_45\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_23\", %\"val_1503\"{...})\n",
              "             675 |  # node_add_1882\n",
              "                    %\"add_1882\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1761\", %\"linear_45\")\n",
              "             676 |  # node_layer_norm_23\n",
              "                    %\"layer_norm_23\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1882\", %\"model.layers.11.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             677 |  # node_linear_46\n",
              "                    %\"linear_46\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_23\", %\"val_1506\"{...})\n",
              "             678 |  # node_Split_2944\n",
              "                    %\"split_11_split_0\"<FLOAT,[1,s53,1152]>, %\"split_11_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_46\") {axis=2, num_outputs=2}\n",
              "             679 |  # node_Div_1460\n",
              "                    %\"val_1508\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_11_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             680 |  # node_Erf_1461\n",
              "                    %\"val_1509\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1508\")\n",
              "             681 |  # node_Add_1463\n",
              "                    %\"val_1511\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1509\", %\"clone\"{1.0})\n",
              "             682 |  # node_Mul_1465\n",
              "                    %\"val_1513\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1511\")\n",
              "             683 |  # node_gelu_11\n",
              "                    %\"gelu_11\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_11_split_0\", %\"val_1513\")\n",
              "             684 |  # node_mul_1898\n",
              "                    %\"mul_1898\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_11\", %\"split_11_split_1\")\n",
              "             685 |  # node_linear_47\n",
              "                    %\"linear_47\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_1898\", %\"val_1514\"{...})\n",
              "             686 |  # node_add_1910\n",
              "                    %\"add_1910\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1882\", %\"linear_47\")\n",
              "             687 |  # node_layer_norm_24\n",
              "                    %\"layer_norm_24\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_1910\", %\"model.layers.12.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             688 |  # node_linear_48\n",
              "                    %\"linear_48\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_24\", %\"val_1517\"{...})\n",
              "             689 |  # node_view_24\n",
              "                    %\"view_24\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_48\", %\"val_54\") {allowzero=1}\n",
              "             690 |  # node_transpose_37\n",
              "                    %\"transpose_37\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_24\") {perm=(0, 3, 2, 1, 4)}\n",
              "             691 |  # node_Slice_1493\n",
              "                    %\"val_1543\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_37\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             692 |  # node_unbind_12__0\n",
              "                    %\"getitem_60\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1543\", %\"val_21\"{[2]})\n",
              "             693 |  # node_Slice_1497\n",
              "                    %\"val_1547\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_37\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             694 |  # node_unbind_12__1\n",
              "                    %\"getitem_61\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1547\", %\"val_21\"{[2]})\n",
              "             695 |  # node_Slice_1501\n",
              "                    %\"val_1551\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_37\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             696 |  # node_unbind_12__2\n",
              "                    %\"getitem_62\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1551\", %\"val_21\"{[2]})\n",
              "             697 |  # node_mul_1972\n",
              "                    %\"mul_1972\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_60\", %\"unsqueeze_9\")\n",
              "             698 |  # node_slice_64\n",
              "                    %\"slice_64\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_60\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             699 |  # node_slice_65\n",
              "                    %\"slice_65\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_60\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             700 |  # node_neg_24\n",
              "                    %\"neg_24\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_65\")\n",
              "             701 |  # node_cat_37\n",
              "                    %\"cat_37\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_24\", %\"slice_64\") {axis=-1}\n",
              "             702 |  # node_mul_1989\n",
              "                    %\"mul_1989\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_37\", %\"unsqueeze_10\")\n",
              "             703 |  # node_add_1990\n",
              "                    %\"add_1990\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1972\", %\"mul_1989\")\n",
              "             704 |  # node_mul_1997\n",
              "                    %\"mul_1997\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_61\", %\"unsqueeze_9\")\n",
              "             705 |  # node_slice_66\n",
              "                    %\"slice_66\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_61\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             706 |  # node_slice_67\n",
              "                    %\"slice_67\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_61\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             707 |  # node_neg_25\n",
              "                    %\"neg_25\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_67\")\n",
              "             708 |  # node_cat_38\n",
              "                    %\"cat_38\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_25\", %\"slice_66\") {axis=-1}\n",
              "             709 |  # node_mul_2014\n",
              "                    %\"mul_2014\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_38\", %\"unsqueeze_10\")\n",
              "             710 |  # node_add_2014\n",
              "                    %\"add_2014\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_1997\", %\"mul_2014\")\n",
              "             711 |  # node_Shape_1551\n",
              "                    %\"val_1601\"<INT64,[4]> ⬅️ ::Shape(%\"add_2014\") {start=0}\n",
              "             712 |  # node_Slice_1553\n",
              "                    %\"val_1603\"<INT64,[1]> ⬅️ ::Slice(%\"val_1601\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             713 |  # node_Slice_1554\n",
              "                    %\"val_1604\"<INT64,[1]> ⬅️ ::Slice(%\"val_1601\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             714 |  # node_Slice_1556\n",
              "                    %\"val_1606\"<INT64,[2]> ⬅️ ::Slice(%\"val_1601\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             715 |  # node_Concat_1558\n",
              "                    %\"val_1608\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1604\", %\"val_1603\") {axis=0}\n",
              "             716 |  # node_Reshape_1559\n",
              "                    %\"val_1609\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2014\", %\"val_1608\") {allowzero=0}\n",
              "             717 |  # node_Transpose_1560\n",
              "                    %\"val_1610\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1609\") {perm=(0, 2, 1)}\n",
              "             718 |  # node_Concat_1561\n",
              "                    %\"val_1611\"<INT64,[4]> ⬅️ ::Concat(%\"val_1606\", %\"val_1603\", %\"val_1604\") {axis=0}\n",
              "             719 |  # node_Reshape_1562\n",
              "                    %\"val_1612\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1610\", %\"val_1611\") {allowzero=0}\n",
              "             720 |  # node_Mul_1564\n",
              "                    %\"val_1614\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_1990\", %\"val_147\"{[0.3535533845424652]})\n",
              "             721 |  # node_Mul_1566\n",
              "                    %\"val_1616\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1612\", %\"val_147\"{[0.3535533845424652]})\n",
              "             722 |  # node_MatMul_1567\n",
              "                    %\"val_1617\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1614\", %\"val_1616\")\n",
              "             723 |  # node_Add_1568\n",
              "                    %\"val_1618\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1617\", %\"masked_fill\")\n",
              "             724 |  # node_Softmax_1569\n",
              "                    %\"val_1619\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1618\") {axis=-1}\n",
              "             725 |  # node_scaled_dot_product_attention_12\n",
              "                    %\"scaled_dot_product_attention_12\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1619\", %\"getitem_62\")\n",
              "             726 |  # node_transpose_38\n",
              "                    %\"transpose_38\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_12\") {perm=(0, 2, 1, 3)}\n",
              "             727 |  # node_view_25\n",
              "                    %\"view_25\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_38\", %\"val_158\") {allowzero=1}\n",
              "             728 |  # node_linear_49\n",
              "                    %\"linear_49\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_25\", %\"val_1625\"{...})\n",
              "             729 |  # node_add_2031\n",
              "                    %\"add_2031\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_1910\", %\"linear_49\")\n",
              "             730 |  # node_layer_norm_25\n",
              "                    %\"layer_norm_25\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2031\", %\"model.layers.12.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             731 |  # node_linear_50\n",
              "                    %\"linear_50\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_25\", %\"val_1628\"{...})\n",
              "             732 |  # node_Split_2967\n",
              "                    %\"split_12_split_0\"<FLOAT,[1,s53,1152]>, %\"split_12_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_50\") {axis=2, num_outputs=2}\n",
              "             733 |  # node_Div_1578\n",
              "                    %\"val_1630\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_12_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             734 |  # node_Erf_1579\n",
              "                    %\"val_1631\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1630\")\n",
              "             735 |  # node_Add_1581\n",
              "                    %\"val_1633\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1631\", %\"clone\"{1.0})\n",
              "             736 |  # node_Mul_1583\n",
              "                    %\"val_1635\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1633\")\n",
              "             737 |  # node_gelu_12\n",
              "                    %\"gelu_12\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_12_split_0\", %\"val_1635\")\n",
              "             738 |  # node_mul_2052\n",
              "                    %\"mul_2052\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_12\", %\"split_12_split_1\")\n",
              "             739 |  # node_linear_51\n",
              "                    %\"linear_51\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2052\", %\"val_1636\"{...})\n",
              "             740 |  # node_add_2059\n",
              "                    %\"add_2059\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2031\", %\"linear_51\")\n",
              "             741 |  # node_layer_norm_26\n",
              "                    %\"layer_norm_26\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2059\", %\"model.layers.13.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             742 |  # node_linear_52\n",
              "                    %\"linear_52\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_26\", %\"val_1639\"{...})\n",
              "             743 |  # node_view_26\n",
              "                    %\"view_26\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_52\", %\"val_54\") {allowzero=1}\n",
              "             744 |  # node_transpose_40\n",
              "                    %\"transpose_40\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_26\") {perm=(0, 3, 2, 1, 4)}\n",
              "             745 |  # node_Slice_1611\n",
              "                    %\"val_1665\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_40\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             746 |  # node_unbind_13__0\n",
              "                    %\"getitem_65\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1665\", %\"val_21\"{[2]})\n",
              "             747 |  # node_Slice_1615\n",
              "                    %\"val_1669\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_40\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             748 |  # node_unbind_13__1\n",
              "                    %\"getitem_66\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1669\", %\"val_21\"{[2]})\n",
              "             749 |  # node_Slice_1619\n",
              "                    %\"val_1673\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_40\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             750 |  # node_unbind_13__2\n",
              "                    %\"getitem_67\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1673\", %\"val_21\"{[2]})\n",
              "             751 |  # node_mul_2126\n",
              "                    %\"mul_2126\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_65\", %\"unsqueeze_14\")\n",
              "             752 |  # node_slice_69\n",
              "                    %\"slice_69\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_65\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             753 |  # node_slice_70\n",
              "                    %\"slice_70\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_65\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             754 |  # node_neg_26\n",
              "                    %\"neg_26\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_70\")\n",
              "             755 |  # node_cat_40\n",
              "                    %\"cat_40\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_26\", %\"slice_69\") {axis=-1}\n",
              "             756 |  # node_mul_2143\n",
              "                    %\"mul_2143\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_40\", %\"unsqueeze_15\")\n",
              "             757 |  # node_add_2139\n",
              "                    %\"add_2139\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2126\", %\"mul_2143\")\n",
              "             758 |  # node_mul_2151\n",
              "                    %\"mul_2151\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_66\", %\"unsqueeze_14\")\n",
              "             759 |  # node_slice_71\n",
              "                    %\"slice_71\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_66\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             760 |  # node_slice_72\n",
              "                    %\"slice_72\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_66\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             761 |  # node_neg_27\n",
              "                    %\"neg_27\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_72\")\n",
              "             762 |  # node_cat_41\n",
              "                    %\"cat_41\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_27\", %\"slice_71\") {axis=-1}\n",
              "             763 |  # node_mul_2168\n",
              "                    %\"mul_2168\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_41\", %\"unsqueeze_15\")\n",
              "             764 |  # node_add_2163\n",
              "                    %\"add_2163\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2151\", %\"mul_2168\")\n",
              "             765 |  # node_Shape_1669\n",
              "                    %\"val_1723\"<INT64,[4]> ⬅️ ::Shape(%\"add_2163\") {start=0}\n",
              "             766 |  # node_Slice_1671\n",
              "                    %\"val_1725\"<INT64,[1]> ⬅️ ::Slice(%\"val_1723\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             767 |  # node_Slice_1672\n",
              "                    %\"val_1726\"<INT64,[1]> ⬅️ ::Slice(%\"val_1723\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             768 |  # node_Slice_1674\n",
              "                    %\"val_1728\"<INT64,[2]> ⬅️ ::Slice(%\"val_1723\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             769 |  # node_Concat_1676\n",
              "                    %\"val_1730\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1726\", %\"val_1725\") {axis=0}\n",
              "             770 |  # node_Reshape_1677\n",
              "                    %\"val_1731\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2163\", %\"val_1730\") {allowzero=0}\n",
              "             771 |  # node_Transpose_1678\n",
              "                    %\"val_1732\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1731\") {perm=(0, 2, 1)}\n",
              "             772 |  # node_Concat_1679\n",
              "                    %\"val_1733\"<INT64,[4]> ⬅️ ::Concat(%\"val_1728\", %\"val_1725\", %\"val_1726\") {axis=0}\n",
              "             773 |  # node_Reshape_1680\n",
              "                    %\"val_1734\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1732\", %\"val_1733\") {allowzero=0}\n",
              "             774 |  # node_Mul_1682\n",
              "                    %\"val_1736\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_2139\", %\"val_147\"{[0.3535533845424652]})\n",
              "             775 |  # node_Mul_1684\n",
              "                    %\"val_1738\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1734\", %\"val_147\"{[0.3535533845424652]})\n",
              "             776 |  # node_MatMul_1685\n",
              "                    %\"val_1739\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1736\", %\"val_1738\")\n",
              "             777 |  # node_Add_1686\n",
              "                    %\"val_1740\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1739\", %\"masked_fill_1\")\n",
              "             778 |  # node_Softmax_1687\n",
              "                    %\"val_1741\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1740\") {axis=-1}\n",
              "             779 |  # node_scaled_dot_product_attention_13\n",
              "                    %\"scaled_dot_product_attention_13\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1741\", %\"getitem_67\")\n",
              "             780 |  # node_transpose_41\n",
              "                    %\"transpose_41\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_13\") {perm=(0, 2, 1, 3)}\n",
              "             781 |  # node_view_27\n",
              "                    %\"view_27\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_41\", %\"val_158\") {allowzero=1}\n",
              "             782 |  # node_linear_53\n",
              "                    %\"linear_53\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_27\", %\"val_1747\"{...})\n",
              "             783 |  # node_add_2180\n",
              "                    %\"add_2180\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2059\", %\"linear_53\")\n",
              "             784 |  # node_layer_norm_27\n",
              "                    %\"layer_norm_27\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2180\", %\"model.layers.13.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             785 |  # node_linear_54\n",
              "                    %\"linear_54\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_27\", %\"val_1750\"{...})\n",
              "             786 |  # node_Split_2990\n",
              "                    %\"split_13_split_0\"<FLOAT,[1,s53,1152]>, %\"split_13_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_54\") {axis=2, num_outputs=2}\n",
              "             787 |  # node_Div_1696\n",
              "                    %\"val_1752\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_13_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             788 |  # node_Erf_1697\n",
              "                    %\"val_1753\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1752\")\n",
              "             789 |  # node_Add_1699\n",
              "                    %\"val_1755\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1753\", %\"clone\"{1.0})\n",
              "             790 |  # node_Mul_1701\n",
              "                    %\"val_1757\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1755\")\n",
              "             791 |  # node_gelu_13\n",
              "                    %\"gelu_13\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_13_split_0\", %\"val_1757\")\n",
              "             792 |  # node_mul_2206\n",
              "                    %\"mul_2206\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_13\", %\"split_13_split_1\")\n",
              "             793 |  # node_linear_55\n",
              "                    %\"linear_55\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2206\", %\"val_1758\"{...})\n",
              "             794 |  # node_add_2208\n",
              "                    %\"add_2208\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2180\", %\"linear_55\")\n",
              "             795 |  # node_layer_norm_28\n",
              "                    %\"layer_norm_28\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2208\", %\"model.layers.14.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             796 |  # node_linear_56\n",
              "                    %\"linear_56\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_28\", %\"val_1761\"{...})\n",
              "             797 |  # node_view_28\n",
              "                    %\"view_28\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_56\", %\"val_54\") {allowzero=1}\n",
              "             798 |  # node_transpose_43\n",
              "                    %\"transpose_43\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_28\") {perm=(0, 3, 2, 1, 4)}\n",
              "             799 |  # node_Slice_1729\n",
              "                    %\"val_1787\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_43\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             800 |  # node_unbind_14__0\n",
              "                    %\"getitem_70\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1787\", %\"val_21\"{[2]})\n",
              "             801 |  # node_Slice_1733\n",
              "                    %\"val_1791\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_43\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             802 |  # node_unbind_14__1\n",
              "                    %\"getitem_71\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1791\", %\"val_21\"{[2]})\n",
              "             803 |  # node_Slice_1737\n",
              "                    %\"val_1795\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_43\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             804 |  # node_unbind_14__2\n",
              "                    %\"getitem_72\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1795\", %\"val_21\"{[2]})\n",
              "             805 |  # node_mul_2280\n",
              "                    %\"mul_2280\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_70\", %\"unsqueeze_14\")\n",
              "             806 |  # node_slice_74\n",
              "                    %\"slice_74\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_70\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             807 |  # node_slice_75\n",
              "                    %\"slice_75\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_70\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             808 |  # node_neg_28\n",
              "                    %\"neg_28\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_75\")\n",
              "             809 |  # node_cat_43\n",
              "                    %\"cat_43\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_28\", %\"slice_74\") {axis=-1}\n",
              "             810 |  # node_mul_2297\n",
              "                    %\"mul_2297\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_43\", %\"unsqueeze_15\")\n",
              "             811 |  # node_add_2288\n",
              "                    %\"add_2288\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2280\", %\"mul_2297\")\n",
              "             812 |  # node_mul_2305\n",
              "                    %\"mul_2305\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_71\", %\"unsqueeze_14\")\n",
              "             813 |  # node_slice_76\n",
              "                    %\"slice_76\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_71\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             814 |  # node_slice_77\n",
              "                    %\"slice_77\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_71\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             815 |  # node_neg_29\n",
              "                    %\"neg_29\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_77\")\n",
              "             816 |  # node_cat_44\n",
              "                    %\"cat_44\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_29\", %\"slice_76\") {axis=-1}\n",
              "             817 |  # node_mul_2322\n",
              "                    %\"mul_2322\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_44\", %\"unsqueeze_15\")\n",
              "             818 |  # node_add_2312\n",
              "                    %\"add_2312\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2305\", %\"mul_2322\")\n",
              "             819 |  # node_Shape_1787\n",
              "                    %\"val_1845\"<INT64,[4]> ⬅️ ::Shape(%\"add_2312\") {start=0}\n",
              "             820 |  # node_Slice_1789\n",
              "                    %\"val_1847\"<INT64,[1]> ⬅️ ::Slice(%\"val_1845\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             821 |  # node_Slice_1790\n",
              "                    %\"val_1848\"<INT64,[1]> ⬅️ ::Slice(%\"val_1845\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             822 |  # node_Slice_1792\n",
              "                    %\"val_1850\"<INT64,[2]> ⬅️ ::Slice(%\"val_1845\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             823 |  # node_Concat_1794\n",
              "                    %\"val_1852\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1848\", %\"val_1847\") {axis=0}\n",
              "             824 |  # node_Reshape_1795\n",
              "                    %\"val_1853\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2312\", %\"val_1852\") {allowzero=0}\n",
              "             825 |  # node_Transpose_1796\n",
              "                    %\"val_1854\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1853\") {perm=(0, 2, 1)}\n",
              "             826 |  # node_Concat_1797\n",
              "                    %\"val_1855\"<INT64,[4]> ⬅️ ::Concat(%\"val_1850\", %\"val_1847\", %\"val_1848\") {axis=0}\n",
              "             827 |  # node_Reshape_1798\n",
              "                    %\"val_1856\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1854\", %\"val_1855\") {allowzero=0}\n",
              "             828 |  # node_Mul_1800\n",
              "                    %\"val_1858\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_2288\", %\"val_147\"{[0.3535533845424652]})\n",
              "             829 |  # node_Mul_1802\n",
              "                    %\"val_1860\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1856\", %\"val_147\"{[0.3535533845424652]})\n",
              "             830 |  # node_MatMul_1803\n",
              "                    %\"val_1861\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1858\", %\"val_1860\")\n",
              "             831 |  # node_Add_1804\n",
              "                    %\"val_1862\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1861\", %\"masked_fill_1\")\n",
              "             832 |  # node_Softmax_1805\n",
              "                    %\"val_1863\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1862\") {axis=-1}\n",
              "             833 |  # node_scaled_dot_product_attention_14\n",
              "                    %\"scaled_dot_product_attention_14\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1863\", %\"getitem_72\")\n",
              "             834 |  # node_transpose_44\n",
              "                    %\"transpose_44\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_14\") {perm=(0, 2, 1, 3)}\n",
              "             835 |  # node_view_29\n",
              "                    %\"view_29\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_44\", %\"val_158\") {allowzero=1}\n",
              "             836 |  # node_linear_57\n",
              "                    %\"linear_57\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_29\", %\"val_1869\"{...})\n",
              "             837 |  # node_add_2329\n",
              "                    %\"add_2329\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2208\", %\"linear_57\")\n",
              "             838 |  # node_layer_norm_29\n",
              "                    %\"layer_norm_29\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2329\", %\"model.layers.14.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             839 |  # node_linear_58\n",
              "                    %\"linear_58\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_29\", %\"val_1872\"{...})\n",
              "             840 |  # node_Split_3013\n",
              "                    %\"split_14_split_0\"<FLOAT,[1,s53,1152]>, %\"split_14_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_58\") {axis=2, num_outputs=2}\n",
              "             841 |  # node_Div_1814\n",
              "                    %\"val_1874\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_14_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             842 |  # node_Erf_1815\n",
              "                    %\"val_1875\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1874\")\n",
              "             843 |  # node_Add_1817\n",
              "                    %\"val_1877\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1875\", %\"clone\"{1.0})\n",
              "             844 |  # node_Mul_1819\n",
              "                    %\"val_1879\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1877\")\n",
              "             845 |  # node_gelu_14\n",
              "                    %\"gelu_14\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_14_split_0\", %\"val_1879\")\n",
              "             846 |  # node_mul_2360\n",
              "                    %\"mul_2360\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_14\", %\"split_14_split_1\")\n",
              "             847 |  # node_linear_59\n",
              "                    %\"linear_59\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2360\", %\"val_1880\"{...})\n",
              "             848 |  # node_add_2357\n",
              "                    %\"add_2357\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2329\", %\"linear_59\")\n",
              "             849 |  # node_layer_norm_30\n",
              "                    %\"layer_norm_30\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2357\", %\"model.layers.15.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             850 |  # node_linear_60\n",
              "                    %\"linear_60\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_30\", %\"val_1883\"{...})\n",
              "             851 |  # node_view_30\n",
              "                    %\"view_30\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_60\", %\"val_54\") {allowzero=1}\n",
              "             852 |  # node_transpose_46\n",
              "                    %\"transpose_46\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_30\") {perm=(0, 3, 2, 1, 4)}\n",
              "             853 |  # node_Slice_1847\n",
              "                    %\"val_1909\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_46\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             854 |  # node_unbind_15__0\n",
              "                    %\"getitem_75\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1909\", %\"val_21\"{[2]})\n",
              "             855 |  # node_Slice_1851\n",
              "                    %\"val_1913\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_46\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             856 |  # node_unbind_15__1\n",
              "                    %\"getitem_76\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1913\", %\"val_21\"{[2]})\n",
              "             857 |  # node_Slice_1855\n",
              "                    %\"val_1917\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_46\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             858 |  # node_unbind_15__2\n",
              "                    %\"getitem_77\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_1917\", %\"val_21\"{[2]})\n",
              "             859 |  # node_mul_2434\n",
              "                    %\"mul_2434\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_75\", %\"unsqueeze_9\")\n",
              "             860 |  # node_slice_79\n",
              "                    %\"slice_79\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_75\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             861 |  # node_slice_80\n",
              "                    %\"slice_80\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_75\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             862 |  # node_neg_30\n",
              "                    %\"neg_30\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_80\")\n",
              "             863 |  # node_cat_46\n",
              "                    %\"cat_46\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_30\", %\"slice_79\") {axis=-1}\n",
              "             864 |  # node_mul_2451\n",
              "                    %\"mul_2451\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_46\", %\"unsqueeze_10\")\n",
              "             865 |  # node_add_2437\n",
              "                    %\"add_2437\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2434\", %\"mul_2451\")\n",
              "             866 |  # node_mul_2459\n",
              "                    %\"mul_2459\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_76\", %\"unsqueeze_9\")\n",
              "             867 |  # node_slice_81\n",
              "                    %\"slice_81\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_76\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             868 |  # node_slice_82\n",
              "                    %\"slice_82\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_76\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             869 |  # node_neg_31\n",
              "                    %\"neg_31\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_82\")\n",
              "             870 |  # node_cat_47\n",
              "                    %\"cat_47\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_31\", %\"slice_81\") {axis=-1}\n",
              "             871 |  # node_mul_2476\n",
              "                    %\"mul_2476\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_47\", %\"unsqueeze_10\")\n",
              "             872 |  # node_add_2461\n",
              "                    %\"add_2461\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2459\", %\"mul_2476\")\n",
              "             873 |  # node_Shape_1905\n",
              "                    %\"val_1967\"<INT64,[4]> ⬅️ ::Shape(%\"add_2461\") {start=0}\n",
              "             874 |  # node_Slice_1907\n",
              "                    %\"val_1969\"<INT64,[1]> ⬅️ ::Slice(%\"val_1967\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             875 |  # node_Slice_1908\n",
              "                    %\"val_1970\"<INT64,[1]> ⬅️ ::Slice(%\"val_1967\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             876 |  # node_Slice_1910\n",
              "                    %\"val_1972\"<INT64,[2]> ⬅️ ::Slice(%\"val_1967\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             877 |  # node_Concat_1912\n",
              "                    %\"val_1974\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_1970\", %\"val_1969\") {axis=0}\n",
              "             878 |  # node_Reshape_1913\n",
              "                    %\"val_1975\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2461\", %\"val_1974\") {allowzero=0}\n",
              "             879 |  # node_Transpose_1914\n",
              "                    %\"val_1976\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_1975\") {perm=(0, 2, 1)}\n",
              "             880 |  # node_Concat_1915\n",
              "                    %\"val_1977\"<INT64,[4]> ⬅️ ::Concat(%\"val_1972\", %\"val_1969\", %\"val_1970\") {axis=0}\n",
              "             881 |  # node_Reshape_1916\n",
              "                    %\"val_1978\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_1976\", %\"val_1977\") {allowzero=0}\n",
              "             882 |  # node_Mul_1918\n",
              "                    %\"val_1980\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_2437\", %\"val_147\"{[0.3535533845424652]})\n",
              "             883 |  # node_Mul_1920\n",
              "                    %\"val_1982\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_1978\", %\"val_147\"{[0.3535533845424652]})\n",
              "             884 |  # node_MatMul_1921\n",
              "                    %\"val_1983\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_1980\", %\"val_1982\")\n",
              "             885 |  # node_Add_1922\n",
              "                    %\"val_1984\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_1983\", %\"masked_fill\")\n",
              "             886 |  # node_Softmax_1923\n",
              "                    %\"val_1985\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_1984\") {axis=-1}\n",
              "             887 |  # node_scaled_dot_product_attention_15\n",
              "                    %\"scaled_dot_product_attention_15\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_1985\", %\"getitem_77\")\n",
              "             888 |  # node_transpose_47\n",
              "                    %\"transpose_47\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_15\") {perm=(0, 2, 1, 3)}\n",
              "             889 |  # node_view_31\n",
              "                    %\"view_31\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_47\", %\"val_158\") {allowzero=1}\n",
              "             890 |  # node_linear_61\n",
              "                    %\"linear_61\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_31\", %\"val_1991\"{...})\n",
              "             891 |  # node_add_2478\n",
              "                    %\"add_2478\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2357\", %\"linear_61\")\n",
              "             892 |  # node_layer_norm_31\n",
              "                    %\"layer_norm_31\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2478\", %\"model.layers.15.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             893 |  # node_linear_62\n",
              "                    %\"linear_62\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_31\", %\"val_1994\"{...})\n",
              "             894 |  # node_Split_3036\n",
              "                    %\"split_15_split_0\"<FLOAT,[1,s53,1152]>, %\"split_15_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_62\") {axis=2, num_outputs=2}\n",
              "             895 |  # node_Div_1932\n",
              "                    %\"val_1996\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_15_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             896 |  # node_Erf_1933\n",
              "                    %\"val_1997\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_1996\")\n",
              "             897 |  # node_Add_1935\n",
              "                    %\"val_1999\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_1997\", %\"clone\"{1.0})\n",
              "             898 |  # node_Mul_1937\n",
              "                    %\"val_2001\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_1999\")\n",
              "             899 |  # node_gelu_15\n",
              "                    %\"gelu_15\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_15_split_0\", %\"val_2001\")\n",
              "             900 |  # node_mul_2514\n",
              "                    %\"mul_2514\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_15\", %\"split_15_split_1\")\n",
              "             901 |  # node_linear_63\n",
              "                    %\"linear_63\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2514\", %\"val_2002\"{...})\n",
              "             902 |  # node_add_2506\n",
              "                    %\"add_2506\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2478\", %\"linear_63\")\n",
              "             903 |  # node_layer_norm_32\n",
              "                    %\"layer_norm_32\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2506\", %\"model.layers.16.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             904 |  # node_linear_64\n",
              "                    %\"linear_64\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_32\", %\"val_2005\"{...})\n",
              "             905 |  # node_view_32\n",
              "                    %\"view_32\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_64\", %\"val_54\") {allowzero=1}\n",
              "             906 |  # node_transpose_49\n",
              "                    %\"transpose_49\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_32\") {perm=(0, 3, 2, 1, 4)}\n",
              "             907 |  # node_Slice_1965\n",
              "                    %\"val_2031\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_49\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             908 |  # node_unbind_16__0\n",
              "                    %\"getitem_80\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2031\", %\"val_21\"{[2]})\n",
              "             909 |  # node_Slice_1969\n",
              "                    %\"val_2035\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_49\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             910 |  # node_unbind_16__1\n",
              "                    %\"getitem_81\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2035\", %\"val_21\"{[2]})\n",
              "             911 |  # node_Slice_1973\n",
              "                    %\"val_2039\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_49\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             912 |  # node_unbind_16__2\n",
              "                    %\"getitem_82\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2039\", %\"val_21\"{[2]})\n",
              "             913 |  # node_mul_2588\n",
              "                    %\"mul_2588\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_80\", %\"unsqueeze_14\")\n",
              "             914 |  # node_slice_84\n",
              "                    %\"slice_84\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_80\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             915 |  # node_slice_85\n",
              "                    %\"slice_85\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_80\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             916 |  # node_neg_32\n",
              "                    %\"neg_32\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_85\")\n",
              "             917 |  # node_cat_49\n",
              "                    %\"cat_49\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_32\", %\"slice_84\") {axis=-1}\n",
              "             918 |  # node_mul_2605\n",
              "                    %\"mul_2605\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_49\", %\"unsqueeze_15\")\n",
              "             919 |  # node_add_2586\n",
              "                    %\"add_2586\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2588\", %\"mul_2605\")\n",
              "             920 |  # node_mul_2613\n",
              "                    %\"mul_2613\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_81\", %\"unsqueeze_14\")\n",
              "             921 |  # node_slice_86\n",
              "                    %\"slice_86\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_81\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             922 |  # node_slice_87\n",
              "                    %\"slice_87\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_81\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             923 |  # node_neg_33\n",
              "                    %\"neg_33\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_87\")\n",
              "             924 |  # node_cat_50\n",
              "                    %\"cat_50\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_33\", %\"slice_86\") {axis=-1}\n",
              "             925 |  # node_mul_2630\n",
              "                    %\"mul_2630\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_50\", %\"unsqueeze_15\")\n",
              "             926 |  # node_add_2610\n",
              "                    %\"add_2610\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2613\", %\"mul_2630\")\n",
              "             927 |  # node_Shape_2023\n",
              "                    %\"val_2089\"<INT64,[4]> ⬅️ ::Shape(%\"add_2610\") {start=0}\n",
              "             928 |  # node_Slice_2025\n",
              "                    %\"val_2091\"<INT64,[1]> ⬅️ ::Slice(%\"val_2089\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             929 |  # node_Slice_2026\n",
              "                    %\"val_2092\"<INT64,[1]> ⬅️ ::Slice(%\"val_2089\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             930 |  # node_Slice_2028\n",
              "                    %\"val_2094\"<INT64,[2]> ⬅️ ::Slice(%\"val_2089\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             931 |  # node_Concat_2030\n",
              "                    %\"val_2096\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_2092\", %\"val_2091\") {axis=0}\n",
              "             932 |  # node_Reshape_2031\n",
              "                    %\"val_2097\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2610\", %\"val_2096\") {allowzero=0}\n",
              "             933 |  # node_Transpose_2032\n",
              "                    %\"val_2098\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_2097\") {perm=(0, 2, 1)}\n",
              "             934 |  # node_Concat_2033\n",
              "                    %\"val_2099\"<INT64,[4]> ⬅️ ::Concat(%\"val_2094\", %\"val_2091\", %\"val_2092\") {axis=0}\n",
              "             935 |  # node_Reshape_2034\n",
              "                    %\"val_2100\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_2098\", %\"val_2099\") {allowzero=0}\n",
              "             936 |  # node_Mul_2036\n",
              "                    %\"val_2102\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_2586\", %\"val_147\"{[0.3535533845424652]})\n",
              "             937 |  # node_Mul_2038\n",
              "                    %\"val_2104\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_2100\", %\"val_147\"{[0.3535533845424652]})\n",
              "             938 |  # node_MatMul_2039\n",
              "                    %\"val_2105\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_2102\", %\"val_2104\")\n",
              "             939 |  # node_Add_2040\n",
              "                    %\"val_2106\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_2105\", %\"masked_fill_1\")\n",
              "             940 |  # node_Softmax_2041\n",
              "                    %\"val_2107\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_2106\") {axis=-1}\n",
              "             941 |  # node_scaled_dot_product_attention_16\n",
              "                    %\"scaled_dot_product_attention_16\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_2107\", %\"getitem_82\")\n",
              "             942 |  # node_transpose_50\n",
              "                    %\"transpose_50\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_16\") {perm=(0, 2, 1, 3)}\n",
              "             943 |  # node_view_33\n",
              "                    %\"view_33\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_50\", %\"val_158\") {allowzero=1}\n",
              "             944 |  # node_linear_65\n",
              "                    %\"linear_65\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_33\", %\"val_2113\"{...})\n",
              "             945 |  # node_add_2627\n",
              "                    %\"add_2627\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2506\", %\"linear_65\")\n",
              "             946 |  # node_layer_norm_33\n",
              "                    %\"layer_norm_33\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2627\", %\"model.layers.16.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             947 |  # node_linear_66\n",
              "                    %\"linear_66\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_33\", %\"val_2116\"{...})\n",
              "             948 |  # node_Split_3059\n",
              "                    %\"split_16_split_0\"<FLOAT,[1,s53,1152]>, %\"split_16_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_66\") {axis=2, num_outputs=2}\n",
              "             949 |  # node_Div_2050\n",
              "                    %\"val_2118\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_16_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "             950 |  # node_Erf_2051\n",
              "                    %\"val_2119\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_2118\")\n",
              "             951 |  # node_Add_2053\n",
              "                    %\"val_2121\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_2119\", %\"clone\"{1.0})\n",
              "             952 |  # node_Mul_2055\n",
              "                    %\"val_2123\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2121\")\n",
              "             953 |  # node_gelu_16\n",
              "                    %\"gelu_16\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_16_split_0\", %\"val_2123\")\n",
              "             954 |  # node_mul_2668\n",
              "                    %\"mul_2668\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_16\", %\"split_16_split_1\")\n",
              "             955 |  # node_linear_67\n",
              "                    %\"linear_67\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2668\", %\"val_2124\"{...})\n",
              "             956 |  # node_add_2655\n",
              "                    %\"add_2655\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2627\", %\"linear_67\")\n",
              "             957 |  # node_layer_norm_34\n",
              "                    %\"layer_norm_34\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2655\", %\"model.layers.17.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "             958 |  # node_linear_68\n",
              "                    %\"linear_68\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_34\", %\"val_2127\"{...})\n",
              "             959 |  # node_view_34\n",
              "                    %\"view_34\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_68\", %\"val_54\") {allowzero=1}\n",
              "             960 |  # node_transpose_52\n",
              "                    %\"transpose_52\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_34\") {perm=(0, 3, 2, 1, 4)}\n",
              "             961 |  # node_Slice_2083\n",
              "                    %\"val_2153\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_52\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "             962 |  # node_unbind_17__0\n",
              "                    %\"getitem_85\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2153\", %\"val_21\"{[2]})\n",
              "             963 |  # node_Slice_2087\n",
              "                    %\"val_2157\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_52\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "             964 |  # node_unbind_17__1\n",
              "                    %\"getitem_86\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2157\", %\"val_21\"{[2]})\n",
              "             965 |  # node_Slice_2091\n",
              "                    %\"val_2161\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_52\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "             966 |  # node_unbind_17__2\n",
              "                    %\"getitem_87\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2161\", %\"val_21\"{[2]})\n",
              "             967 |  # node_mul_2742\n",
              "                    %\"mul_2742\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_85\", %\"unsqueeze_14\")\n",
              "             968 |  # node_slice_89\n",
              "                    %\"slice_89\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_85\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             969 |  # node_slice_90\n",
              "                    %\"slice_90\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_85\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             970 |  # node_neg_34\n",
              "                    %\"neg_34\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_90\")\n",
              "             971 |  # node_cat_52\n",
              "                    %\"cat_52\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_34\", %\"slice_89\") {axis=-1}\n",
              "             972 |  # node_mul_2759\n",
              "                    %\"mul_2759\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_52\", %\"unsqueeze_15\")\n",
              "             973 |  # node_add_2735\n",
              "                    %\"add_2735\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2742\", %\"mul_2759\")\n",
              "             974 |  # node_mul_2767\n",
              "                    %\"mul_2767\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_86\", %\"unsqueeze_14\")\n",
              "             975 |  # node_slice_91\n",
              "                    %\"slice_91\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_86\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             976 |  # node_slice_92\n",
              "                    %\"slice_92\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_86\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "             977 |  # node_neg_35\n",
              "                    %\"neg_35\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_92\")\n",
              "             978 |  # node_cat_53\n",
              "                    %\"cat_53\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_35\", %\"slice_91\") {axis=-1}\n",
              "             979 |  # node_mul_2784\n",
              "                    %\"mul_2784\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_53\", %\"unsqueeze_15\")\n",
              "             980 |  # node_add_2759\n",
              "                    %\"add_2759\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2767\", %\"mul_2784\")\n",
              "             981 |  # node_Shape_2141\n",
              "                    %\"val_2211\"<INT64,[4]> ⬅️ ::Shape(%\"add_2759\") {start=0}\n",
              "             982 |  # node_Slice_2143\n",
              "                    %\"val_2213\"<INT64,[1]> ⬅️ ::Slice(%\"val_2211\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "             983 |  # node_Slice_2144\n",
              "                    %\"val_2214\"<INT64,[1]> ⬅️ ::Slice(%\"val_2211\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "             984 |  # node_Slice_2146\n",
              "                    %\"val_2216\"<INT64,[2]> ⬅️ ::Slice(%\"val_2211\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "             985 |  # node_Concat_2148\n",
              "                    %\"val_2218\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_2214\", %\"val_2213\") {axis=0}\n",
              "             986 |  # node_Reshape_2149\n",
              "                    %\"val_2219\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2759\", %\"val_2218\") {allowzero=0}\n",
              "             987 |  # node_Transpose_2150\n",
              "                    %\"val_2220\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_2219\") {perm=(0, 2, 1)}\n",
              "             988 |  # node_Concat_2151\n",
              "                    %\"val_2221\"<INT64,[4]> ⬅️ ::Concat(%\"val_2216\", %\"val_2213\", %\"val_2214\") {axis=0}\n",
              "             989 |  # node_Reshape_2152\n",
              "                    %\"val_2222\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_2220\", %\"val_2221\") {allowzero=0}\n",
              "             990 |  # node_Mul_2154\n",
              "                    %\"val_2224\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_2735\", %\"val_147\"{[0.3535533845424652]})\n",
              "             991 |  # node_Mul_2156\n",
              "                    %\"val_2226\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_2222\", %\"val_147\"{[0.3535533845424652]})\n",
              "             992 |  # node_MatMul_2157\n",
              "                    %\"val_2227\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_2224\", %\"val_2226\")\n",
              "             993 |  # node_Add_2158\n",
              "                    %\"val_2228\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_2227\", %\"masked_fill_1\")\n",
              "             994 |  # node_Softmax_2159\n",
              "                    %\"val_2229\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_2228\") {axis=-1}\n",
              "             995 |  # node_scaled_dot_product_attention_17\n",
              "                    %\"scaled_dot_product_attention_17\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_2229\", %\"getitem_87\")\n",
              "             996 |  # node_transpose_53\n",
              "                    %\"transpose_53\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_17\") {perm=(0, 2, 1, 3)}\n",
              "             997 |  # node_view_35\n",
              "                    %\"view_35\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_53\", %\"val_158\") {allowzero=1}\n",
              "             998 |  # node_linear_69\n",
              "                    %\"linear_69\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_35\", %\"val_2235\"{...})\n",
              "             999 |  # node_add_2776\n",
              "                    %\"add_2776\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2655\", %\"linear_69\")\n",
              "            1000 |  # node_layer_norm_35\n",
              "                    %\"layer_norm_35\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2776\", %\"model.layers.17.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1001 |  # node_linear_70\n",
              "                    %\"linear_70\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_35\", %\"val_2238\"{...})\n",
              "            1002 |  # node_Split_3082\n",
              "                    %\"split_17_split_0\"<FLOAT,[1,s53,1152]>, %\"split_17_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_70\") {axis=2, num_outputs=2}\n",
              "            1003 |  # node_Div_2168\n",
              "                    %\"val_2240\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_17_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "            1004 |  # node_Erf_2169\n",
              "                    %\"val_2241\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_2240\")\n",
              "            1005 |  # node_Add_2171\n",
              "                    %\"val_2243\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_2241\", %\"clone\"{1.0})\n",
              "            1006 |  # node_Mul_2173\n",
              "                    %\"val_2245\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2243\")\n",
              "            1007 |  # node_gelu_17\n",
              "                    %\"gelu_17\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_17_split_0\", %\"val_2245\")\n",
              "            1008 |  # node_mul_2822\n",
              "                    %\"mul_2822\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_17\", %\"split_17_split_1\")\n",
              "            1009 |  # node_linear_71\n",
              "                    %\"linear_71\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2822\", %\"val_2246\"{...})\n",
              "            1010 |  # node_add_2804\n",
              "                    %\"add_2804\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2776\", %\"linear_71\")\n",
              "            1011 |  # node_layer_norm_36\n",
              "                    %\"layer_norm_36\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2804\", %\"model.layers.18.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1012 |  # node_linear_72\n",
              "                    %\"linear_72\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_36\", %\"val_2249\"{...})\n",
              "            1013 |  # node_view_36\n",
              "                    %\"view_36\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_72\", %\"val_54\") {allowzero=1}\n",
              "            1014 |  # node_transpose_55\n",
              "                    %\"transpose_55\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_36\") {perm=(0, 3, 2, 1, 4)}\n",
              "            1015 |  # node_Slice_2201\n",
              "                    %\"val_2275\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_55\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "            1016 |  # node_unbind_18__0\n",
              "                    %\"getitem_90\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2275\", %\"val_21\"{[2]})\n",
              "            1017 |  # node_Slice_2205\n",
              "                    %\"val_2279\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_55\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "            1018 |  # node_unbind_18__1\n",
              "                    %\"getitem_91\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2279\", %\"val_21\"{[2]})\n",
              "            1019 |  # node_Slice_2209\n",
              "                    %\"val_2283\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_55\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "            1020 |  # node_unbind_18__2\n",
              "                    %\"getitem_92\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2283\", %\"val_21\"{[2]})\n",
              "            1021 |  # node_mul_2896\n",
              "                    %\"mul_2896\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_90\", %\"unsqueeze_9\")\n",
              "            1022 |  # node_slice_94\n",
              "                    %\"slice_94\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_90\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1023 |  # node_slice_95\n",
              "                    %\"slice_95\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_90\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1024 |  # node_neg_36\n",
              "                    %\"neg_36\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_95\")\n",
              "            1025 |  # node_cat_55\n",
              "                    %\"cat_55\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_36\", %\"slice_94\") {axis=-1}\n",
              "            1026 |  # node_mul_2913\n",
              "                    %\"mul_2913\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_55\", %\"unsqueeze_10\")\n",
              "            1027 |  # node_add_2884\n",
              "                    %\"add_2884\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2896\", %\"mul_2913\")\n",
              "            1028 |  # node_mul_2921\n",
              "                    %\"mul_2921\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_91\", %\"unsqueeze_9\")\n",
              "            1029 |  # node_slice_96\n",
              "                    %\"slice_96\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_91\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1030 |  # node_slice_97\n",
              "                    %\"slice_97\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_91\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1031 |  # node_neg_37\n",
              "                    %\"neg_37\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_97\")\n",
              "            1032 |  # node_cat_56\n",
              "                    %\"cat_56\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_37\", %\"slice_96\") {axis=-1}\n",
              "            1033 |  # node_mul_2938\n",
              "                    %\"mul_2938\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_56\", %\"unsqueeze_10\")\n",
              "            1034 |  # node_add_2908\n",
              "                    %\"add_2908\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_2921\", %\"mul_2938\")\n",
              "            1035 |  # node_Shape_2259\n",
              "                    %\"val_2333\"<INT64,[4]> ⬅️ ::Shape(%\"add_2908\") {start=0}\n",
              "            1036 |  # node_Slice_2261\n",
              "                    %\"val_2335\"<INT64,[1]> ⬅️ ::Slice(%\"val_2333\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "            1037 |  # node_Slice_2262\n",
              "                    %\"val_2336\"<INT64,[1]> ⬅️ ::Slice(%\"val_2333\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "            1038 |  # node_Slice_2264\n",
              "                    %\"val_2338\"<INT64,[2]> ⬅️ ::Slice(%\"val_2333\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "            1039 |  # node_Concat_2266\n",
              "                    %\"val_2340\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_2336\", %\"val_2335\") {axis=0}\n",
              "            1040 |  # node_Reshape_2267\n",
              "                    %\"val_2341\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_2908\", %\"val_2340\") {allowzero=0}\n",
              "            1041 |  # node_Transpose_2268\n",
              "                    %\"val_2342\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_2341\") {perm=(0, 2, 1)}\n",
              "            1042 |  # node_Concat_2269\n",
              "                    %\"val_2343\"<INT64,[4]> ⬅️ ::Concat(%\"val_2338\", %\"val_2335\", %\"val_2336\") {axis=0}\n",
              "            1043 |  # node_Reshape_2270\n",
              "                    %\"val_2344\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_2342\", %\"val_2343\") {allowzero=0}\n",
              "            1044 |  # node_Mul_2272\n",
              "                    %\"val_2346\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_2884\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1045 |  # node_Mul_2274\n",
              "                    %\"val_2348\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_2344\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1046 |  # node_MatMul_2275\n",
              "                    %\"val_2349\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_2346\", %\"val_2348\")\n",
              "            1047 |  # node_Add_2276\n",
              "                    %\"val_2350\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_2349\", %\"masked_fill\")\n",
              "            1048 |  # node_Softmax_2277\n",
              "                    %\"val_2351\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_2350\") {axis=-1}\n",
              "            1049 |  # node_scaled_dot_product_attention_18\n",
              "                    %\"scaled_dot_product_attention_18\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_2351\", %\"getitem_92\")\n",
              "            1050 |  # node_transpose_56\n",
              "                    %\"transpose_56\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_18\") {perm=(0, 2, 1, 3)}\n",
              "            1051 |  # node_view_37\n",
              "                    %\"view_37\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_56\", %\"val_158\") {allowzero=1}\n",
              "            1052 |  # node_linear_73\n",
              "                    %\"linear_73\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_37\", %\"val_2357\"{...})\n",
              "            1053 |  # node_add_2925\n",
              "                    %\"add_2925\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2804\", %\"linear_73\")\n",
              "            1054 |  # node_layer_norm_37\n",
              "                    %\"layer_norm_37\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2925\", %\"model.layers.18.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1055 |  # node_linear_74\n",
              "                    %\"linear_74\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_37\", %\"val_2360\"{...})\n",
              "            1056 |  # node_Split_3105\n",
              "                    %\"split_18_split_0\"<FLOAT,[1,s53,1152]>, %\"split_18_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_74\") {axis=2, num_outputs=2}\n",
              "            1057 |  # node_Div_2286\n",
              "                    %\"val_2362\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_18_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "            1058 |  # node_Erf_2287\n",
              "                    %\"val_2363\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_2362\")\n",
              "            1059 |  # node_Add_2289\n",
              "                    %\"val_2365\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_2363\", %\"clone\"{1.0})\n",
              "            1060 |  # node_Mul_2291\n",
              "                    %\"val_2367\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2365\")\n",
              "            1061 |  # node_gelu_18\n",
              "                    %\"gelu_18\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_18_split_0\", %\"val_2367\")\n",
              "            1062 |  # node_mul_2976\n",
              "                    %\"mul_2976\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_18\", %\"split_18_split_1\")\n",
              "            1063 |  # node_linear_75\n",
              "                    %\"linear_75\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_2976\", %\"val_2368\"{...})\n",
              "            1064 |  # node_add_2953\n",
              "                    %\"add_2953\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2925\", %\"linear_75\")\n",
              "            1065 |  # node_layer_norm_38\n",
              "                    %\"layer_norm_38\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_2953\", %\"model.layers.19.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1066 |  # node_linear_76\n",
              "                    %\"linear_76\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_38\", %\"val_2371\"{...})\n",
              "            1067 |  # node_view_38\n",
              "                    %\"view_38\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_76\", %\"val_54\") {allowzero=1}\n",
              "            1068 |  # node_transpose_58\n",
              "                    %\"transpose_58\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_38\") {perm=(0, 3, 2, 1, 4)}\n",
              "            1069 |  # node_Slice_2319\n",
              "                    %\"val_2397\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_58\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "            1070 |  # node_unbind_19__0\n",
              "                    %\"getitem_95\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2397\", %\"val_21\"{[2]})\n",
              "            1071 |  # node_Slice_2323\n",
              "                    %\"val_2401\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_58\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "            1072 |  # node_unbind_19__1\n",
              "                    %\"getitem_96\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2401\", %\"val_21\"{[2]})\n",
              "            1073 |  # node_Slice_2327\n",
              "                    %\"val_2405\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_58\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "            1074 |  # node_unbind_19__2\n",
              "                    %\"getitem_97\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2405\", %\"val_21\"{[2]})\n",
              "            1075 |  # node_mul_3050\n",
              "                    %\"mul_3050\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_95\", %\"unsqueeze_14\")\n",
              "            1076 |  # node_slice_99\n",
              "                    %\"slice_99\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_95\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1077 |  # node_slice_100\n",
              "                    %\"slice_100\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_95\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1078 |  # node_neg_38\n",
              "                    %\"neg_38\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_100\")\n",
              "            1079 |  # node_cat_58\n",
              "                    %\"cat_58\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_38\", %\"slice_99\") {axis=-1}\n",
              "            1080 |  # node_mul_3067\n",
              "                    %\"mul_3067\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_58\", %\"unsqueeze_15\")\n",
              "            1081 |  # node_add_3033\n",
              "                    %\"add_3033\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_3050\", %\"mul_3067\")\n",
              "            1082 |  # node_mul_3075\n",
              "                    %\"mul_3075\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_96\", %\"unsqueeze_14\")\n",
              "            1083 |  # node_slice_101\n",
              "                    %\"slice_101\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_96\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1084 |  # node_slice_102\n",
              "                    %\"slice_102\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_96\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1085 |  # node_neg_39\n",
              "                    %\"neg_39\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_102\")\n",
              "            1086 |  # node_cat_59\n",
              "                    %\"cat_59\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_39\", %\"slice_101\") {axis=-1}\n",
              "            1087 |  # node_mul_3092\n",
              "                    %\"mul_3092\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_59\", %\"unsqueeze_15\")\n",
              "            1088 |  # node_add_3057\n",
              "                    %\"add_3057\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_3075\", %\"mul_3092\")\n",
              "            1089 |  # node_Shape_2377\n",
              "                    %\"val_2455\"<INT64,[4]> ⬅️ ::Shape(%\"add_3057\") {start=0}\n",
              "            1090 |  # node_Slice_2379\n",
              "                    %\"val_2457\"<INT64,[1]> ⬅️ ::Slice(%\"val_2455\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "            1091 |  # node_Slice_2380\n",
              "                    %\"val_2458\"<INT64,[1]> ⬅️ ::Slice(%\"val_2455\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "            1092 |  # node_Slice_2382\n",
              "                    %\"val_2460\"<INT64,[2]> ⬅️ ::Slice(%\"val_2455\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "            1093 |  # node_Concat_2384\n",
              "                    %\"val_2462\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_2458\", %\"val_2457\") {axis=0}\n",
              "            1094 |  # node_Reshape_2385\n",
              "                    %\"val_2463\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_3057\", %\"val_2462\") {allowzero=0}\n",
              "            1095 |  # node_Transpose_2386\n",
              "                    %\"val_2464\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_2463\") {perm=(0, 2, 1)}\n",
              "            1096 |  # node_Concat_2387\n",
              "                    %\"val_2465\"<INT64,[4]> ⬅️ ::Concat(%\"val_2460\", %\"val_2457\", %\"val_2458\") {axis=0}\n",
              "            1097 |  # node_Reshape_2388\n",
              "                    %\"val_2466\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_2464\", %\"val_2465\") {allowzero=0}\n",
              "            1098 |  # node_Mul_2390\n",
              "                    %\"val_2468\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_3033\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1099 |  # node_Mul_2392\n",
              "                    %\"val_2470\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_2466\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1100 |  # node_MatMul_2393\n",
              "                    %\"val_2471\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_2468\", %\"val_2470\")\n",
              "            1101 |  # node_Add_2394\n",
              "                    %\"val_2472\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_2471\", %\"masked_fill_1\")\n",
              "            1102 |  # node_Softmax_2395\n",
              "                    %\"val_2473\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_2472\") {axis=-1}\n",
              "            1103 |  # node_scaled_dot_product_attention_19\n",
              "                    %\"scaled_dot_product_attention_19\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_2473\", %\"getitem_97\")\n",
              "            1104 |  # node_transpose_59\n",
              "                    %\"transpose_59\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_19\") {perm=(0, 2, 1, 3)}\n",
              "            1105 |  # node_view_39\n",
              "                    %\"view_39\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_59\", %\"val_158\") {allowzero=1}\n",
              "            1106 |  # node_linear_77\n",
              "                    %\"linear_77\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_39\", %\"val_2479\"{...})\n",
              "            1107 |  # node_add_3074\n",
              "                    %\"add_3074\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_2953\", %\"linear_77\")\n",
              "            1108 |  # node_layer_norm_39\n",
              "                    %\"layer_norm_39\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_3074\", %\"model.layers.19.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1109 |  # node_linear_78\n",
              "                    %\"linear_78\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_39\", %\"val_2482\"{...})\n",
              "            1110 |  # node_Split_3128\n",
              "                    %\"split_19_split_0\"<FLOAT,[1,s53,1152]>, %\"split_19_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_78\") {axis=2, num_outputs=2}\n",
              "            1111 |  # node_Div_2404\n",
              "                    %\"val_2484\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_19_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "            1112 |  # node_Erf_2405\n",
              "                    %\"val_2485\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_2484\")\n",
              "            1113 |  # node_Add_2407\n",
              "                    %\"val_2487\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_2485\", %\"clone\"{1.0})\n",
              "            1114 |  # node_Mul_2409\n",
              "                    %\"val_2489\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2487\")\n",
              "            1115 |  # node_gelu_19\n",
              "                    %\"gelu_19\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_19_split_0\", %\"val_2489\")\n",
              "            1116 |  # node_mul_3130\n",
              "                    %\"mul_3130\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_19\", %\"split_19_split_1\")\n",
              "            1117 |  # node_linear_79\n",
              "                    %\"linear_79\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_3130\", %\"val_2490\"{...})\n",
              "            1118 |  # node_add_3102\n",
              "                    %\"add_3102\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_3074\", %\"linear_79\")\n",
              "            1119 |  # node_layer_norm_40\n",
              "                    %\"layer_norm_40\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_3102\", %\"model.layers.20.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1120 |  # node_linear_80\n",
              "                    %\"linear_80\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_40\", %\"val_2493\"{...})\n",
              "            1121 |  # node_view_40\n",
              "                    %\"view_40\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_80\", %\"val_54\") {allowzero=1}\n",
              "            1122 |  # node_transpose_61\n",
              "                    %\"transpose_61\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_40\") {perm=(0, 3, 2, 1, 4)}\n",
              "            1123 |  # node_Slice_2437\n",
              "                    %\"val_2519\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_61\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "            1124 |  # node_unbind_20__0\n",
              "                    %\"getitem_100\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2519\", %\"val_21\"{[2]})\n",
              "            1125 |  # node_Slice_2441\n",
              "                    %\"val_2523\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_61\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "            1126 |  # node_unbind_20__1\n",
              "                    %\"getitem_101\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2523\", %\"val_21\"{[2]})\n",
              "            1127 |  # node_Slice_2445\n",
              "                    %\"val_2527\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_61\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "            1128 |  # node_unbind_20__2\n",
              "                    %\"getitem_102\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2527\", %\"val_21\"{[2]})\n",
              "            1129 |  # node_mul_3204\n",
              "                    %\"mul_3204\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_100\", %\"unsqueeze_14\")\n",
              "            1130 |  # node_slice_104\n",
              "                    %\"slice_104\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_100\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1131 |  # node_slice_105\n",
              "                    %\"slice_105\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_100\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1132 |  # node_neg_40\n",
              "                    %\"neg_40\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_105\")\n",
              "            1133 |  # node_cat_61\n",
              "                    %\"cat_61\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_40\", %\"slice_104\") {axis=-1}\n",
              "            1134 |  # node_mul_3221\n",
              "                    %\"mul_3221\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_61\", %\"unsqueeze_15\")\n",
              "            1135 |  # node_add_3182\n",
              "                    %\"add_3182\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_3204\", %\"mul_3221\")\n",
              "            1136 |  # node_mul_3229\n",
              "                    %\"mul_3229\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_101\", %\"unsqueeze_14\")\n",
              "            1137 |  # node_slice_106\n",
              "                    %\"slice_106\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_101\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1138 |  # node_slice_107\n",
              "                    %\"slice_107\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_101\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1139 |  # node_neg_41\n",
              "                    %\"neg_41\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_107\")\n",
              "            1140 |  # node_cat_62\n",
              "                    %\"cat_62\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_41\", %\"slice_106\") {axis=-1}\n",
              "            1141 |  # node_mul_3246\n",
              "                    %\"mul_3246\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_62\", %\"unsqueeze_15\")\n",
              "            1142 |  # node_add_3206\n",
              "                    %\"add_3206\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_3229\", %\"mul_3246\")\n",
              "            1143 |  # node_Shape_2495\n",
              "                    %\"val_2577\"<INT64,[4]> ⬅️ ::Shape(%\"add_3206\") {start=0}\n",
              "            1144 |  # node_Slice_2497\n",
              "                    %\"val_2579\"<INT64,[1]> ⬅️ ::Slice(%\"val_2577\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "            1145 |  # node_Slice_2498\n",
              "                    %\"val_2580\"<INT64,[1]> ⬅️ ::Slice(%\"val_2577\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "            1146 |  # node_Slice_2500\n",
              "                    %\"val_2582\"<INT64,[2]> ⬅️ ::Slice(%\"val_2577\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "            1147 |  # node_Concat_2502\n",
              "                    %\"val_2584\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_2580\", %\"val_2579\") {axis=0}\n",
              "            1148 |  # node_Reshape_2503\n",
              "                    %\"val_2585\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_3206\", %\"val_2584\") {allowzero=0}\n",
              "            1149 |  # node_Transpose_2504\n",
              "                    %\"val_2586\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_2585\") {perm=(0, 2, 1)}\n",
              "            1150 |  # node_Concat_2505\n",
              "                    %\"val_2587\"<INT64,[4]> ⬅️ ::Concat(%\"val_2582\", %\"val_2579\", %\"val_2580\") {axis=0}\n",
              "            1151 |  # node_Reshape_2506\n",
              "                    %\"val_2588\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_2586\", %\"val_2587\") {allowzero=0}\n",
              "            1152 |  # node_Mul_2508\n",
              "                    %\"val_2590\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_3182\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1153 |  # node_Mul_2510\n",
              "                    %\"val_2592\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_2588\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1154 |  # node_MatMul_2511\n",
              "                    %\"val_2593\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_2590\", %\"val_2592\")\n",
              "            1155 |  # node_Add_2512\n",
              "                    %\"val_2594\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_2593\", %\"masked_fill_1\")\n",
              "            1156 |  # node_Softmax_2513\n",
              "                    %\"val_2595\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_2594\") {axis=-1}\n",
              "            1157 |  # node_scaled_dot_product_attention_20\n",
              "                    %\"scaled_dot_product_attention_20\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_2595\", %\"getitem_102\")\n",
              "            1158 |  # node_transpose_62\n",
              "                    %\"transpose_62\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_20\") {perm=(0, 2, 1, 3)}\n",
              "            1159 |  # node_view_41\n",
              "                    %\"view_41\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_62\", %\"val_158\") {allowzero=1}\n",
              "            1160 |  # node_linear_81\n",
              "                    %\"linear_81\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_41\", %\"val_2601\"{...})\n",
              "            1161 |  # node_add_3223\n",
              "                    %\"add_3223\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_3102\", %\"linear_81\")\n",
              "            1162 |  # node_layer_norm_41\n",
              "                    %\"layer_norm_41\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_3223\", %\"model.layers.20.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1163 |  # node_linear_82\n",
              "                    %\"linear_82\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_41\", %\"val_2604\"{...})\n",
              "            1164 |  # node_Split_3151\n",
              "                    %\"split_20_split_0\"<FLOAT,[1,s53,1152]>, %\"split_20_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_82\") {axis=2, num_outputs=2}\n",
              "            1165 |  # node_Div_2522\n",
              "                    %\"val_2606\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_20_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "            1166 |  # node_Erf_2523\n",
              "                    %\"val_2607\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_2606\")\n",
              "            1167 |  # node_Add_2525\n",
              "                    %\"val_2609\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_2607\", %\"clone\"{1.0})\n",
              "            1168 |  # node_Mul_2527\n",
              "                    %\"val_2611\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2609\")\n",
              "            1169 |  # node_gelu_20\n",
              "                    %\"gelu_20\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_20_split_0\", %\"val_2611\")\n",
              "            1170 |  # node_mul_3284\n",
              "                    %\"mul_3284\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_20\", %\"split_20_split_1\")\n",
              "            1171 |  # node_linear_83\n",
              "                    %\"linear_83\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_3284\", %\"val_2612\"{...})\n",
              "            1172 |  # node_add_3251\n",
              "                    %\"add_3251\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_3223\", %\"linear_83\")\n",
              "            1173 |  # node_layer_norm_42\n",
              "                    %\"layer_norm_42\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_3251\", %\"model.layers.21.attn_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1174 |  # node_linear_84\n",
              "                    %\"linear_84\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_42\", %\"val_2615\"{...})\n",
              "            1175 |  # node_view_42\n",
              "                    %\"view_42\"<FLOAT,[1,s53,3,12,64]> ⬅️ ::Reshape(%\"linear_84\", %\"val_54\") {allowzero=1}\n",
              "            1176 |  # node_transpose_64\n",
              "                    %\"transpose_64\"<FLOAT,[1,12,3,s53,64]> ⬅️ ::Transpose(%\"view_42\") {perm=(0, 3, 2, 1, 4)}\n",
              "            1177 |  # node_Slice_2555\n",
              "                    %\"val_2641\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_64\", %\"val_85\"{[0]}, %\"val_2739\"{[1]}, %\"val_21\"{[2]})\n",
              "            1178 |  # node_unbind_21__0\n",
              "                    %\"getitem_105\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2641\", %\"val_21\"{[2]})\n",
              "            1179 |  # node_Slice_2559\n",
              "                    %\"val_2645\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_64\", %\"val_2739\"{[1]}, %\"val_21\"{[2]}, %\"val_21\"{[2]})\n",
              "            1180 |  # node_unbind_21__1\n",
              "                    %\"getitem_106\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2645\", %\"val_21\"{[2]})\n",
              "            1181 |  # node_Slice_2563\n",
              "                    %\"val_2649\"<FLOAT,[1,12,1,s53,64]> ⬅️ ::Slice(%\"transpose_64\", %\"val_21\"{[2]}, %\"val_92\"{[3]}, %\"val_21\"{[2]})\n",
              "            1182 |  # node_unbind_21__2\n",
              "                    %\"getitem_107\"<FLOAT,[1,12,s53,64]> ⬅️ ::Squeeze(%\"val_2649\", %\"val_21\"{[2]})\n",
              "            1183 |  # node_mul_3358\n",
              "                    %\"mul_3358\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_105\", %\"unsqueeze_9\")\n",
              "            1184 |  # node_slice_109\n",
              "                    %\"slice_109\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_105\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1185 |  # node_slice_110\n",
              "                    %\"slice_110\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_105\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1186 |  # node_neg_42\n",
              "                    %\"neg_42\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_110\")\n",
              "            1187 |  # node_cat_64\n",
              "                    %\"cat_64\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_42\", %\"slice_109\") {axis=-1}\n",
              "            1188 |  # node_mul_3375\n",
              "                    %\"mul_3375\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_64\", %\"unsqueeze_10\")\n",
              "            1189 |  # node_add_3331\n",
              "                    %\"add_3331\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_3358\", %\"mul_3375\")\n",
              "            1190 |  # node_mul_3383\n",
              "                    %\"mul_3383\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"getitem_106\", %\"unsqueeze_9\")\n",
              "            1191 |  # node_slice_111\n",
              "                    %\"slice_111\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_106\", %\"val_85\"{[0]}, %\"val_89\"{[32]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1192 |  # node_slice_112\n",
              "                    %\"slice_112\"<FLOAT,[1,12,s53,32]> ⬅️ ::Slice(%\"getitem_106\", %\"val_89\"{[32]}, %\"val_99\"{[9223372036854775807]}, %\"val_92\"{[3]}, %\"val_2739\"{[1]})\n",
              "            1193 |  # node_neg_43\n",
              "                    %\"neg_43\"<FLOAT,[1,12,s53,32]> ⬅️ ::Neg(%\"slice_112\")\n",
              "            1194 |  # node_cat_65\n",
              "                    %\"cat_65\"<FLOAT,[1,12,s53,64]> ⬅️ ::Concat(%\"neg_43\", %\"slice_111\") {axis=-1}\n",
              "            1195 |  # node_mul_3400\n",
              "                    %\"mul_3400\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"cat_65\", %\"unsqueeze_10\")\n",
              "            1196 |  # node_add_3355\n",
              "                    %\"add_3355\"<FLOAT,[1,12,s53,64]> ⬅️ ::Add(%\"mul_3383\", %\"mul_3400\")\n",
              "            1197 |  # node_Shape_2613\n",
              "                    %\"val_2699\"<INT64,[4]> ⬅️ ::Shape(%\"add_3355\") {start=0}\n",
              "            1198 |  # node_Slice_2615\n",
              "                    %\"val_2701\"<INT64,[1]> ⬅️ ::Slice(%\"val_2699\", %\"val_50\"{[-1]}, %\"val_99\"{[9223372036854775807]})\n",
              "            1199 |  # node_Slice_2616\n",
              "                    %\"val_2702\"<INT64,[1]> ⬅️ ::Slice(%\"val_2699\", %\"val_137\"{[-2]}, %\"val_50\"{[-1]})\n",
              "            1200 |  # node_Slice_2618\n",
              "                    %\"val_2704\"<INT64,[2]> ⬅️ ::Slice(%\"val_2699\", %\"val_139\"{[-9223372036854775808]}, %\"val_137\"{[-2]})\n",
              "            1201 |  # node_Concat_2620\n",
              "                    %\"val_2706\"<INT64,[3]> ⬅️ ::Concat(%\"val_50\"{[-1]}, %\"val_2702\", %\"val_2701\") {axis=0}\n",
              "            1202 |  # node_Reshape_2621\n",
              "                    %\"val_2707\"<FLOAT,[None,None,None]> ⬅️ ::Reshape(%\"add_3355\", %\"val_2706\") {allowzero=0}\n",
              "            1203 |  # node_Transpose_2622\n",
              "                    %\"val_2708\"<FLOAT,[None,None,None]> ⬅️ ::Transpose(%\"val_2707\") {perm=(0, 2, 1)}\n",
              "            1204 |  # node_Concat_2623\n",
              "                    %\"val_2709\"<INT64,[4]> ⬅️ ::Concat(%\"val_2704\", %\"val_2701\", %\"val_2702\") {axis=0}\n",
              "            1205 |  # node_Reshape_2624\n",
              "                    %\"val_2710\"<FLOAT,[None,None,None,None]> ⬅️ ::Reshape(%\"val_2708\", %\"val_2709\") {allowzero=0}\n",
              "            1206 |  # node_Mul_2626\n",
              "                    %\"val_2712\"<FLOAT,[1,12,s53,64]> ⬅️ ::Mul(%\"add_3331\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1207 |  # node_Mul_2628\n",
              "                    %\"val_2714\"<FLOAT,[None,None,None,None]> ⬅️ ::Mul(%\"val_2710\", %\"val_147\"{[0.3535533845424652]})\n",
              "            1208 |  # node_MatMul_2629\n",
              "                    %\"val_2715\"<FLOAT,[None,12,s53,None]> ⬅️ ::MatMul(%\"val_2712\", %\"val_2714\")\n",
              "            1209 |  # node_Add_2630\n",
              "                    %\"val_2716\"<FLOAT,[None,12,s53,None]> ⬅️ ::Add(%\"val_2715\", %\"masked_fill\")\n",
              "            1210 |  # node_Softmax_2631\n",
              "                    %\"val_2717\"<FLOAT,[None,12,s53,None]> ⬅️ ::Softmax(%\"val_2716\") {axis=-1}\n",
              "            1211 |  # node_scaled_dot_product_attention_21\n",
              "                    %\"scaled_dot_product_attention_21\"<FLOAT,[1,12,s53,64]> ⬅️ ::MatMul(%\"val_2717\", %\"getitem_107\")\n",
              "            1212 |  # node_transpose_65\n",
              "                    %\"transpose_65\"<FLOAT,[1,s53,12,64]> ⬅️ ::Transpose(%\"scaled_dot_product_attention_21\") {perm=(0, 2, 1, 3)}\n",
              "            1213 |  # node_view_43\n",
              "                    %\"view_43\"<FLOAT,[1,s53,768]> ⬅️ ::Reshape(%\"transpose_65\", %\"val_158\") {allowzero=1}\n",
              "            1214 |  # node_linear_85\n",
              "                    %\"linear_85\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"view_43\", %\"val_2723\"{...})\n",
              "            1215 |  # node_add_3372\n",
              "                    %\"add_3372\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_3251\", %\"linear_85\")\n",
              "            1216 |  # node_layer_norm_43\n",
              "                    %\"layer_norm_43\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_3372\", %\"model.layers.21.mlp_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1217 |  # node_linear_86\n",
              "                    %\"linear_86\"<FLOAT,[1,s53,2304]> ⬅️ ::MatMul(%\"layer_norm_43\", %\"val_2726\"{...})\n",
              "            1218 |  # node_Split_3174\n",
              "                    %\"split_21_split_0\"<FLOAT,[1,s53,1152]>, %\"split_21_split_1\"<FLOAT,[1,s53,1152]> ⬅️ ::Split(%\"linear_86\") {axis=2, num_outputs=2}\n",
              "            1219 |  # node_Div_2640\n",
              "                    %\"val_2728\"<FLOAT,[1,s53,1152]> ⬅️ ::Div(%\"split_21_split_0\", %\"val_165\"{1.4142135381698608})\n",
              "            1220 |  # node_Erf_2641\n",
              "                    %\"val_2729\"<FLOAT,[1,s53,1152]> ⬅️ ::Erf(%\"val_2728\")\n",
              "            1221 |  # node_Add_2643\n",
              "                    %\"val_2731\"<FLOAT,[1,s53,1152]> ⬅️ ::Add(%\"val_2729\", %\"clone\"{1.0})\n",
              "            1222 |  # node_Mul_2645\n",
              "                    %\"val_2733\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2731\")\n",
              "            1223 |  # node_gelu_21\n",
              "                    %\"gelu_21\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"split_21_split_0\", %\"val_2733\")\n",
              "            1224 |  # node_mul_3438\n",
              "                    %\"mul_3438\"<FLOAT,[1,s53,1152]> ⬅️ ::Mul(%\"gelu_21\", %\"split_21_split_1\")\n",
              "            1225 |  # node_linear_87\n",
              "                    %\"linear_87\"<FLOAT,[1,s53,768]> ⬅️ ::MatMul(%\"mul_3438\", %\"val_2734\"{...})\n",
              "            1226 |  # node_add_3400\n",
              "                    %\"add_3400\"<FLOAT,[1,s53,768]> ⬅️ ::Add(%\"add_3372\", %\"linear_87\")\n",
              "            1227 |  # node_layer_norm_44\n",
              "                    %\"layer_norm_44\"<FLOAT,[1,s53,768]> ⬅️ ::LayerNormalization(%\"add_3400\", %\"model.final_norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1228 |  # node_unsqueeze_116\n",
              "                    %\"unsqueeze_116\"<INT64,[s43,s53,1]> ⬅️ ::Unsqueeze(%\"attention_mask\", %\"val_50\"{[-1]})\n",
              "            1229 |  # node_convert_element_type_default\n",
              "                    %\"convert_element_type_default\"<FLOAT,[s43,s53,1]> ⬅️ ::Cast(%\"unsqueeze_116\") {to=1}\n",
              "            1230 |  # node_mul_3456\n",
              "                    %\"mul_3456\"<FLOAT,[s43,s53,768]> ⬅️ ::Mul(%\"layer_norm_44\", %\"convert_element_type_default\")\n",
              "            1231 |  # node_sum_1\n",
              "                    %\"sum_1\"<FLOAT,[s43,768]> ⬅️ ::ReduceSum(%\"mul_3456\", %\"val_2739\"{[1]}) {noop_with_empty_axes=0, keepdims=0}\n",
              "            1232 |  # node_sum_2\n",
              "                    %\"sum_2\"<INT64,[s43,1]> ⬅️ ::ReduceSum(%\"attention_mask\", %\"val_2739\"{[1]}) {noop_with_empty_axes=0, keepdims=1}\n",
              "            1233 |  # node_convert_element_type_default_1\n",
              "                    %\"convert_element_type_default_1\"<FLOAT,[s43,1]> ⬅️ ::Cast(%\"sum_2\") {to=1}\n",
              "            1234 |  # node_div\n",
              "                    %\"div\"<FLOAT,[s43,768]> ⬅️ ::Div(%\"sum_1\", %\"convert_element_type_default_1\")\n",
              "            1235 |  # node_linear_88\n",
              "                    %\"linear_88\"<FLOAT,[s43,768]> ⬅️ ::Gemm(%\"div\", %\"head.dense.weight\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            1236 |  # node_Div_2654\n",
              "                    %\"val_2744\"<FLOAT,[s43,768]> ⬅️ ::Div(%\"linear_88\", %\"val_165\"{1.4142135381698608})\n",
              "            1237 |  # node_Erf_2655\n",
              "                    %\"val_2745\"<FLOAT,[s43,768]> ⬅️ ::Erf(%\"val_2744\")\n",
              "            1238 |  # node_Add_2657\n",
              "                    %\"val_2747\"<FLOAT,[s43,768]> ⬅️ ::Add(%\"val_2745\", %\"clone\"{1.0})\n",
              "            1239 |  # node_Mul_2659\n",
              "                    %\"val_2749\"<FLOAT,[s43,768]> ⬅️ ::Mul(%\"val_170\"{0.5}, %\"val_2747\")\n",
              "            1240 |  # node_gelu_22\n",
              "                    %\"gelu_22\"<FLOAT,[1,768]> ⬅️ ::Mul(%\"linear_88\", %\"val_2749\")\n",
              "            1241 |  # node_layer_norm_45\n",
              "                    %\"layer_norm_45\"<FLOAT,[1,768]> ⬅️ ::LayerNormalization(%\"gelu_22\", %\"head.norm.weight\"{...}) {stash_type=1, epsilon=1e-05, axis=-1}\n",
              "            1242 |  # node_linear_89\n",
              "                    %\"logits\"<FLOAT,[1,83]> ⬅️ ::Gemm(%\"layer_norm_45\", %\"classifier.weight\"{...}, %\"classifier.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
              "            return %\"logits\"<FLOAT,[1,83]>\n",
              "        }\n",
              "\n",
              "\n",
              "    ,\n",
              "    exported_program=\n",
              "        ExportedProgram:\n",
              "            class GraphModule(torch.nn.Module):\n",
              "                def forward(self, p_model_embeddings_tok_embeddings_weight: \"f32[50368, 768]\", p_model_embeddings_norm_weight: \"f32[768]\", p_model_layers_0_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_0_attn_wo_weight: \"f32[768, 768]\", p_model_layers_0_mlp_norm_weight: \"f32[768]\", p_model_layers_0_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_0_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_1_attn_norm_weight: \"f32[768]\", p_model_layers_1_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_1_attn_wo_weight: \"f32[768, 768]\", p_model_layers_1_mlp_norm_weight: \"f32[768]\", p_model_layers_1_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_1_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_2_attn_norm_weight: \"f32[768]\", p_model_layers_2_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_2_attn_wo_weight: \"f32[768, 768]\", p_model_layers_2_mlp_norm_weight: \"f32[768]\", p_model_layers_2_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_2_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_3_attn_norm_weight: \"f32[768]\", p_model_layers_3_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_3_attn_wo_weight: \"f32[768, 768]\", p_model_layers_3_mlp_norm_weight: \"f32[768]\", p_model_layers_3_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_3_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_4_attn_norm_weight: \"f32[768]\", p_model_layers_4_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_4_attn_wo_weight: \"f32[768, 768]\", p_model_layers_4_mlp_norm_weight: \"f32[768]\", p_model_layers_4_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_4_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_5_attn_norm_weight: \"f32[768]\", p_model_layers_5_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_5_attn_wo_weight: \"f32[768, 768]\", p_model_layers_5_mlp_norm_weight: \"f32[768]\", p_model_layers_5_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_5_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_6_attn_norm_weight: \"f32[768]\", p_model_layers_6_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_6_attn_wo_weight: \"f32[768, 768]\", p_model_layers_6_mlp_norm_weight: \"f32[768]\", p_model_layers_6_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_6_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_7_attn_norm_weight: \"f32[768]\", p_model_layers_7_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_7_attn_wo_weight: \"f32[768, 768]\", p_model_layers_7_mlp_norm_weight: \"f32[768]\", p_model_layers_7_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_7_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_8_attn_norm_weight: \"f32[768]\", p_model_layers_8_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_8_attn_wo_weight: \"f32[768, 768]\", p_model_layers_8_mlp_norm_weight: \"f32[768]\", p_model_layers_8_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_8_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_9_attn_norm_weight: \"f32[768]\", p_model_layers_9_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_9_attn_wo_weight: \"f32[768, 768]\", p_model_layers_9_mlp_norm_weight: \"f32[768]\", p_model_layers_9_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_9_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_10_attn_norm_weight: \"f32[768]\", p_model_layers_10_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_10_attn_wo_weight: \"f32[768, 768]\", p_model_layers_10_mlp_norm_weight: \"f32[768]\", p_model_layers_10_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_10_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_11_attn_norm_weight: \"f32[768]\", p_model_layers_11_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_11_attn_wo_weight: \"f32[768, 768]\", p_model_layers_11_mlp_norm_weight: \"f32[768]\", p_model_layers_11_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_11_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_12_attn_norm_weight: \"f32[768]\", p_model_layers_12_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_12_attn_wo_weight: \"f32[768, 768]\", p_model_layers_12_mlp_norm_weight: \"f32[768]\", p_model_layers_12_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_12_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_13_attn_norm_weight: \"f32[768]\", p_model_layers_13_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_13_attn_wo_weight: \"f32[768, 768]\", p_model_layers_13_mlp_norm_weight: \"f32[768]\", p_model_layers_13_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_13_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_14_attn_norm_weight: \"f32[768]\", p_model_layers_14_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_14_attn_wo_weight: \"f32[768, 768]\", p_model_layers_14_mlp_norm_weight: \"f32[768]\", p_model_layers_14_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_14_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_15_attn_norm_weight: \"f32[768]\", p_model_layers_15_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_15_attn_wo_weight: \"f32[768, 768]\", p_model_layers_15_mlp_norm_weight: \"f32[768]\", p_model_layers_15_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_15_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_16_attn_norm_weight: \"f32[768]\", p_model_layers_16_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_16_attn_wo_weight: \"f32[768, 768]\", p_model_layers_16_mlp_norm_weight: \"f32[768]\", p_model_layers_16_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_16_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_17_attn_norm_weight: \"f32[768]\", p_model_layers_17_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_17_attn_wo_weight: \"f32[768, 768]\", p_model_layers_17_mlp_norm_weight: \"f32[768]\", p_model_layers_17_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_17_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_18_attn_norm_weight: \"f32[768]\", p_model_layers_18_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_18_attn_wo_weight: \"f32[768, 768]\", p_model_layers_18_mlp_norm_weight: \"f32[768]\", p_model_layers_18_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_18_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_19_attn_norm_weight: \"f32[768]\", p_model_layers_19_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_19_attn_wo_weight: \"f32[768, 768]\", p_model_layers_19_mlp_norm_weight: \"f32[768]\", p_model_layers_19_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_19_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_20_attn_norm_weight: \"f32[768]\", p_model_layers_20_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_20_attn_wo_weight: \"f32[768, 768]\", p_model_layers_20_mlp_norm_weight: \"f32[768]\", p_model_layers_20_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_20_mlp_wo_weight: \"f32[768, 1152]\", p_model_layers_21_attn_norm_weight: \"f32[768]\", p_model_layers_21_attn_wqkv_weight: \"f32[2304, 768]\", p_model_layers_21_attn_wo_weight: \"f32[768, 768]\", p_model_layers_21_mlp_norm_weight: \"f32[768]\", p_model_layers_21_mlp_wi_weight: \"f32[2304, 768]\", p_model_layers_21_mlp_wo_weight: \"f32[768, 1152]\", p_model_final_norm_weight: \"f32[768]\", p_head_dense_weight: \"f32[768, 768]\", p_head_norm_weight: \"f32[768]\", p_classifier_weight: \"f32[83, 768]\", p_classifier_bias: \"f32[83]\", c_model_lifted_tensor_0: \"f32[]\", b_model_layers_0_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_1_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_2_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_3_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_4_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_5_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_6_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_7_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_8_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_9_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_10_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_11_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_12_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_13_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_14_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_15_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_16_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_17_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_18_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_19_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_20_attn_rotary_emb_inv_freq: \"f32[32]\", b_model_layers_21_attn_rotary_emb_inv_freq: \"f32[32]\", input_ids: \"i64[s72, s53]\", attention_mask: \"i64[s43, s53]\"):\n",
              "                     # \n",
              "                    sym_size_int_118: \"Sym(s72)\" = torch.ops.aten.sym_size.int(input_ids, 0)\n",
              "                    sym_size_int_120: \"Sym(s43)\" = torch.ops.aten.sym_size.int(attention_mask, 0)\n",
              "                    sym_size_int_121: \"Sym(s53)\" = torch.ops.aten.sym_size.int(attention_mask, 1)\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:857 in forward, code: position_ids = torch.arange(seq_len, device=device).unsqueeze(0)\n",
              "                    arange: \"i64[s53]\" = torch.ops.aten.arange.default(sym_size_int_121, device = device(type='cpu'), pin_memory = False)\n",
              "                    unsqueeze: \"i64[1, s53]\" = torch.ops.aten.unsqueeze.default(arange, 0);  arange = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:859 in forward, code: attention_mask, sliding_window_mask = self._update_attention_mask(\n",
              "                    slice_1: \"i64[s43, s53]\" = torch.ops.aten.slice.Tensor(attention_mask, 0, 0, 9223372036854775807)\n",
              "                    unsqueeze_1: \"i64[s43, 1, s53]\" = torch.ops.aten.unsqueeze.default(slice_1, 1);  slice_1 = None\n",
              "                    unsqueeze_2: \"i64[s43, 1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze_1, 2);  unsqueeze_1 = None\n",
              "                    slice_2: \"i64[s43, 1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_2, 3, 0, 9223372036854775807);  unsqueeze_2 = None\n",
              "                    expand: \"i64[s43, 1, s53, s53]\" = torch.ops.aten.expand.default(slice_2, [sym_size_int_120, 1, sym_size_int_121, sym_size_int_121]);  slice_2 = sym_size_int_120 = None\n",
              "                    _to_copy: \"f32[s43, 1, s53, s53]\" = torch.ops.aten._to_copy.default(expand, dtype = torch.float32);  expand = None\n",
              "                    clone: \"f32[]\" = torch.ops.aten.clone.default(c_model_lifted_tensor_0);  c_model_lifted_tensor_0 = None\n",
              "                    sub_16: \"f32[s43, 1, s53, s53]\" = torch.ops.aten.sub.Tensor(clone, _to_copy);  clone = _to_copy = None\n",
              "                    _to_copy_1: \"b8[s43, 1, s53, s53]\" = torch.ops.aten._to_copy.default(sub_16, dtype = torch.bool)\n",
              "                    masked_fill: \"f32[s43, 1, s53, s53]\" = torch.ops.aten.masked_fill.Scalar(sub_16, _to_copy_1, -3.4028234663852886e+38);  sub_16 = _to_copy_1 = None\n",
              "                    arange_1: \"i64[s53]\" = torch.ops.aten.arange.default(sym_size_int_121, device = device(type='cpu'), pin_memory = False);  sym_size_int_121 = None\n",
              "                    unsqueeze_3: \"i64[1, s53]\" = torch.ops.aten.unsqueeze.default(arange_1, 0);  arange_1 = None\n",
              "                    permute: \"i64[s53, 1]\" = torch.ops.aten.permute.default(unsqueeze_3, [1, 0])\n",
              "                    sub_29: \"i64[s53, s53]\" = torch.ops.aten.sub.Tensor(unsqueeze_3, permute);  unsqueeze_3 = permute = None\n",
              "                    abs_1: \"i64[s53, s53]\" = torch.ops.aten.abs.default(sub_29);  sub_29 = None\n",
              "                    le_1: \"b8[s53, s53]\" = torch.ops.aten.le.Scalar(abs_1, 64);  abs_1 = None\n",
              "                    unsqueeze_4: \"b8[1, s53, s53]\" = torch.ops.aten.unsqueeze.default(le_1, 0);  le_1 = None\n",
              "                    unsqueeze_5: \"b8[1, 1, s53, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze_4, 0);  unsqueeze_4 = None\n",
              "                    logical_not: \"b8[1, 1, s53, s53]\" = torch.ops.aten.logical_not.default(unsqueeze_5);  unsqueeze_5 = None\n",
              "                    masked_fill_1: \"f32[1, 1, s53, s53]\" = torch.ops.aten.masked_fill.Scalar(masked_fill, logical_not, -3.4028234663852886e+38);  logical_not = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:192 in forward, code: return F.embedding(\n",
              "                    embedding: \"f32[s72, s53, 768]\" = torch.ops.aten.embedding.default(p_model_embeddings_tok_embeddings_weight, input_ids, 50283);  p_model_embeddings_tok_embeddings_weight = input_ids = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm: \"f32[s72, s53, 768]\" = torch.ops.aten.layer_norm.default(embedding, [768], p_model_embeddings_norm_weight);  embedding = p_model_embeddings_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_1: \"f32[s72, s53, 768]\" = torch.ops.aten.clone.default(layer_norm);  layer_norm = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear: \"f32[s72, (s53//s72), 2304]\" = torch.ops.aten.linear.default(clone_1, p_model_layers_0_attn_wqkv_weight);  p_model_layers_0_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view: \"f32[s72, (s53//s72), 3, 12, 64]\" = torch.ops.aten.view.default(linear, [sym_size_int_118, -1, 3, 12, 64]);  linear = None\n",
              "            \n",
              "                     # File: <eval_with_key>.671:5 in forward, code: unsqueeze_6 = torch.ops.aten.unsqueeze.default(b_model_layers_0_attn_rotary_emb_inv_freq, 0);  b_model_layers_0_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_6: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_0_attn_rotary_emb_inv_freq, 0);  b_model_layers_0_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.671:6 in forward, code: unsqueeze_7 = torch.ops.aten.unsqueeze.default(unsqueeze_6, 2);  unsqueeze_6 = None\n",
              "                    unsqueeze_7: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_6, 2);  unsqueeze_6 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.671:9 in forward, code: expand_1 = torch.ops.aten.expand.default(to_3, [1, -1, 1]);  to_3 = None\n",
              "                    expand_1: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_7, [1, -1, 1]);  unsqueeze_7 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.671:12 in forward, code: unsqueeze_8 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_8: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.671:13 in forward, code: slice_3 = torch.ops.aten.slice.Tensor(unsqueeze_8, 2, 0, 9223372036854775807);  unsqueeze_8 = None\n",
              "                    slice_3: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_8, 2, 0, 9223372036854775807);  unsqueeze_8 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.671:15 in forward, code: to_5 = torch.ops.aten.to.dtype(slice_3, torch.float32);  slice_3 = None\n",
              "                    _to_copy_2: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_3, dtype = torch.float32);  slice_3 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.458:9 in forward, code: matmul = torch.ops.aten.matmul.default(to_6, to_7);  to_6 = to_7 = None\n",
              "                    matmul: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_1, _to_copy_2);  expand_1 = _to_copy_2 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.458:10 in forward, code: transpose = torch.ops.aten.transpose.int(matmul, 1, 2);  matmul = None\n",
              "                    transpose: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul, 1, 2);  matmul = None\n",
              "            \n",
              "                     # File: <eval_with_key>.458:11 in forward, code: cat = torch.ops.aten.cat.default([transpose, transpose], -1);  transpose = None\n",
              "                    cat: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose, transpose], -1);  transpose = None\n",
              "            \n",
              "                     # File: <eval_with_key>.458:12 in forward, code: cos = torch.ops.aten.cos.default(cat)\n",
              "                    cos: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat)\n",
              "            \n",
              "                     # File: <eval_with_key>.458:13 in forward, code: mul = torch.ops.aten.mul.Tensor(cos, 1.0);  cos = None\n",
              "                    mul_93: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos, 1.0);  cos = None\n",
              "            \n",
              "                     # File: <eval_with_key>.458:14 in forward, code: sin = torch.ops.aten.sin.default(cat);  cat = None\n",
              "                    sin: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat);  cat = None\n",
              "            \n",
              "                     # File: <eval_with_key>.458:15 in forward, code: mul_1 = torch.ops.aten.mul.Tensor(sin, 1.0);  sin = None\n",
              "                    mul_100: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin, 1.0);  sin = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_1: \"f32[s72, 12, 3, (s53//s72), 64]\" = torch.ops.aten.transpose.int(view, 3, 1);  view = None\n",
              "                    unbind = torch.ops.aten.unbind.int(transpose_1, 2);  transpose_1 = None\n",
              "                    getitem: \"f32[s72, 12, (s53//s72), 64]\" = unbind[0]\n",
              "                    getitem_1: \"f32[s72, 12, (s53//s72), 64]\" = unbind[1]\n",
              "                    getitem_2: \"f32[s72, 12, (s53//s72), 64]\" = unbind[2];  unbind = None\n",
              "                    unsqueeze_9: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_93, 1);  mul_93 = None\n",
              "                    unsqueeze_10: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_100, 1);  mul_100 = None\n",
              "                    mul_124: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.mul.Tensor(getitem, unsqueeze_9)\n",
              "                    slice_4: \"f32[s72, 12, (s53//s72), 32]\" = torch.ops.aten.slice.Tensor(getitem, 3, 0, 32)\n",
              "                    slice_5: \"f32[s72, 12, (s53//s72), 32]\" = torch.ops.aten.slice.Tensor(getitem, 3, 32, 9223372036854775807);  getitem = None\n",
              "                    neg: \"f32[s72, 12, (s53//s72), 32]\" = torch.ops.aten.neg.default(slice_5);  slice_5 = None\n",
              "                    cat_1: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.cat.default([neg, slice_4], -1);  neg = slice_4 = None\n",
              "                    mul_141: \"f32[1, 12, (s53//s72), 64]\" = torch.ops.aten.mul.Tensor(cat_1, unsqueeze_10);  cat_1 = None\n",
              "                    add_179: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.add.Tensor(mul_124, mul_141);  mul_124 = mul_141 = None\n",
              "                    mul_149: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.mul.Tensor(getitem_1, unsqueeze_9);  unsqueeze_9 = None\n",
              "                    slice_6: \"f32[s72, 12, (s53//s72), 32]\" = torch.ops.aten.slice.Tensor(getitem_1, 3, 0, 32)\n",
              "                    slice_7: \"f32[s72, 12, (s53//s72), 32]\" = torch.ops.aten.slice.Tensor(getitem_1, 3, 32, 9223372036854775807);  getitem_1 = None\n",
              "                    neg_1: \"f32[s72, 12, (s53//s72), 32]\" = torch.ops.aten.neg.default(slice_7);  slice_7 = None\n",
              "                    cat_2: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.cat.default([neg_1, slice_6], -1);  neg_1 = slice_6 = None\n",
              "                    mul_166: \"f32[1, 12, (s53//s72), 64]\" = torch.ops.aten.mul.Tensor(cat_2, unsqueeze_10);  cat_2 = unsqueeze_10 = None\n",
              "                    add_214: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.add.Tensor(mul_149, mul_166);  mul_149 = mul_166 = None\n",
              "                    scaled_dot_product_attention: \"f32[s72, 12, (s53//s72), 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_179, add_214, getitem_2, masked_fill);  add_179 = add_214 = getitem_2 = None\n",
              "                    transpose_2: \"f32[s72, (s53//s72), 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention, 1, 2);  scaled_dot_product_attention = None\n",
              "                    view_1: \"f32[s72, (s53//s72), 768]\" = torch.ops.aten.view.default(transpose_2, [sym_size_int_118, -1, 768]);  transpose_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_1: \"f32[s72, (s53//(s72**2)), 768]\" = torch.ops.aten.linear.default(view_1, p_model_layers_0_attn_wo_weight);  view_1 = p_model_layers_0_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_238: \"f32[s72, s53, 768]\" = torch.ops.aten.add.Tensor(clone_1, linear_1);  clone_1 = linear_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_1: \"f32[s72, s53, 768]\" = torch.ops.aten.layer_norm.default(add_238, [768], p_model_layers_0_mlp_norm_weight);  p_model_layers_0_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_2: \"f32[s72, (s53//s72), 2304]\" = torch.ops.aten.linear.default(layer_norm_1, p_model_layers_0_mlp_wi_weight);  layer_norm_1 = p_model_layers_0_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split = torch.ops.aten.split.Tensor(linear_2, 1152, -1);  linear_2 = None\n",
              "                    getitem_3: \"f32[s72, (s53//s72), 1152]\" = split[0]\n",
              "                    getitem_4: \"f32[s72, (s53//s72), 1152]\" = split[1];  split = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu: \"f32[1, (s53//s72), 1152]\" = torch.ops.aten.gelu.default(getitem_3);  getitem_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_204: \"f32[1, (s53//s72), 1152]\" = torch.ops.aten.mul.Tensor(gelu, getitem_4);  gelu = getitem_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_2: \"f32[1, (s53//s72), 1152]\" = torch.ops.aten.clone.default(mul_204);  mul_204 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_3: \"f32[1, (s53//s72), 768]\" = torch.ops.aten.linear.default(clone_2, p_model_layers_0_mlp_wo_weight);  clone_2 = p_model_layers_0_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_271: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_238, linear_3);  add_238 = linear_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_2: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_271, [768], p_model_layers_1_attn_norm_weight);  p_model_layers_1_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_4: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_2, p_model_layers_1_attn_wqkv_weight);  layer_norm_2 = p_model_layers_1_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_2: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_4, [sym_size_int_118, -1, 3, 12, 64]);  linear_4 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.672:5 in forward, code: unsqueeze_11 = torch.ops.aten.unsqueeze.default(b_model_layers_1_attn_rotary_emb_inv_freq, 0);  b_model_layers_1_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_11: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_1_attn_rotary_emb_inv_freq, 0);  b_model_layers_1_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.672:6 in forward, code: unsqueeze_12 = torch.ops.aten.unsqueeze.default(unsqueeze_11, 2);  unsqueeze_11 = None\n",
              "                    unsqueeze_12: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_11, 2);  unsqueeze_11 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.672:9 in forward, code: expand_2 = torch.ops.aten.expand.default(to_10, [1, -1, 1]);  to_10 = None\n",
              "                    expand_2: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_12, [1, -1, 1]);  unsqueeze_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.672:12 in forward, code: unsqueeze_13 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_13: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.672:13 in forward, code: slice_8 = torch.ops.aten.slice.Tensor(unsqueeze_13, 2, 0, 9223372036854775807);  unsqueeze_13 = None\n",
              "                    slice_8: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_13, 2, 0, 9223372036854775807);  unsqueeze_13 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.672:15 in forward, code: to_12 = torch.ops.aten.to.dtype(slice_8, torch.float32);  slice_8 = None\n",
              "                    _to_copy_3: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_8, dtype = torch.float32);  slice_8 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.468:9 in forward, code: matmul_1 = torch.ops.aten.matmul.default(to_13, to_14);  to_13 = to_14 = None\n",
              "                    matmul_1: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_2, _to_copy_3);  expand_2 = _to_copy_3 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.468:10 in forward, code: transpose_3 = torch.ops.aten.transpose.int(matmul_1, 1, 2);  matmul_1 = None\n",
              "                    transpose_3: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_1, 1, 2);  matmul_1 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.468:11 in forward, code: cat_3 = torch.ops.aten.cat.default([transpose_3, transpose_3], -1);  transpose_3 = None\n",
              "                    cat_3: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_3, transpose_3], -1);  transpose_3 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.468:12 in forward, code: cos_1 = torch.ops.aten.cos.default(cat_3)\n",
              "                    cos_1: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_3)\n",
              "            \n",
              "                     # File: <eval_with_key>.468:13 in forward, code: mul_11 = torch.ops.aten.mul.Tensor(cos_1, 1.0);  cos_1 = None\n",
              "                    mul_247: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_1, 1.0);  cos_1 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.468:14 in forward, code: sin_1 = torch.ops.aten.sin.default(cat_3);  cat_3 = None\n",
              "                    sin_1: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_3);  cat_3 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.468:15 in forward, code: mul_12 = torch.ops.aten.mul.Tensor(sin_1, 1.0);  sin_1 = None\n",
              "                    mul_254: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_1, 1.0);  sin_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_4: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_2, 3, 1);  view_2 = None\n",
              "                    unbind_1 = torch.ops.aten.unbind.int(transpose_4, 2);  transpose_4 = None\n",
              "                    getitem_5: \"f32[1, 12, s53, 64]\" = unbind_1[0]\n",
              "                    getitem_6: \"f32[1, 12, s53, 64]\" = unbind_1[1]\n",
              "                    getitem_7: \"f32[1, 12, s53, 64]\" = unbind_1[2];  unbind_1 = None\n",
              "                    unsqueeze_14: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_247, 1);  mul_247 = None\n",
              "                    unsqueeze_15: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_254, 1);  mul_254 = None\n",
              "                    mul_278: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_5, unsqueeze_14)\n",
              "                    slice_9: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_5, 3, 0, 32)\n",
              "                    slice_10: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_5, 3, 32, 9223372036854775807);  getitem_5 = None\n",
              "                    neg_2: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_10);  slice_10 = None\n",
              "                    cat_4: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_2, slice_9], -1);  neg_2 = slice_9 = None\n",
              "                    mul_295: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_4, unsqueeze_15);  cat_4 = None\n",
              "                    add_351: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_278, mul_295);  mul_278 = mul_295 = None\n",
              "                    mul_303: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_6, unsqueeze_14);  unsqueeze_14 = None\n",
              "                    slice_11: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_6, 3, 0, 32)\n",
              "                    slice_12: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_6, 3, 32, 9223372036854775807);  getitem_6 = None\n",
              "                    neg_3: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_12);  slice_12 = None\n",
              "                    cat_5: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_3, slice_11], -1);  neg_3 = slice_11 = None\n",
              "                    mul_320: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_5, unsqueeze_15);  cat_5 = unsqueeze_15 = None\n",
              "                    add_375: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_303, mul_320);  mul_303 = mul_320 = None\n",
              "                    scaled_dot_product_attention_1: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_351, add_375, getitem_7, masked_fill_1);  add_351 = add_375 = getitem_7 = None\n",
              "                    transpose_5: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_1, 1, 2);  scaled_dot_product_attention_1 = None\n",
              "                    view_3: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_5, [sym_size_int_118, -1, 768]);  transpose_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_5: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_3, p_model_layers_1_attn_wo_weight);  view_3 = p_model_layers_1_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_392: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_271, linear_5);  add_271 = linear_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_3: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_392, [768], p_model_layers_1_mlp_norm_weight);  p_model_layers_1_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_6: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_3, p_model_layers_1_mlp_wi_weight);  layer_norm_3 = p_model_layers_1_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_1 = torch.ops.aten.split.Tensor(linear_6, 1152, -1);  linear_6 = None\n",
              "                    getitem_8: \"f32[1, s53, 1152]\" = split_1[0]\n",
              "                    getitem_9: \"f32[1, s53, 1152]\" = split_1[1];  split_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_1: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_8);  getitem_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_358: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_1, getitem_9);  gelu_1 = getitem_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_3: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_358);  mul_358 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_7: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_3, p_model_layers_1_mlp_wo_weight);  clone_3 = p_model_layers_1_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_420: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_392, linear_7);  add_392 = linear_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_4: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_420, [768], p_model_layers_2_attn_norm_weight);  p_model_layers_2_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_8: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_4, p_model_layers_2_attn_wqkv_weight);  layer_norm_4 = p_model_layers_2_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_4: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_8, [sym_size_int_118, -1, 3, 12, 64]);  linear_8 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.673:5 in forward, code: unsqueeze_16 = torch.ops.aten.unsqueeze.default(b_model_layers_2_attn_rotary_emb_inv_freq, 0);  b_model_layers_2_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_16: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_2_attn_rotary_emb_inv_freq, 0);  b_model_layers_2_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.673:6 in forward, code: unsqueeze_17 = torch.ops.aten.unsqueeze.default(unsqueeze_16, 2);  unsqueeze_16 = None\n",
              "                    unsqueeze_17: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_16, 2);  unsqueeze_16 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.673:9 in forward, code: expand_3 = torch.ops.aten.expand.default(to_17, [1, -1, 1]);  to_17 = None\n",
              "                    expand_3: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_17, [1, -1, 1]);  unsqueeze_17 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.673:12 in forward, code: unsqueeze_18 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_18: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.673:13 in forward, code: slice_13 = torch.ops.aten.slice.Tensor(unsqueeze_18, 2, 0, 9223372036854775807);  unsqueeze_18 = None\n",
              "                    slice_13: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_18, 2, 0, 9223372036854775807);  unsqueeze_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.673:15 in forward, code: to_19 = torch.ops.aten.to.dtype(slice_13, torch.float32);  slice_13 = None\n",
              "                    _to_copy_4: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_13, dtype = torch.float32);  slice_13 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.478:9 in forward, code: matmul_2 = torch.ops.aten.matmul.default(to_20, to_21);  to_20 = to_21 = None\n",
              "                    matmul_2: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_3, _to_copy_4);  expand_3 = _to_copy_4 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.478:10 in forward, code: transpose_6 = torch.ops.aten.transpose.int(matmul_2, 1, 2);  matmul_2 = None\n",
              "                    transpose_6: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_2, 1, 2);  matmul_2 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.478:11 in forward, code: cat_6 = torch.ops.aten.cat.default([transpose_6, transpose_6], -1);  transpose_6 = None\n",
              "                    cat_6: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_6, transpose_6], -1);  transpose_6 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.478:12 in forward, code: cos_2 = torch.ops.aten.cos.default(cat_6)\n",
              "                    cos_2: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_6)\n",
              "            \n",
              "                     # File: <eval_with_key>.478:13 in forward, code: mul_22 = torch.ops.aten.mul.Tensor(cos_2, 1.0);  cos_2 = None\n",
              "                    mul_401: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_2, 1.0);  cos_2 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.478:14 in forward, code: sin_2 = torch.ops.aten.sin.default(cat_6);  cat_6 = None\n",
              "                    sin_2: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_6);  cat_6 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.478:15 in forward, code: mul_23 = torch.ops.aten.mul.Tensor(sin_2, 1.0);  sin_2 = None\n",
              "                    mul_408: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_2, 1.0);  sin_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_7: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_4, 3, 1);  view_4 = None\n",
              "                    unbind_2 = torch.ops.aten.unbind.int(transpose_7, 2);  transpose_7 = None\n",
              "                    getitem_10: \"f32[1, 12, s53, 64]\" = unbind_2[0]\n",
              "                    getitem_11: \"f32[1, 12, s53, 64]\" = unbind_2[1]\n",
              "                    getitem_12: \"f32[1, 12, s53, 64]\" = unbind_2[2];  unbind_2 = None\n",
              "                    unsqueeze_19: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_401, 1);  mul_401 = None\n",
              "                    unsqueeze_20: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_408, 1);  mul_408 = None\n",
              "                    mul_432: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_10, unsqueeze_19)\n",
              "                    slice_14: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_10, 3, 0, 32)\n",
              "                    slice_15: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_10, 3, 32, 9223372036854775807);  getitem_10 = None\n",
              "                    neg_4: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_15);  slice_15 = None\n",
              "                    cat_7: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_4, slice_14], -1);  neg_4 = slice_14 = None\n",
              "                    mul_449: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_7, unsqueeze_20);  cat_7 = None\n",
              "                    add_500: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_432, mul_449);  mul_432 = mul_449 = None\n",
              "                    mul_457: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_11, unsqueeze_19);  unsqueeze_19 = None\n",
              "                    slice_16: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_11, 3, 0, 32)\n",
              "                    slice_17: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_11, 3, 32, 9223372036854775807);  getitem_11 = None\n",
              "                    neg_5: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_17);  slice_17 = None\n",
              "                    cat_8: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_5, slice_16], -1);  neg_5 = slice_16 = None\n",
              "                    mul_474: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_8, unsqueeze_20);  cat_8 = unsqueeze_20 = None\n",
              "                    add_524: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_457, mul_474);  mul_457 = mul_474 = None\n",
              "                    scaled_dot_product_attention_2: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_500, add_524, getitem_12, masked_fill_1);  add_500 = add_524 = getitem_12 = None\n",
              "                    transpose_8: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_2, 1, 2);  scaled_dot_product_attention_2 = None\n",
              "                    view_5: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_8, [sym_size_int_118, -1, 768]);  transpose_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_9: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_5, p_model_layers_2_attn_wo_weight);  view_5 = p_model_layers_2_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_541: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_420, linear_9);  add_420 = linear_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_5: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_541, [768], p_model_layers_2_mlp_norm_weight);  p_model_layers_2_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_10: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_5, p_model_layers_2_mlp_wi_weight);  layer_norm_5 = p_model_layers_2_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_2 = torch.ops.aten.split.Tensor(linear_10, 1152, -1);  linear_10 = None\n",
              "                    getitem_13: \"f32[1, s53, 1152]\" = split_2[0]\n",
              "                    getitem_14: \"f32[1, s53, 1152]\" = split_2[1];  split_2 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_2: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_13);  getitem_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_512: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_2, getitem_14);  gelu_2 = getitem_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_4: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_512);  mul_512 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_11: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_4, p_model_layers_2_mlp_wo_weight);  clone_4 = p_model_layers_2_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_569: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_541, linear_11);  add_541 = linear_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_6: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_569, [768], p_model_layers_3_attn_norm_weight);  p_model_layers_3_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_12: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_6, p_model_layers_3_attn_wqkv_weight);  layer_norm_6 = p_model_layers_3_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_6: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_12, [sym_size_int_118, -1, 3, 12, 64]);  linear_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.674:5 in forward, code: unsqueeze_21 = torch.ops.aten.unsqueeze.default(b_model_layers_3_attn_rotary_emb_inv_freq, 0);  b_model_layers_3_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_21: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_3_attn_rotary_emb_inv_freq, 0);  b_model_layers_3_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.674:6 in forward, code: unsqueeze_22 = torch.ops.aten.unsqueeze.default(unsqueeze_21, 2);  unsqueeze_21 = None\n",
              "                    unsqueeze_22: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_21, 2);  unsqueeze_21 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.674:9 in forward, code: expand_4 = torch.ops.aten.expand.default(to_24, [1, -1, 1]);  to_24 = None\n",
              "                    expand_4: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_22, [1, -1, 1]);  unsqueeze_22 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.674:12 in forward, code: unsqueeze_23 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_23: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.674:13 in forward, code: slice_18 = torch.ops.aten.slice.Tensor(unsqueeze_23, 2, 0, 9223372036854775807);  unsqueeze_23 = None\n",
              "                    slice_18: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_23, 2, 0, 9223372036854775807);  unsqueeze_23 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.674:15 in forward, code: to_26 = torch.ops.aten.to.dtype(slice_18, torch.float32);  slice_18 = None\n",
              "                    _to_copy_5: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_18, dtype = torch.float32);  slice_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.488:9 in forward, code: matmul_3 = torch.ops.aten.matmul.default(to_27, to_28);  to_27 = to_28 = None\n",
              "                    matmul_3: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_4, _to_copy_5);  expand_4 = _to_copy_5 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.488:10 in forward, code: transpose_9 = torch.ops.aten.transpose.int(matmul_3, 1, 2);  matmul_3 = None\n",
              "                    transpose_9: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_3, 1, 2);  matmul_3 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.488:11 in forward, code: cat_9 = torch.ops.aten.cat.default([transpose_9, transpose_9], -1);  transpose_9 = None\n",
              "                    cat_9: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_9, transpose_9], -1);  transpose_9 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.488:12 in forward, code: cos_3 = torch.ops.aten.cos.default(cat_9)\n",
              "                    cos_3: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_9)\n",
              "            \n",
              "                     # File: <eval_with_key>.488:13 in forward, code: mul_33 = torch.ops.aten.mul.Tensor(cos_3, 1.0);  cos_3 = None\n",
              "                    mul_555: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_3, 1.0);  cos_3 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.488:14 in forward, code: sin_3 = torch.ops.aten.sin.default(cat_9);  cat_9 = None\n",
              "                    sin_3: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_9);  cat_9 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.488:15 in forward, code: mul_34 = torch.ops.aten.mul.Tensor(sin_3, 1.0);  sin_3 = None\n",
              "                    mul_562: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_3, 1.0);  sin_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_10: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_6, 3, 1);  view_6 = None\n",
              "                    unbind_3 = torch.ops.aten.unbind.int(transpose_10, 2);  transpose_10 = None\n",
              "                    getitem_15: \"f32[1, 12, s53, 64]\" = unbind_3[0]\n",
              "                    getitem_16: \"f32[1, 12, s53, 64]\" = unbind_3[1]\n",
              "                    getitem_17: \"f32[1, 12, s53, 64]\" = unbind_3[2];  unbind_3 = None\n",
              "                    unsqueeze_24: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_555, 1);  mul_555 = None\n",
              "                    unsqueeze_25: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_562, 1);  mul_562 = None\n",
              "                    mul_586: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_15, unsqueeze_24)\n",
              "                    slice_19: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_15, 3, 0, 32)\n",
              "                    slice_20: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_15, 3, 32, 9223372036854775807);  getitem_15 = None\n",
              "                    neg_6: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_20);  slice_20 = None\n",
              "                    cat_10: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_6, slice_19], -1);  neg_6 = slice_19 = None\n",
              "                    mul_603: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_10, unsqueeze_25);  cat_10 = None\n",
              "                    add_649: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_586, mul_603);  mul_586 = mul_603 = None\n",
              "                    mul_611: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_16, unsqueeze_24);  unsqueeze_24 = None\n",
              "                    slice_21: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_16, 3, 0, 32)\n",
              "                    slice_22: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_16, 3, 32, 9223372036854775807);  getitem_16 = None\n",
              "                    neg_7: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_22);  slice_22 = None\n",
              "                    cat_11: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_7, slice_21], -1);  neg_7 = slice_21 = None\n",
              "                    mul_628: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_11, unsqueeze_25);  cat_11 = unsqueeze_25 = None\n",
              "                    add_673: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_611, mul_628);  mul_611 = mul_628 = None\n",
              "                    scaled_dot_product_attention_3: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_649, add_673, getitem_17, masked_fill);  add_649 = add_673 = getitem_17 = None\n",
              "                    transpose_11: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_3, 1, 2);  scaled_dot_product_attention_3 = None\n",
              "                    view_7: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_11, [sym_size_int_118, -1, 768]);  transpose_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_13: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_7, p_model_layers_3_attn_wo_weight);  view_7 = p_model_layers_3_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_690: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_569, linear_13);  add_569 = linear_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_7: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_690, [768], p_model_layers_3_mlp_norm_weight);  p_model_layers_3_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_14: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_7, p_model_layers_3_mlp_wi_weight);  layer_norm_7 = p_model_layers_3_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_3 = torch.ops.aten.split.Tensor(linear_14, 1152, -1);  linear_14 = None\n",
              "                    getitem_18: \"f32[1, s53, 1152]\" = split_3[0]\n",
              "                    getitem_19: \"f32[1, s53, 1152]\" = split_3[1];  split_3 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_3: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_18);  getitem_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_666: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_3, getitem_19);  gelu_3 = getitem_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_5: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_666);  mul_666 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_15: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_5, p_model_layers_3_mlp_wo_weight);  clone_5 = p_model_layers_3_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_718: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_690, linear_15);  add_690 = linear_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_8: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_718, [768], p_model_layers_4_attn_norm_weight);  p_model_layers_4_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_16: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_8, p_model_layers_4_attn_wqkv_weight);  layer_norm_8 = p_model_layers_4_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_8: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_16, [sym_size_int_118, -1, 3, 12, 64]);  linear_16 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.675:5 in forward, code: unsqueeze_26 = torch.ops.aten.unsqueeze.default(b_model_layers_4_attn_rotary_emb_inv_freq, 0);  b_model_layers_4_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_26: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_4_attn_rotary_emb_inv_freq, 0);  b_model_layers_4_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.675:6 in forward, code: unsqueeze_27 = torch.ops.aten.unsqueeze.default(unsqueeze_26, 2);  unsqueeze_26 = None\n",
              "                    unsqueeze_27: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_26, 2);  unsqueeze_26 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.675:9 in forward, code: expand_5 = torch.ops.aten.expand.default(to_31, [1, -1, 1]);  to_31 = None\n",
              "                    expand_5: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_27, [1, -1, 1]);  unsqueeze_27 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.675:12 in forward, code: unsqueeze_28 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_28: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.675:13 in forward, code: slice_23 = torch.ops.aten.slice.Tensor(unsqueeze_28, 2, 0, 9223372036854775807);  unsqueeze_28 = None\n",
              "                    slice_23: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_28, 2, 0, 9223372036854775807);  unsqueeze_28 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.675:15 in forward, code: to_33 = torch.ops.aten.to.dtype(slice_23, torch.float32);  slice_23 = None\n",
              "                    _to_copy_6: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_23, dtype = torch.float32);  slice_23 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.498:9 in forward, code: matmul_4 = torch.ops.aten.matmul.default(to_34, to_35);  to_34 = to_35 = None\n",
              "                    matmul_4: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_5, _to_copy_6);  expand_5 = _to_copy_6 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.498:10 in forward, code: transpose_12 = torch.ops.aten.transpose.int(matmul_4, 1, 2);  matmul_4 = None\n",
              "                    transpose_12: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_4, 1, 2);  matmul_4 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.498:11 in forward, code: cat_12 = torch.ops.aten.cat.default([transpose_12, transpose_12], -1);  transpose_12 = None\n",
              "                    cat_12: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_12, transpose_12], -1);  transpose_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.498:12 in forward, code: cos_4 = torch.ops.aten.cos.default(cat_12)\n",
              "                    cos_4: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_12)\n",
              "            \n",
              "                     # File: <eval_with_key>.498:13 in forward, code: mul_40 = torch.ops.aten.mul.Tensor(cos_4, 1.0);  cos_4 = None\n",
              "                    mul_709: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_4, 1.0);  cos_4 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.498:14 in forward, code: sin_4 = torch.ops.aten.sin.default(cat_12);  cat_12 = None\n",
              "                    sin_4: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_12);  cat_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.498:15 in forward, code: mul_41 = torch.ops.aten.mul.Tensor(sin_4, 1.0);  sin_4 = None\n",
              "                    mul_716: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_4, 1.0);  sin_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_13: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_8, 3, 1);  view_8 = None\n",
              "                    unbind_4 = torch.ops.aten.unbind.int(transpose_13, 2);  transpose_13 = None\n",
              "                    getitem_20: \"f32[1, 12, s53, 64]\" = unbind_4[0]\n",
              "                    getitem_21: \"f32[1, 12, s53, 64]\" = unbind_4[1]\n",
              "                    getitem_22: \"f32[1, 12, s53, 64]\" = unbind_4[2];  unbind_4 = None\n",
              "                    unsqueeze_29: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_709, 1);  mul_709 = None\n",
              "                    unsqueeze_30: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_716, 1);  mul_716 = None\n",
              "                    mul_740: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_20, unsqueeze_29)\n",
              "                    slice_24: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_20, 3, 0, 32)\n",
              "                    slice_25: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_20, 3, 32, 9223372036854775807);  getitem_20 = None\n",
              "                    neg_8: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_25);  slice_25 = None\n",
              "                    cat_13: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_8, slice_24], -1);  neg_8 = slice_24 = None\n",
              "                    mul_757: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_13, unsqueeze_30);  cat_13 = None\n",
              "                    add_798: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_740, mul_757);  mul_740 = mul_757 = None\n",
              "                    mul_765: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_21, unsqueeze_29);  unsqueeze_29 = None\n",
              "                    slice_26: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_21, 3, 0, 32)\n",
              "                    slice_27: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_21, 3, 32, 9223372036854775807);  getitem_21 = None\n",
              "                    neg_9: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_27);  slice_27 = None\n",
              "                    cat_14: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_9, slice_26], -1);  neg_9 = slice_26 = None\n",
              "                    mul_782: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_14, unsqueeze_30);  cat_14 = unsqueeze_30 = None\n",
              "                    add_822: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_765, mul_782);  mul_765 = mul_782 = None\n",
              "                    scaled_dot_product_attention_4: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_798, add_822, getitem_22, masked_fill_1);  add_798 = add_822 = getitem_22 = None\n",
              "                    transpose_14: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_4, 1, 2);  scaled_dot_product_attention_4 = None\n",
              "                    view_9: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_14, [sym_size_int_118, -1, 768]);  transpose_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_17: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_9, p_model_layers_4_attn_wo_weight);  view_9 = p_model_layers_4_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_839: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_718, linear_17);  add_718 = linear_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_9: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_839, [768], p_model_layers_4_mlp_norm_weight);  p_model_layers_4_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_18: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_9, p_model_layers_4_mlp_wi_weight);  layer_norm_9 = p_model_layers_4_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_4 = torch.ops.aten.split.Tensor(linear_18, 1152, -1);  linear_18 = None\n",
              "                    getitem_23: \"f32[1, s53, 1152]\" = split_4[0]\n",
              "                    getitem_24: \"f32[1, s53, 1152]\" = split_4[1];  split_4 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_4: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_23);  getitem_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_820: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_4, getitem_24);  gelu_4 = getitem_24 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_6: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_820);  mul_820 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_19: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_6, p_model_layers_4_mlp_wo_weight);  clone_6 = p_model_layers_4_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_867: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_839, linear_19);  add_839 = linear_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_10: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_867, [768], p_model_layers_5_attn_norm_weight);  p_model_layers_5_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_20: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_10, p_model_layers_5_attn_wqkv_weight);  layer_norm_10 = p_model_layers_5_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_10: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_20, [sym_size_int_118, -1, 3, 12, 64]);  linear_20 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.676:5 in forward, code: unsqueeze_31 = torch.ops.aten.unsqueeze.default(b_model_layers_5_attn_rotary_emb_inv_freq, 0);  b_model_layers_5_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_31: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_5_attn_rotary_emb_inv_freq, 0);  b_model_layers_5_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.676:6 in forward, code: unsqueeze_32 = torch.ops.aten.unsqueeze.default(unsqueeze_31, 2);  unsqueeze_31 = None\n",
              "                    unsqueeze_32: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_31, 2);  unsqueeze_31 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.676:9 in forward, code: expand_6 = torch.ops.aten.expand.default(to_38, [1, -1, 1]);  to_38 = None\n",
              "                    expand_6: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_32, [1, -1, 1]);  unsqueeze_32 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.676:12 in forward, code: unsqueeze_33 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_33: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.676:13 in forward, code: slice_28 = torch.ops.aten.slice.Tensor(unsqueeze_33, 2, 0, 9223372036854775807);  unsqueeze_33 = None\n",
              "                    slice_28: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_33, 2, 0, 9223372036854775807);  unsqueeze_33 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.676:15 in forward, code: to_40 = torch.ops.aten.to.dtype(slice_28, torch.float32);  slice_28 = None\n",
              "                    _to_copy_7: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_28, dtype = torch.float32);  slice_28 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.508:9 in forward, code: matmul_5 = torch.ops.aten.matmul.default(to_41, to_42);  to_41 = to_42 = None\n",
              "                    matmul_5: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_6, _to_copy_7);  expand_6 = _to_copy_7 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.508:10 in forward, code: transpose_15 = torch.ops.aten.transpose.int(matmul_5, 1, 2);  matmul_5 = None\n",
              "                    transpose_15: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_5, 1, 2);  matmul_5 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.508:11 in forward, code: cat_15 = torch.ops.aten.cat.default([transpose_15, transpose_15], -1);  transpose_15 = None\n",
              "                    cat_15: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_15, transpose_15], -1);  transpose_15 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.508:12 in forward, code: cos_5 = torch.ops.aten.cos.default(cat_15)\n",
              "                    cos_5: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_15)\n",
              "            \n",
              "                     # File: <eval_with_key>.508:13 in forward, code: mul_47 = torch.ops.aten.mul.Tensor(cos_5, 1.0);  cos_5 = None\n",
              "                    mul_863: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_5, 1.0);  cos_5 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.508:14 in forward, code: sin_5 = torch.ops.aten.sin.default(cat_15);  cat_15 = None\n",
              "                    sin_5: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_15);  cat_15 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.508:15 in forward, code: mul_48 = torch.ops.aten.mul.Tensor(sin_5, 1.0);  sin_5 = None\n",
              "                    mul_870: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_5, 1.0);  sin_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_16: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_10, 3, 1);  view_10 = None\n",
              "                    unbind_5 = torch.ops.aten.unbind.int(transpose_16, 2);  transpose_16 = None\n",
              "                    getitem_25: \"f32[1, 12, s53, 64]\" = unbind_5[0]\n",
              "                    getitem_26: \"f32[1, 12, s53, 64]\" = unbind_5[1]\n",
              "                    getitem_27: \"f32[1, 12, s53, 64]\" = unbind_5[2];  unbind_5 = None\n",
              "                    unsqueeze_34: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_863, 1);  mul_863 = None\n",
              "                    unsqueeze_35: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_870, 1);  mul_870 = None\n",
              "                    mul_894: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_25, unsqueeze_34)\n",
              "                    slice_29: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_25, 3, 0, 32)\n",
              "                    slice_30: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_25, 3, 32, 9223372036854775807);  getitem_25 = None\n",
              "                    neg_10: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_30);  slice_30 = None\n",
              "                    cat_16: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_10, slice_29], -1);  neg_10 = slice_29 = None\n",
              "                    mul_911: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_16, unsqueeze_35);  cat_16 = None\n",
              "                    add_947: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_894, mul_911);  mul_894 = mul_911 = None\n",
              "                    mul_919: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_26, unsqueeze_34);  unsqueeze_34 = None\n",
              "                    slice_31: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_26, 3, 0, 32)\n",
              "                    slice_32: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_26, 3, 32, 9223372036854775807);  getitem_26 = None\n",
              "                    neg_11: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_32);  slice_32 = None\n",
              "                    cat_17: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_11, slice_31], -1);  neg_11 = slice_31 = None\n",
              "                    mul_936: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_17, unsqueeze_35);  cat_17 = unsqueeze_35 = None\n",
              "                    add_971: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_919, mul_936);  mul_919 = mul_936 = None\n",
              "                    scaled_dot_product_attention_5: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_947, add_971, getitem_27, masked_fill_1);  add_947 = add_971 = getitem_27 = None\n",
              "                    transpose_17: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_5, 1, 2);  scaled_dot_product_attention_5 = None\n",
              "                    view_11: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_17, [sym_size_int_118, -1, 768]);  transpose_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_21: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_11, p_model_layers_5_attn_wo_weight);  view_11 = p_model_layers_5_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_988: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_867, linear_21);  add_867 = linear_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_11: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_988, [768], p_model_layers_5_mlp_norm_weight);  p_model_layers_5_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_22: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_11, p_model_layers_5_mlp_wi_weight);  layer_norm_11 = p_model_layers_5_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_5 = torch.ops.aten.split.Tensor(linear_22, 1152, -1);  linear_22 = None\n",
              "                    getitem_28: \"f32[1, s53, 1152]\" = split_5[0]\n",
              "                    getitem_29: \"f32[1, s53, 1152]\" = split_5[1];  split_5 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_5: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_28);  getitem_28 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_974: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_5, getitem_29);  gelu_5 = getitem_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_7: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_974);  mul_974 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_23: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_7, p_model_layers_5_mlp_wo_weight);  clone_7 = p_model_layers_5_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1016: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_988, linear_23);  add_988 = linear_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_12: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1016, [768], p_model_layers_6_attn_norm_weight);  p_model_layers_6_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_24: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_12, p_model_layers_6_attn_wqkv_weight);  layer_norm_12 = p_model_layers_6_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_12: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_24, [sym_size_int_118, -1, 3, 12, 64]);  linear_24 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.677:5 in forward, code: unsqueeze_36 = torch.ops.aten.unsqueeze.default(b_model_layers_6_attn_rotary_emb_inv_freq, 0);  b_model_layers_6_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_36: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_6_attn_rotary_emb_inv_freq, 0);  b_model_layers_6_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.677:6 in forward, code: unsqueeze_37 = torch.ops.aten.unsqueeze.default(unsqueeze_36, 2);  unsqueeze_36 = None\n",
              "                    unsqueeze_37: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_36, 2);  unsqueeze_36 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.677:9 in forward, code: expand_7 = torch.ops.aten.expand.default(to_45, [1, -1, 1]);  to_45 = None\n",
              "                    expand_7: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_37, [1, -1, 1]);  unsqueeze_37 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.677:12 in forward, code: unsqueeze_38 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_38: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.677:13 in forward, code: slice_33 = torch.ops.aten.slice.Tensor(unsqueeze_38, 2, 0, 9223372036854775807);  unsqueeze_38 = None\n",
              "                    slice_33: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_38, 2, 0, 9223372036854775807);  unsqueeze_38 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.677:15 in forward, code: to_47 = torch.ops.aten.to.dtype(slice_33, torch.float32);  slice_33 = None\n",
              "                    _to_copy_8: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_33, dtype = torch.float32);  slice_33 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.518:9 in forward, code: matmul_6 = torch.ops.aten.matmul.default(to_48, to_49);  to_48 = to_49 = None\n",
              "                    matmul_6: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_7, _to_copy_8);  expand_7 = _to_copy_8 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.518:10 in forward, code: transpose_18 = torch.ops.aten.transpose.int(matmul_6, 1, 2);  matmul_6 = None\n",
              "                    transpose_18: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_6, 1, 2);  matmul_6 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.518:11 in forward, code: cat_18 = torch.ops.aten.cat.default([transpose_18, transpose_18], -1);  transpose_18 = None\n",
              "                    cat_18: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_18, transpose_18], -1);  transpose_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.518:12 in forward, code: cos_6 = torch.ops.aten.cos.default(cat_18)\n",
              "                    cos_6: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_18)\n",
              "            \n",
              "                     # File: <eval_with_key>.518:13 in forward, code: mul_54 = torch.ops.aten.mul.Tensor(cos_6, 1.0);  cos_6 = None\n",
              "                    mul_1017: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_6, 1.0);  cos_6 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.518:14 in forward, code: sin_6 = torch.ops.aten.sin.default(cat_18);  cat_18 = None\n",
              "                    sin_6: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_18);  cat_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.518:15 in forward, code: mul_55 = torch.ops.aten.mul.Tensor(sin_6, 1.0);  sin_6 = None\n",
              "                    mul_1024: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_6, 1.0);  sin_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_19: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_12, 3, 1);  view_12 = None\n",
              "                    unbind_6 = torch.ops.aten.unbind.int(transpose_19, 2);  transpose_19 = None\n",
              "                    getitem_30: \"f32[1, 12, s53, 64]\" = unbind_6[0]\n",
              "                    getitem_31: \"f32[1, 12, s53, 64]\" = unbind_6[1]\n",
              "                    getitem_32: \"f32[1, 12, s53, 64]\" = unbind_6[2];  unbind_6 = None\n",
              "                    unsqueeze_39: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1017, 1);  mul_1017 = None\n",
              "                    unsqueeze_40: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1024, 1);  mul_1024 = None\n",
              "                    mul_1048: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_30, unsqueeze_39)\n",
              "                    slice_34: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_30, 3, 0, 32)\n",
              "                    slice_35: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_30, 3, 32, 9223372036854775807);  getitem_30 = None\n",
              "                    neg_12: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_35);  slice_35 = None\n",
              "                    cat_19: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_12, slice_34], -1);  neg_12 = slice_34 = None\n",
              "                    mul_1065: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_19, unsqueeze_40);  cat_19 = None\n",
              "                    add_1096: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1048, mul_1065);  mul_1048 = mul_1065 = None\n",
              "                    mul_1073: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_31, unsqueeze_39);  unsqueeze_39 = None\n",
              "                    slice_36: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_31, 3, 0, 32)\n",
              "                    slice_37: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_31, 3, 32, 9223372036854775807);  getitem_31 = None\n",
              "                    neg_13: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_37);  slice_37 = None\n",
              "                    cat_20: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_13, slice_36], -1);  neg_13 = slice_36 = None\n",
              "                    mul_1090: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_20, unsqueeze_40);  cat_20 = unsqueeze_40 = None\n",
              "                    add_1120: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1073, mul_1090);  mul_1073 = mul_1090 = None\n",
              "                    scaled_dot_product_attention_6: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1096, add_1120, getitem_32, masked_fill);  add_1096 = add_1120 = getitem_32 = None\n",
              "                    transpose_20: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_6, 1, 2);  scaled_dot_product_attention_6 = None\n",
              "                    view_13: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_20, [sym_size_int_118, -1, 768]);  transpose_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_25: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_13, p_model_layers_6_attn_wo_weight);  view_13 = p_model_layers_6_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_1137: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1016, linear_25);  add_1016 = linear_25 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_13: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1137, [768], p_model_layers_6_mlp_norm_weight);  p_model_layers_6_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_26: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_13, p_model_layers_6_mlp_wi_weight);  layer_norm_13 = p_model_layers_6_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_6 = torch.ops.aten.split.Tensor(linear_26, 1152, -1);  linear_26 = None\n",
              "                    getitem_33: \"f32[1, s53, 1152]\" = split_6[0]\n",
              "                    getitem_34: \"f32[1, s53, 1152]\" = split_6[1];  split_6 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_6: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_33);  getitem_33 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_1128: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_6, getitem_34);  gelu_6 = getitem_34 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_8: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_1128);  mul_1128 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_27: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_8, p_model_layers_6_mlp_wo_weight);  clone_8 = p_model_layers_6_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1165: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1137, linear_27);  add_1137 = linear_27 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_14: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1165, [768], p_model_layers_7_attn_norm_weight);  p_model_layers_7_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_28: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_14, p_model_layers_7_attn_wqkv_weight);  layer_norm_14 = p_model_layers_7_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_14: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_28, [sym_size_int_118, -1, 3, 12, 64]);  linear_28 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.678:5 in forward, code: unsqueeze_41 = torch.ops.aten.unsqueeze.default(b_model_layers_7_attn_rotary_emb_inv_freq, 0);  b_model_layers_7_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_41: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_7_attn_rotary_emb_inv_freq, 0);  b_model_layers_7_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.678:6 in forward, code: unsqueeze_42 = torch.ops.aten.unsqueeze.default(unsqueeze_41, 2);  unsqueeze_41 = None\n",
              "                    unsqueeze_42: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_41, 2);  unsqueeze_41 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.678:9 in forward, code: expand_8 = torch.ops.aten.expand.default(to_52, [1, -1, 1]);  to_52 = None\n",
              "                    expand_8: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_42, [1, -1, 1]);  unsqueeze_42 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.678:12 in forward, code: unsqueeze_43 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_43: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.678:13 in forward, code: slice_38 = torch.ops.aten.slice.Tensor(unsqueeze_43, 2, 0, 9223372036854775807);  unsqueeze_43 = None\n",
              "                    slice_38: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_43, 2, 0, 9223372036854775807);  unsqueeze_43 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.678:15 in forward, code: to_54 = torch.ops.aten.to.dtype(slice_38, torch.float32);  slice_38 = None\n",
              "                    _to_copy_9: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_38, dtype = torch.float32);  slice_38 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.528:9 in forward, code: matmul_7 = torch.ops.aten.matmul.default(to_55, to_56);  to_55 = to_56 = None\n",
              "                    matmul_7: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_8, _to_copy_9);  expand_8 = _to_copy_9 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.528:10 in forward, code: transpose_21 = torch.ops.aten.transpose.int(matmul_7, 1, 2);  matmul_7 = None\n",
              "                    transpose_21: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_7, 1, 2);  matmul_7 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.528:11 in forward, code: cat_21 = torch.ops.aten.cat.default([transpose_21, transpose_21], -1);  transpose_21 = None\n",
              "                    cat_21: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_21, transpose_21], -1);  transpose_21 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.528:12 in forward, code: cos_7 = torch.ops.aten.cos.default(cat_21)\n",
              "                    cos_7: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_21)\n",
              "            \n",
              "                     # File: <eval_with_key>.528:13 in forward, code: mul_61 = torch.ops.aten.mul.Tensor(cos_7, 1.0);  cos_7 = None\n",
              "                    mul_1171: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_7, 1.0);  cos_7 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.528:14 in forward, code: sin_7 = torch.ops.aten.sin.default(cat_21);  cat_21 = None\n",
              "                    sin_7: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_21);  cat_21 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.528:15 in forward, code: mul_62 = torch.ops.aten.mul.Tensor(sin_7, 1.0);  sin_7 = None\n",
              "                    mul_1178: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_7, 1.0);  sin_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_22: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_14, 3, 1);  view_14 = None\n",
              "                    unbind_7 = torch.ops.aten.unbind.int(transpose_22, 2);  transpose_22 = None\n",
              "                    getitem_35: \"f32[1, 12, s53, 64]\" = unbind_7[0]\n",
              "                    getitem_36: \"f32[1, 12, s53, 64]\" = unbind_7[1]\n",
              "                    getitem_37: \"f32[1, 12, s53, 64]\" = unbind_7[2];  unbind_7 = None\n",
              "                    unsqueeze_44: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1171, 1);  mul_1171 = None\n",
              "                    unsqueeze_45: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1178, 1);  mul_1178 = None\n",
              "                    mul_1202: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_35, unsqueeze_44)\n",
              "                    slice_39: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_35, 3, 0, 32)\n",
              "                    slice_40: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_35, 3, 32, 9223372036854775807);  getitem_35 = None\n",
              "                    neg_14: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_40);  slice_40 = None\n",
              "                    cat_22: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_14, slice_39], -1);  neg_14 = slice_39 = None\n",
              "                    mul_1219: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_22, unsqueeze_45);  cat_22 = None\n",
              "                    add_1245: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1202, mul_1219);  mul_1202 = mul_1219 = None\n",
              "                    mul_1227: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_36, unsqueeze_44);  unsqueeze_44 = None\n",
              "                    slice_41: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_36, 3, 0, 32)\n",
              "                    slice_42: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_36, 3, 32, 9223372036854775807);  getitem_36 = None\n",
              "                    neg_15: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_42);  slice_42 = None\n",
              "                    cat_23: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_15, slice_41], -1);  neg_15 = slice_41 = None\n",
              "                    mul_1244: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_23, unsqueeze_45);  cat_23 = unsqueeze_45 = None\n",
              "                    add_1269: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1227, mul_1244);  mul_1227 = mul_1244 = None\n",
              "                    scaled_dot_product_attention_7: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1245, add_1269, getitem_37, masked_fill_1);  add_1245 = add_1269 = getitem_37 = None\n",
              "                    transpose_23: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_7, 1, 2);  scaled_dot_product_attention_7 = None\n",
              "                    view_15: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_23, [sym_size_int_118, -1, 768]);  transpose_23 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_29: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_15, p_model_layers_7_attn_wo_weight);  view_15 = p_model_layers_7_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_1286: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1165, linear_29);  add_1165 = linear_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_15: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1286, [768], p_model_layers_7_mlp_norm_weight);  p_model_layers_7_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_30: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_15, p_model_layers_7_mlp_wi_weight);  layer_norm_15 = p_model_layers_7_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_7 = torch.ops.aten.split.Tensor(linear_30, 1152, -1);  linear_30 = None\n",
              "                    getitem_38: \"f32[1, s53, 1152]\" = split_7[0]\n",
              "                    getitem_39: \"f32[1, s53, 1152]\" = split_7[1];  split_7 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_7: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_38);  getitem_38 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_1282: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_7, getitem_39);  gelu_7 = getitem_39 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_9: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_1282);  mul_1282 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_31: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_9, p_model_layers_7_mlp_wo_weight);  clone_9 = p_model_layers_7_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1314: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1286, linear_31);  add_1286 = linear_31 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_16: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1314, [768], p_model_layers_8_attn_norm_weight);  p_model_layers_8_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_32: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_16, p_model_layers_8_attn_wqkv_weight);  layer_norm_16 = p_model_layers_8_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_16: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_32, [sym_size_int_118, -1, 3, 12, 64]);  linear_32 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.679:5 in forward, code: unsqueeze_46 = torch.ops.aten.unsqueeze.default(b_model_layers_8_attn_rotary_emb_inv_freq, 0);  b_model_layers_8_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_46: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_8_attn_rotary_emb_inv_freq, 0);  b_model_layers_8_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.679:6 in forward, code: unsqueeze_47 = torch.ops.aten.unsqueeze.default(unsqueeze_46, 2);  unsqueeze_46 = None\n",
              "                    unsqueeze_47: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_46, 2);  unsqueeze_46 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.679:9 in forward, code: expand_9 = torch.ops.aten.expand.default(to_59, [1, -1, 1]);  to_59 = None\n",
              "                    expand_9: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_47, [1, -1, 1]);  unsqueeze_47 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.679:12 in forward, code: unsqueeze_48 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_48: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.679:13 in forward, code: slice_43 = torch.ops.aten.slice.Tensor(unsqueeze_48, 2, 0, 9223372036854775807);  unsqueeze_48 = None\n",
              "                    slice_43: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_48, 2, 0, 9223372036854775807);  unsqueeze_48 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.679:15 in forward, code: to_61 = torch.ops.aten.to.dtype(slice_43, torch.float32);  slice_43 = None\n",
              "                    _to_copy_10: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_43, dtype = torch.float32);  slice_43 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.538:9 in forward, code: matmul_8 = torch.ops.aten.matmul.default(to_62, to_63);  to_62 = to_63 = None\n",
              "                    matmul_8: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_9, _to_copy_10);  expand_9 = _to_copy_10 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.538:10 in forward, code: transpose_24 = torch.ops.aten.transpose.int(matmul_8, 1, 2);  matmul_8 = None\n",
              "                    transpose_24: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_8, 1, 2);  matmul_8 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.538:11 in forward, code: cat_24 = torch.ops.aten.cat.default([transpose_24, transpose_24], -1);  transpose_24 = None\n",
              "                    cat_24: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_24, transpose_24], -1);  transpose_24 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.538:12 in forward, code: cos_8 = torch.ops.aten.cos.default(cat_24)\n",
              "                    cos_8: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_24)\n",
              "            \n",
              "                     # File: <eval_with_key>.538:13 in forward, code: mul_68 = torch.ops.aten.mul.Tensor(cos_8, 1.0);  cos_8 = None\n",
              "                    mul_1325: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_8, 1.0);  cos_8 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.538:14 in forward, code: sin_8 = torch.ops.aten.sin.default(cat_24);  cat_24 = None\n",
              "                    sin_8: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_24);  cat_24 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.538:15 in forward, code: mul_69 = torch.ops.aten.mul.Tensor(sin_8, 1.0);  sin_8 = None\n",
              "                    mul_1332: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_8, 1.0);  sin_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_25: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_16, 3, 1);  view_16 = None\n",
              "                    unbind_8 = torch.ops.aten.unbind.int(transpose_25, 2);  transpose_25 = None\n",
              "                    getitem_40: \"f32[1, 12, s53, 64]\" = unbind_8[0]\n",
              "                    getitem_41: \"f32[1, 12, s53, 64]\" = unbind_8[1]\n",
              "                    getitem_42: \"f32[1, 12, s53, 64]\" = unbind_8[2];  unbind_8 = None\n",
              "                    unsqueeze_49: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1325, 1);  mul_1325 = None\n",
              "                    unsqueeze_50: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1332, 1);  mul_1332 = None\n",
              "                    mul_1356: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_40, unsqueeze_49)\n",
              "                    slice_44: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_40, 3, 0, 32)\n",
              "                    slice_45: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_40, 3, 32, 9223372036854775807);  getitem_40 = None\n",
              "                    neg_16: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_45);  slice_45 = None\n",
              "                    cat_25: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_16, slice_44], -1);  neg_16 = slice_44 = None\n",
              "                    mul_1373: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_25, unsqueeze_50);  cat_25 = None\n",
              "                    add_1394: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1356, mul_1373);  mul_1356 = mul_1373 = None\n",
              "                    mul_1381: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_41, unsqueeze_49);  unsqueeze_49 = None\n",
              "                    slice_46: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_41, 3, 0, 32)\n",
              "                    slice_47: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_41, 3, 32, 9223372036854775807);  getitem_41 = None\n",
              "                    neg_17: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_47);  slice_47 = None\n",
              "                    cat_26: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_17, slice_46], -1);  neg_17 = slice_46 = None\n",
              "                    mul_1398: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_26, unsqueeze_50);  cat_26 = unsqueeze_50 = None\n",
              "                    add_1418: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1381, mul_1398);  mul_1381 = mul_1398 = None\n",
              "                    scaled_dot_product_attention_8: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1394, add_1418, getitem_42, masked_fill_1);  add_1394 = add_1418 = getitem_42 = None\n",
              "                    transpose_26: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_8, 1, 2);  scaled_dot_product_attention_8 = None\n",
              "                    view_17: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_26, [sym_size_int_118, -1, 768]);  transpose_26 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_33: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_17, p_model_layers_8_attn_wo_weight);  view_17 = p_model_layers_8_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_1435: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1314, linear_33);  add_1314 = linear_33 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_17: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1435, [768], p_model_layers_8_mlp_norm_weight);  p_model_layers_8_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_34: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_17, p_model_layers_8_mlp_wi_weight);  layer_norm_17 = p_model_layers_8_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_8 = torch.ops.aten.split.Tensor(linear_34, 1152, -1);  linear_34 = None\n",
              "                    getitem_43: \"f32[1, s53, 1152]\" = split_8[0]\n",
              "                    getitem_44: \"f32[1, s53, 1152]\" = split_8[1];  split_8 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_8: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_43);  getitem_43 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_1436: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_8, getitem_44);  gelu_8 = getitem_44 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_10: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_1436);  mul_1436 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_35: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_10, p_model_layers_8_mlp_wo_weight);  clone_10 = p_model_layers_8_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1463: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1435, linear_35);  add_1435 = linear_35 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_18: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1463, [768], p_model_layers_9_attn_norm_weight);  p_model_layers_9_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_36: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_18, p_model_layers_9_attn_wqkv_weight);  layer_norm_18 = p_model_layers_9_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_18: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_36, [sym_size_int_118, -1, 3, 12, 64]);  linear_36 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.680:5 in forward, code: unsqueeze_51 = torch.ops.aten.unsqueeze.default(b_model_layers_9_attn_rotary_emb_inv_freq, 0);  b_model_layers_9_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_51: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_9_attn_rotary_emb_inv_freq, 0);  b_model_layers_9_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.680:6 in forward, code: unsqueeze_52 = torch.ops.aten.unsqueeze.default(unsqueeze_51, 2);  unsqueeze_51 = None\n",
              "                    unsqueeze_52: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_51, 2);  unsqueeze_51 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.680:9 in forward, code: expand_10 = torch.ops.aten.expand.default(to_66, [1, -1, 1]);  to_66 = None\n",
              "                    expand_10: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_52, [1, -1, 1]);  unsqueeze_52 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.680:12 in forward, code: unsqueeze_53 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_53: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.680:13 in forward, code: slice_48 = torch.ops.aten.slice.Tensor(unsqueeze_53, 2, 0, 9223372036854775807);  unsqueeze_53 = None\n",
              "                    slice_48: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_53, 2, 0, 9223372036854775807);  unsqueeze_53 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.680:15 in forward, code: to_68 = torch.ops.aten.to.dtype(slice_48, torch.float32);  slice_48 = None\n",
              "                    _to_copy_11: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_48, dtype = torch.float32);  slice_48 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.548:9 in forward, code: matmul_9 = torch.ops.aten.matmul.default(to_69, to_70);  to_69 = to_70 = None\n",
              "                    matmul_9: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_10, _to_copy_11);  expand_10 = _to_copy_11 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.548:10 in forward, code: transpose_27 = torch.ops.aten.transpose.int(matmul_9, 1, 2);  matmul_9 = None\n",
              "                    transpose_27: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_9, 1, 2);  matmul_9 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.548:11 in forward, code: cat_27 = torch.ops.aten.cat.default([transpose_27, transpose_27], -1);  transpose_27 = None\n",
              "                    cat_27: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_27, transpose_27], -1);  transpose_27 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.548:12 in forward, code: cos_9 = torch.ops.aten.cos.default(cat_27)\n",
              "                    cos_9: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_27)\n",
              "            \n",
              "                     # File: <eval_with_key>.548:13 in forward, code: mul_75 = torch.ops.aten.mul.Tensor(cos_9, 1.0);  cos_9 = None\n",
              "                    mul_1479: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_9, 1.0);  cos_9 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.548:14 in forward, code: sin_9 = torch.ops.aten.sin.default(cat_27);  cat_27 = None\n",
              "                    sin_9: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_27);  cat_27 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.548:15 in forward, code: mul_76 = torch.ops.aten.mul.Tensor(sin_9, 1.0);  sin_9 = None\n",
              "                    mul_1486: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_9, 1.0);  sin_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_28: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_18, 3, 1);  view_18 = None\n",
              "                    unbind_9 = torch.ops.aten.unbind.int(transpose_28, 2);  transpose_28 = None\n",
              "                    getitem_45: \"f32[1, 12, s53, 64]\" = unbind_9[0]\n",
              "                    getitem_46: \"f32[1, 12, s53, 64]\" = unbind_9[1]\n",
              "                    getitem_47: \"f32[1, 12, s53, 64]\" = unbind_9[2];  unbind_9 = None\n",
              "                    unsqueeze_54: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1479, 1);  mul_1479 = None\n",
              "                    unsqueeze_55: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1486, 1);  mul_1486 = None\n",
              "                    mul_1510: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_45, unsqueeze_54)\n",
              "                    slice_49: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_45, 3, 0, 32)\n",
              "                    slice_50: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_45, 3, 32, 9223372036854775807);  getitem_45 = None\n",
              "                    neg_18: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_50);  slice_50 = None\n",
              "                    cat_28: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_18, slice_49], -1);  neg_18 = slice_49 = None\n",
              "                    mul_1527: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_28, unsqueeze_55);  cat_28 = None\n",
              "                    add_1543: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1510, mul_1527);  mul_1510 = mul_1527 = None\n",
              "                    mul_1535: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_46, unsqueeze_54);  unsqueeze_54 = None\n",
              "                    slice_51: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_46, 3, 0, 32)\n",
              "                    slice_52: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_46, 3, 32, 9223372036854775807);  getitem_46 = None\n",
              "                    neg_19: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_52);  slice_52 = None\n",
              "                    cat_29: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_19, slice_51], -1);  neg_19 = slice_51 = None\n",
              "                    mul_1552: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_29, unsqueeze_55);  cat_29 = unsqueeze_55 = None\n",
              "                    add_1567: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1535, mul_1552);  mul_1535 = mul_1552 = None\n",
              "                    scaled_dot_product_attention_9: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1543, add_1567, getitem_47, masked_fill);  add_1543 = add_1567 = getitem_47 = None\n",
              "                    transpose_29: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_9, 1, 2);  scaled_dot_product_attention_9 = None\n",
              "                    view_19: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_29, [sym_size_int_118, -1, 768]);  transpose_29 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_37: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_19, p_model_layers_9_attn_wo_weight);  view_19 = p_model_layers_9_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_1584: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1463, linear_37);  add_1463 = linear_37 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_19: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1584, [768], p_model_layers_9_mlp_norm_weight);  p_model_layers_9_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_38: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_19, p_model_layers_9_mlp_wi_weight);  layer_norm_19 = p_model_layers_9_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_9 = torch.ops.aten.split.Tensor(linear_38, 1152, -1);  linear_38 = None\n",
              "                    getitem_48: \"f32[1, s53, 1152]\" = split_9[0]\n",
              "                    getitem_49: \"f32[1, s53, 1152]\" = split_9[1];  split_9 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_9: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_48);  getitem_48 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_1590: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_9, getitem_49);  gelu_9 = getitem_49 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_11: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_1590);  mul_1590 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_39: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_11, p_model_layers_9_mlp_wo_weight);  clone_11 = p_model_layers_9_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1612: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1584, linear_39);  add_1584 = linear_39 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_20: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1612, [768], p_model_layers_10_attn_norm_weight);  p_model_layers_10_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_40: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_20, p_model_layers_10_attn_wqkv_weight);  layer_norm_20 = p_model_layers_10_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_20: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_40, [sym_size_int_118, -1, 3, 12, 64]);  linear_40 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.681:5 in forward, code: unsqueeze_56 = torch.ops.aten.unsqueeze.default(b_model_layers_10_attn_rotary_emb_inv_freq, 0);  b_model_layers_10_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_56: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_10_attn_rotary_emb_inv_freq, 0);  b_model_layers_10_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.681:6 in forward, code: unsqueeze_57 = torch.ops.aten.unsqueeze.default(unsqueeze_56, 2);  unsqueeze_56 = None\n",
              "                    unsqueeze_57: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_56, 2);  unsqueeze_56 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.681:9 in forward, code: expand_11 = torch.ops.aten.expand.default(to_73, [1, -1, 1]);  to_73 = None\n",
              "                    expand_11: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_57, [1, -1, 1]);  unsqueeze_57 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.681:12 in forward, code: unsqueeze_58 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_58: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.681:13 in forward, code: slice_53 = torch.ops.aten.slice.Tensor(unsqueeze_58, 2, 0, 9223372036854775807);  unsqueeze_58 = None\n",
              "                    slice_53: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_58, 2, 0, 9223372036854775807);  unsqueeze_58 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.681:15 in forward, code: to_75 = torch.ops.aten.to.dtype(slice_53, torch.float32);  slice_53 = None\n",
              "                    _to_copy_12: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_53, dtype = torch.float32);  slice_53 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.558:9 in forward, code: matmul_10 = torch.ops.aten.matmul.default(to_76, to_77);  to_76 = to_77 = None\n",
              "                    matmul_10: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_11, _to_copy_12);  expand_11 = _to_copy_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.558:10 in forward, code: transpose_30 = torch.ops.aten.transpose.int(matmul_10, 1, 2);  matmul_10 = None\n",
              "                    transpose_30: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_10, 1, 2);  matmul_10 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.558:11 in forward, code: cat_30 = torch.ops.aten.cat.default([transpose_30, transpose_30], -1);  transpose_30 = None\n",
              "                    cat_30: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_30, transpose_30], -1);  transpose_30 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.558:12 in forward, code: cos_10 = torch.ops.aten.cos.default(cat_30)\n",
              "                    cos_10: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_30)\n",
              "            \n",
              "                     # File: <eval_with_key>.558:13 in forward, code: mul_82 = torch.ops.aten.mul.Tensor(cos_10, 1.0);  cos_10 = None\n",
              "                    mul_1633: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_10, 1.0);  cos_10 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.558:14 in forward, code: sin_10 = torch.ops.aten.sin.default(cat_30);  cat_30 = None\n",
              "                    sin_10: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_30);  cat_30 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.558:15 in forward, code: mul_83 = torch.ops.aten.mul.Tensor(sin_10, 1.0);  sin_10 = None\n",
              "                    mul_1640: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_10, 1.0);  sin_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_31: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_20, 3, 1);  view_20 = None\n",
              "                    unbind_10 = torch.ops.aten.unbind.int(transpose_31, 2);  transpose_31 = None\n",
              "                    getitem_50: \"f32[1, 12, s53, 64]\" = unbind_10[0]\n",
              "                    getitem_51: \"f32[1, 12, s53, 64]\" = unbind_10[1]\n",
              "                    getitem_52: \"f32[1, 12, s53, 64]\" = unbind_10[2];  unbind_10 = None\n",
              "                    unsqueeze_59: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1633, 1);  mul_1633 = None\n",
              "                    unsqueeze_60: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1640, 1);  mul_1640 = None\n",
              "                    mul_1664: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_50, unsqueeze_59)\n",
              "                    slice_54: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_50, 3, 0, 32)\n",
              "                    slice_55: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_50, 3, 32, 9223372036854775807);  getitem_50 = None\n",
              "                    neg_20: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_55);  slice_55 = None\n",
              "                    cat_31: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_20, slice_54], -1);  neg_20 = slice_54 = None\n",
              "                    mul_1681: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_31, unsqueeze_60);  cat_31 = None\n",
              "                    add_1692: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1664, mul_1681);  mul_1664 = mul_1681 = None\n",
              "                    mul_1689: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_51, unsqueeze_59);  unsqueeze_59 = None\n",
              "                    slice_56: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_51, 3, 0, 32)\n",
              "                    slice_57: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_51, 3, 32, 9223372036854775807);  getitem_51 = None\n",
              "                    neg_21: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_57);  slice_57 = None\n",
              "                    cat_32: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_21, slice_56], -1);  neg_21 = slice_56 = None\n",
              "                    mul_1706: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_32, unsqueeze_60);  cat_32 = unsqueeze_60 = None\n",
              "                    add_1716: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1689, mul_1706);  mul_1689 = mul_1706 = None\n",
              "                    scaled_dot_product_attention_10: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1692, add_1716, getitem_52, masked_fill_1);  add_1692 = add_1716 = getitem_52 = None\n",
              "                    transpose_32: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_10, 1, 2);  scaled_dot_product_attention_10 = None\n",
              "                    view_21: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_32, [sym_size_int_118, -1, 768]);  transpose_32 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_41: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_21, p_model_layers_10_attn_wo_weight);  view_21 = p_model_layers_10_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_1733: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1612, linear_41);  add_1612 = linear_41 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_21: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1733, [768], p_model_layers_10_mlp_norm_weight);  p_model_layers_10_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_42: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_21, p_model_layers_10_mlp_wi_weight);  layer_norm_21 = p_model_layers_10_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_10 = torch.ops.aten.split.Tensor(linear_42, 1152, -1);  linear_42 = None\n",
              "                    getitem_53: \"f32[1, s53, 1152]\" = split_10[0]\n",
              "                    getitem_54: \"f32[1, s53, 1152]\" = split_10[1];  split_10 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_10: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_53);  getitem_53 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_1744: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_10, getitem_54);  gelu_10 = getitem_54 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_12: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_1744);  mul_1744 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_43: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_12, p_model_layers_10_mlp_wo_weight);  clone_12 = p_model_layers_10_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1761: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1733, linear_43);  add_1733 = linear_43 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_22: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1761, [768], p_model_layers_11_attn_norm_weight);  p_model_layers_11_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_44: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_22, p_model_layers_11_attn_wqkv_weight);  layer_norm_22 = p_model_layers_11_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_22: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_44, [sym_size_int_118, -1, 3, 12, 64]);  linear_44 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.682:5 in forward, code: unsqueeze_61 = torch.ops.aten.unsqueeze.default(b_model_layers_11_attn_rotary_emb_inv_freq, 0);  b_model_layers_11_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_61: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_11_attn_rotary_emb_inv_freq, 0);  b_model_layers_11_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.682:6 in forward, code: unsqueeze_62 = torch.ops.aten.unsqueeze.default(unsqueeze_61, 2);  unsqueeze_61 = None\n",
              "                    unsqueeze_62: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_61, 2);  unsqueeze_61 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.682:9 in forward, code: expand_12 = torch.ops.aten.expand.default(to_80, [1, -1, 1]);  to_80 = None\n",
              "                    expand_12: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_62, [1, -1, 1]);  unsqueeze_62 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.682:12 in forward, code: unsqueeze_63 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_63: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.682:13 in forward, code: slice_58 = torch.ops.aten.slice.Tensor(unsqueeze_63, 2, 0, 9223372036854775807);  unsqueeze_63 = None\n",
              "                    slice_58: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_63, 2, 0, 9223372036854775807);  unsqueeze_63 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.682:15 in forward, code: to_82 = torch.ops.aten.to.dtype(slice_58, torch.float32);  slice_58 = None\n",
              "                    _to_copy_13: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_58, dtype = torch.float32);  slice_58 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.568:9 in forward, code: matmul_11 = torch.ops.aten.matmul.default(to_83, to_84);  to_83 = to_84 = None\n",
              "                    matmul_11: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_12, _to_copy_13);  expand_12 = _to_copy_13 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.568:10 in forward, code: transpose_33 = torch.ops.aten.transpose.int(matmul_11, 1, 2);  matmul_11 = None\n",
              "                    transpose_33: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_11, 1, 2);  matmul_11 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.568:11 in forward, code: cat_33 = torch.ops.aten.cat.default([transpose_33, transpose_33], -1);  transpose_33 = None\n",
              "                    cat_33: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_33, transpose_33], -1);  transpose_33 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.568:12 in forward, code: cos_11 = torch.ops.aten.cos.default(cat_33)\n",
              "                    cos_11: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_33)\n",
              "            \n",
              "                     # File: <eval_with_key>.568:13 in forward, code: mul_89 = torch.ops.aten.mul.Tensor(cos_11, 1.0);  cos_11 = None\n",
              "                    mul_1787: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_11, 1.0);  cos_11 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.568:14 in forward, code: sin_11 = torch.ops.aten.sin.default(cat_33);  cat_33 = None\n",
              "                    sin_11: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_33);  cat_33 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.568:15 in forward, code: mul_90 = torch.ops.aten.mul.Tensor(sin_11, 1.0);  sin_11 = None\n",
              "                    mul_1794: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_11, 1.0);  sin_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_34: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_22, 3, 1);  view_22 = None\n",
              "                    unbind_11 = torch.ops.aten.unbind.int(transpose_34, 2);  transpose_34 = None\n",
              "                    getitem_55: \"f32[1, 12, s53, 64]\" = unbind_11[0]\n",
              "                    getitem_56: \"f32[1, 12, s53, 64]\" = unbind_11[1]\n",
              "                    getitem_57: \"f32[1, 12, s53, 64]\" = unbind_11[2];  unbind_11 = None\n",
              "                    unsqueeze_64: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1787, 1);  mul_1787 = None\n",
              "                    unsqueeze_65: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1794, 1);  mul_1794 = None\n",
              "                    mul_1818: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_55, unsqueeze_64)\n",
              "                    slice_59: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_55, 3, 0, 32)\n",
              "                    slice_60: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_55, 3, 32, 9223372036854775807);  getitem_55 = None\n",
              "                    neg_22: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_60);  slice_60 = None\n",
              "                    cat_34: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_22, slice_59], -1);  neg_22 = slice_59 = None\n",
              "                    mul_1835: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_34, unsqueeze_65);  cat_34 = None\n",
              "                    add_1841: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1818, mul_1835);  mul_1818 = mul_1835 = None\n",
              "                    mul_1843: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_56, unsqueeze_64);  unsqueeze_64 = None\n",
              "                    slice_61: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_56, 3, 0, 32)\n",
              "                    slice_62: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_56, 3, 32, 9223372036854775807);  getitem_56 = None\n",
              "                    neg_23: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_62);  slice_62 = None\n",
              "                    cat_35: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_23, slice_61], -1);  neg_23 = slice_61 = None\n",
              "                    mul_1860: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_35, unsqueeze_65);  cat_35 = unsqueeze_65 = None\n",
              "                    add_1865: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1843, mul_1860);  mul_1843 = mul_1860 = None\n",
              "                    scaled_dot_product_attention_11: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1841, add_1865, getitem_57, masked_fill_1);  add_1841 = add_1865 = getitem_57 = None\n",
              "                    transpose_35: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_11, 1, 2);  scaled_dot_product_attention_11 = None\n",
              "                    view_23: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_35, [sym_size_int_118, -1, 768]);  transpose_35 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_45: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_23, p_model_layers_11_attn_wo_weight);  view_23 = p_model_layers_11_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_1882: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1761, linear_45);  add_1761 = linear_45 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_23: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1882, [768], p_model_layers_11_mlp_norm_weight);  p_model_layers_11_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_46: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_23, p_model_layers_11_mlp_wi_weight);  layer_norm_23 = p_model_layers_11_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_11 = torch.ops.aten.split.Tensor(linear_46, 1152, -1);  linear_46 = None\n",
              "                    getitem_58: \"f32[1, s53, 1152]\" = split_11[0]\n",
              "                    getitem_59: \"f32[1, s53, 1152]\" = split_11[1];  split_11 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_11: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_58);  getitem_58 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_1898: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_11, getitem_59);  gelu_11 = getitem_59 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_13: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_1898);  mul_1898 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_47: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_13, p_model_layers_11_mlp_wo_weight);  clone_13 = p_model_layers_11_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_1910: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1882, linear_47);  add_1882 = linear_47 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_24: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_1910, [768], p_model_layers_12_attn_norm_weight);  p_model_layers_12_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_48: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_24, p_model_layers_12_attn_wqkv_weight);  layer_norm_24 = p_model_layers_12_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_24: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_48, [sym_size_int_118, -1, 3, 12, 64]);  linear_48 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.683:5 in forward, code: unsqueeze_66 = torch.ops.aten.unsqueeze.default(b_model_layers_12_attn_rotary_emb_inv_freq, 0);  b_model_layers_12_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_66: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_12_attn_rotary_emb_inv_freq, 0);  b_model_layers_12_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.683:6 in forward, code: unsqueeze_67 = torch.ops.aten.unsqueeze.default(unsqueeze_66, 2);  unsqueeze_66 = None\n",
              "                    unsqueeze_67: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_66, 2);  unsqueeze_66 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.683:9 in forward, code: expand_13 = torch.ops.aten.expand.default(to_87, [1, -1, 1]);  to_87 = None\n",
              "                    expand_13: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_67, [1, -1, 1]);  unsqueeze_67 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.683:12 in forward, code: unsqueeze_68 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_68: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.683:13 in forward, code: slice_63 = torch.ops.aten.slice.Tensor(unsqueeze_68, 2, 0, 9223372036854775807);  unsqueeze_68 = None\n",
              "                    slice_63: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_68, 2, 0, 9223372036854775807);  unsqueeze_68 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.683:15 in forward, code: to_89 = torch.ops.aten.to.dtype(slice_63, torch.float32);  slice_63 = None\n",
              "                    _to_copy_14: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_63, dtype = torch.float32);  slice_63 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.578:9 in forward, code: matmul_12 = torch.ops.aten.matmul.default(to_90, to_91);  to_90 = to_91 = None\n",
              "                    matmul_12: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_13, _to_copy_14);  expand_13 = _to_copy_14 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.578:10 in forward, code: transpose_36 = torch.ops.aten.transpose.int(matmul_12, 1, 2);  matmul_12 = None\n",
              "                    transpose_36: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_12, 1, 2);  matmul_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.578:11 in forward, code: cat_36 = torch.ops.aten.cat.default([transpose_36, transpose_36], -1);  transpose_36 = None\n",
              "                    cat_36: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_36, transpose_36], -1);  transpose_36 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.578:12 in forward, code: cos_12 = torch.ops.aten.cos.default(cat_36)\n",
              "                    cos_12: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_36)\n",
              "            \n",
              "                     # File: <eval_with_key>.578:13 in forward, code: mul_96 = torch.ops.aten.mul.Tensor(cos_12, 1.0);  cos_12 = None\n",
              "                    mul_1941: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_12, 1.0);  cos_12 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.578:14 in forward, code: sin_12 = torch.ops.aten.sin.default(cat_36);  cat_36 = None\n",
              "                    sin_12: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_36);  cat_36 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.578:15 in forward, code: mul_97 = torch.ops.aten.mul.Tensor(sin_12, 1.0);  sin_12 = None\n",
              "                    mul_1948: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_12, 1.0);  sin_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_37: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_24, 3, 1);  view_24 = None\n",
              "                    unbind_12 = torch.ops.aten.unbind.int(transpose_37, 2);  transpose_37 = None\n",
              "                    getitem_60: \"f32[1, 12, s53, 64]\" = unbind_12[0]\n",
              "                    getitem_61: \"f32[1, 12, s53, 64]\" = unbind_12[1]\n",
              "                    getitem_62: \"f32[1, 12, s53, 64]\" = unbind_12[2];  unbind_12 = None\n",
              "                    unsqueeze_69: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1941, 1);  mul_1941 = None\n",
              "                    unsqueeze_70: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_1948, 1);  mul_1948 = None\n",
              "                    mul_1972: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_60, unsqueeze_69)\n",
              "                    slice_64: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_60, 3, 0, 32)\n",
              "                    slice_65: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_60, 3, 32, 9223372036854775807);  getitem_60 = None\n",
              "                    neg_24: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_65);  slice_65 = None\n",
              "                    cat_37: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_24, slice_64], -1);  neg_24 = slice_64 = None\n",
              "                    mul_1989: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_37, unsqueeze_70);  cat_37 = None\n",
              "                    add_1990: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1972, mul_1989);  mul_1972 = mul_1989 = None\n",
              "                    mul_1997: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_61, unsqueeze_69);  unsqueeze_69 = None\n",
              "                    slice_66: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_61, 3, 0, 32)\n",
              "                    slice_67: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_61, 3, 32, 9223372036854775807);  getitem_61 = None\n",
              "                    neg_25: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_67);  slice_67 = None\n",
              "                    cat_38: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_25, slice_66], -1);  neg_25 = slice_66 = None\n",
              "                    mul_2014: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_38, unsqueeze_70);  cat_38 = unsqueeze_70 = None\n",
              "                    add_2014: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_1997, mul_2014);  mul_1997 = mul_2014 = None\n",
              "                    scaled_dot_product_attention_12: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_1990, add_2014, getitem_62, masked_fill);  add_1990 = add_2014 = getitem_62 = None\n",
              "                    transpose_38: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_12, 1, 2);  scaled_dot_product_attention_12 = None\n",
              "                    view_25: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_38, [sym_size_int_118, -1, 768]);  transpose_38 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_49: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_25, p_model_layers_12_attn_wo_weight);  view_25 = p_model_layers_12_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2031: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_1910, linear_49);  add_1910 = linear_49 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_25: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2031, [768], p_model_layers_12_mlp_norm_weight);  p_model_layers_12_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_50: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_25, p_model_layers_12_mlp_wi_weight);  layer_norm_25 = p_model_layers_12_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_12 = torch.ops.aten.split.Tensor(linear_50, 1152, -1);  linear_50 = None\n",
              "                    getitem_63: \"f32[1, s53, 1152]\" = split_12[0]\n",
              "                    getitem_64: \"f32[1, s53, 1152]\" = split_12[1];  split_12 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_12: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_63);  getitem_63 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2052: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_12, getitem_64);  gelu_12 = getitem_64 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_14: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2052);  mul_2052 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_51: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_14, p_model_layers_12_mlp_wo_weight);  clone_14 = p_model_layers_12_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2059: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2031, linear_51);  add_2031 = linear_51 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_26: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2059, [768], p_model_layers_13_attn_norm_weight);  p_model_layers_13_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_52: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_26, p_model_layers_13_attn_wqkv_weight);  layer_norm_26 = p_model_layers_13_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_26: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_52, [sym_size_int_118, -1, 3, 12, 64]);  linear_52 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.684:5 in forward, code: unsqueeze_71 = torch.ops.aten.unsqueeze.default(b_model_layers_13_attn_rotary_emb_inv_freq, 0);  b_model_layers_13_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_71: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_13_attn_rotary_emb_inv_freq, 0);  b_model_layers_13_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.684:6 in forward, code: unsqueeze_72 = torch.ops.aten.unsqueeze.default(unsqueeze_71, 2);  unsqueeze_71 = None\n",
              "                    unsqueeze_72: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_71, 2);  unsqueeze_71 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.684:9 in forward, code: expand_14 = torch.ops.aten.expand.default(to_94, [1, -1, 1]);  to_94 = None\n",
              "                    expand_14: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_72, [1, -1, 1]);  unsqueeze_72 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.684:12 in forward, code: unsqueeze_73 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_73: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.684:13 in forward, code: slice_68 = torch.ops.aten.slice.Tensor(unsqueeze_73, 2, 0, 9223372036854775807);  unsqueeze_73 = None\n",
              "                    slice_68: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_73, 2, 0, 9223372036854775807);  unsqueeze_73 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.684:15 in forward, code: to_96 = torch.ops.aten.to.dtype(slice_68, torch.float32);  slice_68 = None\n",
              "                    _to_copy_15: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_68, dtype = torch.float32);  slice_68 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.588:9 in forward, code: matmul_13 = torch.ops.aten.matmul.default(to_97, to_98);  to_97 = to_98 = None\n",
              "                    matmul_13: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_14, _to_copy_15);  expand_14 = _to_copy_15 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.588:10 in forward, code: transpose_39 = torch.ops.aten.transpose.int(matmul_13, 1, 2);  matmul_13 = None\n",
              "                    transpose_39: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_13, 1, 2);  matmul_13 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.588:11 in forward, code: cat_39 = torch.ops.aten.cat.default([transpose_39, transpose_39], -1);  transpose_39 = None\n",
              "                    cat_39: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_39, transpose_39], -1);  transpose_39 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.588:12 in forward, code: cos_13 = torch.ops.aten.cos.default(cat_39)\n",
              "                    cos_13: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_39)\n",
              "            \n",
              "                     # File: <eval_with_key>.588:13 in forward, code: mul_103 = torch.ops.aten.mul.Tensor(cos_13, 1.0);  cos_13 = None\n",
              "                    mul_2095: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_13, 1.0);  cos_13 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.588:14 in forward, code: sin_13 = torch.ops.aten.sin.default(cat_39);  cat_39 = None\n",
              "                    sin_13: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_39);  cat_39 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.588:15 in forward, code: mul_104 = torch.ops.aten.mul.Tensor(sin_13, 1.0);  sin_13 = None\n",
              "                    mul_2102: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_13, 1.0);  sin_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_40: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_26, 3, 1);  view_26 = None\n",
              "                    unbind_13 = torch.ops.aten.unbind.int(transpose_40, 2);  transpose_40 = None\n",
              "                    getitem_65: \"f32[1, 12, s53, 64]\" = unbind_13[0]\n",
              "                    getitem_66: \"f32[1, 12, s53, 64]\" = unbind_13[1]\n",
              "                    getitem_67: \"f32[1, 12, s53, 64]\" = unbind_13[2];  unbind_13 = None\n",
              "                    unsqueeze_74: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2095, 1);  mul_2095 = None\n",
              "                    unsqueeze_75: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2102, 1);  mul_2102 = None\n",
              "                    mul_2126: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_65, unsqueeze_74)\n",
              "                    slice_69: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_65, 3, 0, 32)\n",
              "                    slice_70: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_65, 3, 32, 9223372036854775807);  getitem_65 = None\n",
              "                    neg_26: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_70);  slice_70 = None\n",
              "                    cat_40: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_26, slice_69], -1);  neg_26 = slice_69 = None\n",
              "                    mul_2143: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_40, unsqueeze_75);  cat_40 = None\n",
              "                    add_2139: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2126, mul_2143);  mul_2126 = mul_2143 = None\n",
              "                    mul_2151: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_66, unsqueeze_74);  unsqueeze_74 = None\n",
              "                    slice_71: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_66, 3, 0, 32)\n",
              "                    slice_72: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_66, 3, 32, 9223372036854775807);  getitem_66 = None\n",
              "                    neg_27: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_72);  slice_72 = None\n",
              "                    cat_41: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_27, slice_71], -1);  neg_27 = slice_71 = None\n",
              "                    mul_2168: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_41, unsqueeze_75);  cat_41 = unsqueeze_75 = None\n",
              "                    add_2163: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2151, mul_2168);  mul_2151 = mul_2168 = None\n",
              "                    scaled_dot_product_attention_13: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_2139, add_2163, getitem_67, masked_fill_1);  add_2139 = add_2163 = getitem_67 = None\n",
              "                    transpose_41: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_13, 1, 2);  scaled_dot_product_attention_13 = None\n",
              "                    view_27: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_41, [sym_size_int_118, -1, 768]);  transpose_41 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_53: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_27, p_model_layers_13_attn_wo_weight);  view_27 = p_model_layers_13_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2180: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2059, linear_53);  add_2059 = linear_53 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_27: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2180, [768], p_model_layers_13_mlp_norm_weight);  p_model_layers_13_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_54: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_27, p_model_layers_13_mlp_wi_weight);  layer_norm_27 = p_model_layers_13_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_13 = torch.ops.aten.split.Tensor(linear_54, 1152, -1);  linear_54 = None\n",
              "                    getitem_68: \"f32[1, s53, 1152]\" = split_13[0]\n",
              "                    getitem_69: \"f32[1, s53, 1152]\" = split_13[1];  split_13 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_13: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_68);  getitem_68 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2206: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_13, getitem_69);  gelu_13 = getitem_69 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_15: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2206);  mul_2206 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_55: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_15, p_model_layers_13_mlp_wo_weight);  clone_15 = p_model_layers_13_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2208: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2180, linear_55);  add_2180 = linear_55 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_28: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2208, [768], p_model_layers_14_attn_norm_weight);  p_model_layers_14_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_56: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_28, p_model_layers_14_attn_wqkv_weight);  layer_norm_28 = p_model_layers_14_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_28: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_56, [sym_size_int_118, -1, 3, 12, 64]);  linear_56 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.685:5 in forward, code: unsqueeze_76 = torch.ops.aten.unsqueeze.default(b_model_layers_14_attn_rotary_emb_inv_freq, 0);  b_model_layers_14_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_76: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_14_attn_rotary_emb_inv_freq, 0);  b_model_layers_14_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.685:6 in forward, code: unsqueeze_77 = torch.ops.aten.unsqueeze.default(unsqueeze_76, 2);  unsqueeze_76 = None\n",
              "                    unsqueeze_77: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_76, 2);  unsqueeze_76 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.685:9 in forward, code: expand_15 = torch.ops.aten.expand.default(to_101, [1, -1, 1]);  to_101 = None\n",
              "                    expand_15: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_77, [1, -1, 1]);  unsqueeze_77 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.685:12 in forward, code: unsqueeze_78 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_78: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.685:13 in forward, code: slice_73 = torch.ops.aten.slice.Tensor(unsqueeze_78, 2, 0, 9223372036854775807);  unsqueeze_78 = None\n",
              "                    slice_73: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_78, 2, 0, 9223372036854775807);  unsqueeze_78 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.685:15 in forward, code: to_103 = torch.ops.aten.to.dtype(slice_73, torch.float32);  slice_73 = None\n",
              "                    _to_copy_16: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_73, dtype = torch.float32);  slice_73 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.598:9 in forward, code: matmul_14 = torch.ops.aten.matmul.default(to_104, to_105);  to_104 = to_105 = None\n",
              "                    matmul_14: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_15, _to_copy_16);  expand_15 = _to_copy_16 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.598:10 in forward, code: transpose_42 = torch.ops.aten.transpose.int(matmul_14, 1, 2);  matmul_14 = None\n",
              "                    transpose_42: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_14, 1, 2);  matmul_14 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.598:11 in forward, code: cat_42 = torch.ops.aten.cat.default([transpose_42, transpose_42], -1);  transpose_42 = None\n",
              "                    cat_42: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_42, transpose_42], -1);  transpose_42 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.598:12 in forward, code: cos_14 = torch.ops.aten.cos.default(cat_42)\n",
              "                    cos_14: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_42)\n",
              "            \n",
              "                     # File: <eval_with_key>.598:13 in forward, code: mul_110 = torch.ops.aten.mul.Tensor(cos_14, 1.0);  cos_14 = None\n",
              "                    mul_2249: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_14, 1.0);  cos_14 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.598:14 in forward, code: sin_14 = torch.ops.aten.sin.default(cat_42);  cat_42 = None\n",
              "                    sin_14: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_42);  cat_42 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.598:15 in forward, code: mul_111 = torch.ops.aten.mul.Tensor(sin_14, 1.0);  sin_14 = None\n",
              "                    mul_2256: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_14, 1.0);  sin_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_43: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_28, 3, 1);  view_28 = None\n",
              "                    unbind_14 = torch.ops.aten.unbind.int(transpose_43, 2);  transpose_43 = None\n",
              "                    getitem_70: \"f32[1, 12, s53, 64]\" = unbind_14[0]\n",
              "                    getitem_71: \"f32[1, 12, s53, 64]\" = unbind_14[1]\n",
              "                    getitem_72: \"f32[1, 12, s53, 64]\" = unbind_14[2];  unbind_14 = None\n",
              "                    unsqueeze_79: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2249, 1);  mul_2249 = None\n",
              "                    unsqueeze_80: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2256, 1);  mul_2256 = None\n",
              "                    mul_2280: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_70, unsqueeze_79)\n",
              "                    slice_74: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_70, 3, 0, 32)\n",
              "                    slice_75: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_70, 3, 32, 9223372036854775807);  getitem_70 = None\n",
              "                    neg_28: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_75);  slice_75 = None\n",
              "                    cat_43: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_28, slice_74], -1);  neg_28 = slice_74 = None\n",
              "                    mul_2297: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_43, unsqueeze_80);  cat_43 = None\n",
              "                    add_2288: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2280, mul_2297);  mul_2280 = mul_2297 = None\n",
              "                    mul_2305: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_71, unsqueeze_79);  unsqueeze_79 = None\n",
              "                    slice_76: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_71, 3, 0, 32)\n",
              "                    slice_77: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_71, 3, 32, 9223372036854775807);  getitem_71 = None\n",
              "                    neg_29: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_77);  slice_77 = None\n",
              "                    cat_44: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_29, slice_76], -1);  neg_29 = slice_76 = None\n",
              "                    mul_2322: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_44, unsqueeze_80);  cat_44 = unsqueeze_80 = None\n",
              "                    add_2312: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2305, mul_2322);  mul_2305 = mul_2322 = None\n",
              "                    scaled_dot_product_attention_14: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_2288, add_2312, getitem_72, masked_fill_1);  add_2288 = add_2312 = getitem_72 = None\n",
              "                    transpose_44: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_14, 1, 2);  scaled_dot_product_attention_14 = None\n",
              "                    view_29: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_44, [sym_size_int_118, -1, 768]);  transpose_44 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_57: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_29, p_model_layers_14_attn_wo_weight);  view_29 = p_model_layers_14_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2329: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2208, linear_57);  add_2208 = linear_57 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_29: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2329, [768], p_model_layers_14_mlp_norm_weight);  p_model_layers_14_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_58: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_29, p_model_layers_14_mlp_wi_weight);  layer_norm_29 = p_model_layers_14_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_14 = torch.ops.aten.split.Tensor(linear_58, 1152, -1);  linear_58 = None\n",
              "                    getitem_73: \"f32[1, s53, 1152]\" = split_14[0]\n",
              "                    getitem_74: \"f32[1, s53, 1152]\" = split_14[1];  split_14 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_14: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_73);  getitem_73 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2360: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_14, getitem_74);  gelu_14 = getitem_74 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_16: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2360);  mul_2360 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_59: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_16, p_model_layers_14_mlp_wo_weight);  clone_16 = p_model_layers_14_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2357: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2329, linear_59);  add_2329 = linear_59 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_30: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2357, [768], p_model_layers_15_attn_norm_weight);  p_model_layers_15_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_60: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_30, p_model_layers_15_attn_wqkv_weight);  layer_norm_30 = p_model_layers_15_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_30: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_60, [sym_size_int_118, -1, 3, 12, 64]);  linear_60 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.686:5 in forward, code: unsqueeze_81 = torch.ops.aten.unsqueeze.default(b_model_layers_15_attn_rotary_emb_inv_freq, 0);  b_model_layers_15_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_81: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_15_attn_rotary_emb_inv_freq, 0);  b_model_layers_15_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.686:6 in forward, code: unsqueeze_82 = torch.ops.aten.unsqueeze.default(unsqueeze_81, 2);  unsqueeze_81 = None\n",
              "                    unsqueeze_82: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_81, 2);  unsqueeze_81 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.686:9 in forward, code: expand_16 = torch.ops.aten.expand.default(to_108, [1, -1, 1]);  to_108 = None\n",
              "                    expand_16: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_82, [1, -1, 1]);  unsqueeze_82 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.686:12 in forward, code: unsqueeze_83 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_83: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.686:13 in forward, code: slice_78 = torch.ops.aten.slice.Tensor(unsqueeze_83, 2, 0, 9223372036854775807);  unsqueeze_83 = None\n",
              "                    slice_78: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_83, 2, 0, 9223372036854775807);  unsqueeze_83 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.686:15 in forward, code: to_110 = torch.ops.aten.to.dtype(slice_78, torch.float32);  slice_78 = None\n",
              "                    _to_copy_17: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_78, dtype = torch.float32);  slice_78 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.608:9 in forward, code: matmul_15 = torch.ops.aten.matmul.default(to_111, to_112);  to_111 = to_112 = None\n",
              "                    matmul_15: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_16, _to_copy_17);  expand_16 = _to_copy_17 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.608:10 in forward, code: transpose_45 = torch.ops.aten.transpose.int(matmul_15, 1, 2);  matmul_15 = None\n",
              "                    transpose_45: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_15, 1, 2);  matmul_15 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.608:11 in forward, code: cat_45 = torch.ops.aten.cat.default([transpose_45, transpose_45], -1);  transpose_45 = None\n",
              "                    cat_45: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_45, transpose_45], -1);  transpose_45 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.608:12 in forward, code: cos_15 = torch.ops.aten.cos.default(cat_45)\n",
              "                    cos_15: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_45)\n",
              "            \n",
              "                     # File: <eval_with_key>.608:13 in forward, code: mul_117 = torch.ops.aten.mul.Tensor(cos_15, 1.0);  cos_15 = None\n",
              "                    mul_2403: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_15, 1.0);  cos_15 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.608:14 in forward, code: sin_15 = torch.ops.aten.sin.default(cat_45);  cat_45 = None\n",
              "                    sin_15: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_45);  cat_45 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.608:15 in forward, code: mul_118 = torch.ops.aten.mul.Tensor(sin_15, 1.0);  sin_15 = None\n",
              "                    mul_2410: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_15, 1.0);  sin_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_46: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_30, 3, 1);  view_30 = None\n",
              "                    unbind_15 = torch.ops.aten.unbind.int(transpose_46, 2);  transpose_46 = None\n",
              "                    getitem_75: \"f32[1, 12, s53, 64]\" = unbind_15[0]\n",
              "                    getitem_76: \"f32[1, 12, s53, 64]\" = unbind_15[1]\n",
              "                    getitem_77: \"f32[1, 12, s53, 64]\" = unbind_15[2];  unbind_15 = None\n",
              "                    unsqueeze_84: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2403, 1);  mul_2403 = None\n",
              "                    unsqueeze_85: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2410, 1);  mul_2410 = None\n",
              "                    mul_2434: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_75, unsqueeze_84)\n",
              "                    slice_79: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_75, 3, 0, 32)\n",
              "                    slice_80: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_75, 3, 32, 9223372036854775807);  getitem_75 = None\n",
              "                    neg_30: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_80);  slice_80 = None\n",
              "                    cat_46: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_30, slice_79], -1);  neg_30 = slice_79 = None\n",
              "                    mul_2451: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_46, unsqueeze_85);  cat_46 = None\n",
              "                    add_2437: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2434, mul_2451);  mul_2434 = mul_2451 = None\n",
              "                    mul_2459: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_76, unsqueeze_84);  unsqueeze_84 = None\n",
              "                    slice_81: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_76, 3, 0, 32)\n",
              "                    slice_82: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_76, 3, 32, 9223372036854775807);  getitem_76 = None\n",
              "                    neg_31: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_82);  slice_82 = None\n",
              "                    cat_47: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_31, slice_81], -1);  neg_31 = slice_81 = None\n",
              "                    mul_2476: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_47, unsqueeze_85);  cat_47 = unsqueeze_85 = None\n",
              "                    add_2461: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2459, mul_2476);  mul_2459 = mul_2476 = None\n",
              "                    scaled_dot_product_attention_15: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_2437, add_2461, getitem_77, masked_fill);  add_2437 = add_2461 = getitem_77 = None\n",
              "                    transpose_47: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_15, 1, 2);  scaled_dot_product_attention_15 = None\n",
              "                    view_31: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_47, [sym_size_int_118, -1, 768]);  transpose_47 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_61: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_31, p_model_layers_15_attn_wo_weight);  view_31 = p_model_layers_15_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2478: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2357, linear_61);  add_2357 = linear_61 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_31: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2478, [768], p_model_layers_15_mlp_norm_weight);  p_model_layers_15_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_62: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_31, p_model_layers_15_mlp_wi_weight);  layer_norm_31 = p_model_layers_15_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_15 = torch.ops.aten.split.Tensor(linear_62, 1152, -1);  linear_62 = None\n",
              "                    getitem_78: \"f32[1, s53, 1152]\" = split_15[0]\n",
              "                    getitem_79: \"f32[1, s53, 1152]\" = split_15[1];  split_15 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_15: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_78);  getitem_78 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2514: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_15, getitem_79);  gelu_15 = getitem_79 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_17: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2514);  mul_2514 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_63: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_17, p_model_layers_15_mlp_wo_weight);  clone_17 = p_model_layers_15_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2506: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2478, linear_63);  add_2478 = linear_63 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_32: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2506, [768], p_model_layers_16_attn_norm_weight);  p_model_layers_16_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_64: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_32, p_model_layers_16_attn_wqkv_weight);  layer_norm_32 = p_model_layers_16_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_32: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_64, [sym_size_int_118, -1, 3, 12, 64]);  linear_64 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.687:5 in forward, code: unsqueeze_86 = torch.ops.aten.unsqueeze.default(b_model_layers_16_attn_rotary_emb_inv_freq, 0);  b_model_layers_16_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_86: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_16_attn_rotary_emb_inv_freq, 0);  b_model_layers_16_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.687:6 in forward, code: unsqueeze_87 = torch.ops.aten.unsqueeze.default(unsqueeze_86, 2);  unsqueeze_86 = None\n",
              "                    unsqueeze_87: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_86, 2);  unsqueeze_86 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.687:9 in forward, code: expand_17 = torch.ops.aten.expand.default(to_115, [1, -1, 1]);  to_115 = None\n",
              "                    expand_17: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_87, [1, -1, 1]);  unsqueeze_87 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.687:12 in forward, code: unsqueeze_88 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_88: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.687:13 in forward, code: slice_83 = torch.ops.aten.slice.Tensor(unsqueeze_88, 2, 0, 9223372036854775807);  unsqueeze_88 = None\n",
              "                    slice_83: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_88, 2, 0, 9223372036854775807);  unsqueeze_88 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.687:15 in forward, code: to_117 = torch.ops.aten.to.dtype(slice_83, torch.float32);  slice_83 = None\n",
              "                    _to_copy_18: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_83, dtype = torch.float32);  slice_83 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.618:9 in forward, code: matmul_16 = torch.ops.aten.matmul.default(to_118, to_119);  to_118 = to_119 = None\n",
              "                    matmul_16: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_17, _to_copy_18);  expand_17 = _to_copy_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.618:10 in forward, code: transpose_48 = torch.ops.aten.transpose.int(matmul_16, 1, 2);  matmul_16 = None\n",
              "                    transpose_48: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_16, 1, 2);  matmul_16 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.618:11 in forward, code: cat_48 = torch.ops.aten.cat.default([transpose_48, transpose_48], -1);  transpose_48 = None\n",
              "                    cat_48: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_48, transpose_48], -1);  transpose_48 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.618:12 in forward, code: cos_16 = torch.ops.aten.cos.default(cat_48)\n",
              "                    cos_16: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_48)\n",
              "            \n",
              "                     # File: <eval_with_key>.618:13 in forward, code: mul_124 = torch.ops.aten.mul.Tensor(cos_16, 1.0);  cos_16 = None\n",
              "                    mul_2557: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_16, 1.0);  cos_16 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.618:14 in forward, code: sin_16 = torch.ops.aten.sin.default(cat_48);  cat_48 = None\n",
              "                    sin_16: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_48);  cat_48 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.618:15 in forward, code: mul_125 = torch.ops.aten.mul.Tensor(sin_16, 1.0);  sin_16 = None\n",
              "                    mul_2564: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_16, 1.0);  sin_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_49: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_32, 3, 1);  view_32 = None\n",
              "                    unbind_16 = torch.ops.aten.unbind.int(transpose_49, 2);  transpose_49 = None\n",
              "                    getitem_80: \"f32[1, 12, s53, 64]\" = unbind_16[0]\n",
              "                    getitem_81: \"f32[1, 12, s53, 64]\" = unbind_16[1]\n",
              "                    getitem_82: \"f32[1, 12, s53, 64]\" = unbind_16[2];  unbind_16 = None\n",
              "                    unsqueeze_89: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2557, 1);  mul_2557 = None\n",
              "                    unsqueeze_90: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2564, 1);  mul_2564 = None\n",
              "                    mul_2588: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_80, unsqueeze_89)\n",
              "                    slice_84: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_80, 3, 0, 32)\n",
              "                    slice_85: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_80, 3, 32, 9223372036854775807);  getitem_80 = None\n",
              "                    neg_32: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_85);  slice_85 = None\n",
              "                    cat_49: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_32, slice_84], -1);  neg_32 = slice_84 = None\n",
              "                    mul_2605: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_49, unsqueeze_90);  cat_49 = None\n",
              "                    add_2586: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2588, mul_2605);  mul_2588 = mul_2605 = None\n",
              "                    mul_2613: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_81, unsqueeze_89);  unsqueeze_89 = None\n",
              "                    slice_86: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_81, 3, 0, 32)\n",
              "                    slice_87: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_81, 3, 32, 9223372036854775807);  getitem_81 = None\n",
              "                    neg_33: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_87);  slice_87 = None\n",
              "                    cat_50: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_33, slice_86], -1);  neg_33 = slice_86 = None\n",
              "                    mul_2630: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_50, unsqueeze_90);  cat_50 = unsqueeze_90 = None\n",
              "                    add_2610: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2613, mul_2630);  mul_2613 = mul_2630 = None\n",
              "                    scaled_dot_product_attention_16: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_2586, add_2610, getitem_82, masked_fill_1);  add_2586 = add_2610 = getitem_82 = None\n",
              "                    transpose_50: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_16, 1, 2);  scaled_dot_product_attention_16 = None\n",
              "                    view_33: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_50, [sym_size_int_118, -1, 768]);  transpose_50 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_65: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_33, p_model_layers_16_attn_wo_weight);  view_33 = p_model_layers_16_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2627: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2506, linear_65);  add_2506 = linear_65 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_33: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2627, [768], p_model_layers_16_mlp_norm_weight);  p_model_layers_16_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_66: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_33, p_model_layers_16_mlp_wi_weight);  layer_norm_33 = p_model_layers_16_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_16 = torch.ops.aten.split.Tensor(linear_66, 1152, -1);  linear_66 = None\n",
              "                    getitem_83: \"f32[1, s53, 1152]\" = split_16[0]\n",
              "                    getitem_84: \"f32[1, s53, 1152]\" = split_16[1];  split_16 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_16: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_83);  getitem_83 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2668: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_16, getitem_84);  gelu_16 = getitem_84 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_18: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2668);  mul_2668 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_67: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_18, p_model_layers_16_mlp_wo_weight);  clone_18 = p_model_layers_16_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2655: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2627, linear_67);  add_2627 = linear_67 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_34: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2655, [768], p_model_layers_17_attn_norm_weight);  p_model_layers_17_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_68: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_34, p_model_layers_17_attn_wqkv_weight);  layer_norm_34 = p_model_layers_17_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_34: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_68, [sym_size_int_118, -1, 3, 12, 64]);  linear_68 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.688:5 in forward, code: unsqueeze_91 = torch.ops.aten.unsqueeze.default(b_model_layers_17_attn_rotary_emb_inv_freq, 0);  b_model_layers_17_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_91: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_17_attn_rotary_emb_inv_freq, 0);  b_model_layers_17_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.688:6 in forward, code: unsqueeze_92 = torch.ops.aten.unsqueeze.default(unsqueeze_91, 2);  unsqueeze_91 = None\n",
              "                    unsqueeze_92: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_91, 2);  unsqueeze_91 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.688:9 in forward, code: expand_18 = torch.ops.aten.expand.default(to_122, [1, -1, 1]);  to_122 = None\n",
              "                    expand_18: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_92, [1, -1, 1]);  unsqueeze_92 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.688:12 in forward, code: unsqueeze_93 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_93: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.688:13 in forward, code: slice_88 = torch.ops.aten.slice.Tensor(unsqueeze_93, 2, 0, 9223372036854775807);  unsqueeze_93 = None\n",
              "                    slice_88: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_93, 2, 0, 9223372036854775807);  unsqueeze_93 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.688:15 in forward, code: to_124 = torch.ops.aten.to.dtype(slice_88, torch.float32);  slice_88 = None\n",
              "                    _to_copy_19: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_88, dtype = torch.float32);  slice_88 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.628:9 in forward, code: matmul_17 = torch.ops.aten.matmul.default(to_125, to_126);  to_125 = to_126 = None\n",
              "                    matmul_17: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_18, _to_copy_19);  expand_18 = _to_copy_19 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.628:10 in forward, code: transpose_51 = torch.ops.aten.transpose.int(matmul_17, 1, 2);  matmul_17 = None\n",
              "                    transpose_51: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_17, 1, 2);  matmul_17 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.628:11 in forward, code: cat_51 = torch.ops.aten.cat.default([transpose_51, transpose_51], -1);  transpose_51 = None\n",
              "                    cat_51: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_51, transpose_51], -1);  transpose_51 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.628:12 in forward, code: cos_17 = torch.ops.aten.cos.default(cat_51)\n",
              "                    cos_17: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_51)\n",
              "            \n",
              "                     # File: <eval_with_key>.628:13 in forward, code: mul_131 = torch.ops.aten.mul.Tensor(cos_17, 1.0);  cos_17 = None\n",
              "                    mul_2711: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_17, 1.0);  cos_17 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.628:14 in forward, code: sin_17 = torch.ops.aten.sin.default(cat_51);  cat_51 = None\n",
              "                    sin_17: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_51);  cat_51 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.628:15 in forward, code: mul_132 = torch.ops.aten.mul.Tensor(sin_17, 1.0);  sin_17 = None\n",
              "                    mul_2718: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_17, 1.0);  sin_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_52: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_34, 3, 1);  view_34 = None\n",
              "                    unbind_17 = torch.ops.aten.unbind.int(transpose_52, 2);  transpose_52 = None\n",
              "                    getitem_85: \"f32[1, 12, s53, 64]\" = unbind_17[0]\n",
              "                    getitem_86: \"f32[1, 12, s53, 64]\" = unbind_17[1]\n",
              "                    getitem_87: \"f32[1, 12, s53, 64]\" = unbind_17[2];  unbind_17 = None\n",
              "                    unsqueeze_94: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2711, 1);  mul_2711 = None\n",
              "                    unsqueeze_95: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2718, 1);  mul_2718 = None\n",
              "                    mul_2742: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_85, unsqueeze_94)\n",
              "                    slice_89: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_85, 3, 0, 32)\n",
              "                    slice_90: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_85, 3, 32, 9223372036854775807);  getitem_85 = None\n",
              "                    neg_34: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_90);  slice_90 = None\n",
              "                    cat_52: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_34, slice_89], -1);  neg_34 = slice_89 = None\n",
              "                    mul_2759: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_52, unsqueeze_95);  cat_52 = None\n",
              "                    add_2735: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2742, mul_2759);  mul_2742 = mul_2759 = None\n",
              "                    mul_2767: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_86, unsqueeze_94);  unsqueeze_94 = None\n",
              "                    slice_91: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_86, 3, 0, 32)\n",
              "                    slice_92: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_86, 3, 32, 9223372036854775807);  getitem_86 = None\n",
              "                    neg_35: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_92);  slice_92 = None\n",
              "                    cat_53: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_35, slice_91], -1);  neg_35 = slice_91 = None\n",
              "                    mul_2784: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_53, unsqueeze_95);  cat_53 = unsqueeze_95 = None\n",
              "                    add_2759: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2767, mul_2784);  mul_2767 = mul_2784 = None\n",
              "                    scaled_dot_product_attention_17: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_2735, add_2759, getitem_87, masked_fill_1);  add_2735 = add_2759 = getitem_87 = None\n",
              "                    transpose_53: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_17, 1, 2);  scaled_dot_product_attention_17 = None\n",
              "                    view_35: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_53, [sym_size_int_118, -1, 768]);  transpose_53 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_69: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_35, p_model_layers_17_attn_wo_weight);  view_35 = p_model_layers_17_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2776: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2655, linear_69);  add_2655 = linear_69 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_35: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2776, [768], p_model_layers_17_mlp_norm_weight);  p_model_layers_17_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_70: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_35, p_model_layers_17_mlp_wi_weight);  layer_norm_35 = p_model_layers_17_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_17 = torch.ops.aten.split.Tensor(linear_70, 1152, -1);  linear_70 = None\n",
              "                    getitem_88: \"f32[1, s53, 1152]\" = split_17[0]\n",
              "                    getitem_89: \"f32[1, s53, 1152]\" = split_17[1];  split_17 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_17: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_88);  getitem_88 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2822: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_17, getitem_89);  gelu_17 = getitem_89 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_19: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2822);  mul_2822 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_71: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_19, p_model_layers_17_mlp_wo_weight);  clone_19 = p_model_layers_17_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2804: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2776, linear_71);  add_2776 = linear_71 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_36: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2804, [768], p_model_layers_18_attn_norm_weight);  p_model_layers_18_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_72: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_36, p_model_layers_18_attn_wqkv_weight);  layer_norm_36 = p_model_layers_18_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_36: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_72, [sym_size_int_118, -1, 3, 12, 64]);  linear_72 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.689:5 in forward, code: unsqueeze_96 = torch.ops.aten.unsqueeze.default(b_model_layers_18_attn_rotary_emb_inv_freq, 0);  b_model_layers_18_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_96: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_18_attn_rotary_emb_inv_freq, 0);  b_model_layers_18_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.689:6 in forward, code: unsqueeze_97 = torch.ops.aten.unsqueeze.default(unsqueeze_96, 2);  unsqueeze_96 = None\n",
              "                    unsqueeze_97: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_96, 2);  unsqueeze_96 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.689:9 in forward, code: expand_19 = torch.ops.aten.expand.default(to_129, [1, -1, 1]);  to_129 = None\n",
              "                    expand_19: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_97, [1, -1, 1]);  unsqueeze_97 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.689:12 in forward, code: unsqueeze_98 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_98: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.689:13 in forward, code: slice_93 = torch.ops.aten.slice.Tensor(unsqueeze_98, 2, 0, 9223372036854775807);  unsqueeze_98 = None\n",
              "                    slice_93: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_98, 2, 0, 9223372036854775807);  unsqueeze_98 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.689:15 in forward, code: to_131 = torch.ops.aten.to.dtype(slice_93, torch.float32);  slice_93 = None\n",
              "                    _to_copy_20: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_93, dtype = torch.float32);  slice_93 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.638:9 in forward, code: matmul_18 = torch.ops.aten.matmul.default(to_132, to_133);  to_132 = to_133 = None\n",
              "                    matmul_18: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_19, _to_copy_20);  expand_19 = _to_copy_20 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.638:10 in forward, code: transpose_54 = torch.ops.aten.transpose.int(matmul_18, 1, 2);  matmul_18 = None\n",
              "                    transpose_54: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_18, 1, 2);  matmul_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.638:11 in forward, code: cat_54 = torch.ops.aten.cat.default([transpose_54, transpose_54], -1);  transpose_54 = None\n",
              "                    cat_54: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_54, transpose_54], -1);  transpose_54 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.638:12 in forward, code: cos_18 = torch.ops.aten.cos.default(cat_54)\n",
              "                    cos_18: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_54)\n",
              "            \n",
              "                     # File: <eval_with_key>.638:13 in forward, code: mul_138 = torch.ops.aten.mul.Tensor(cos_18, 1.0);  cos_18 = None\n",
              "                    mul_2865: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_18, 1.0);  cos_18 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.638:14 in forward, code: sin_18 = torch.ops.aten.sin.default(cat_54);  cat_54 = None\n",
              "                    sin_18: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_54);  cat_54 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.638:15 in forward, code: mul_139 = torch.ops.aten.mul.Tensor(sin_18, 1.0);  sin_18 = None\n",
              "                    mul_2872: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_18, 1.0);  sin_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_55: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_36, 3, 1);  view_36 = None\n",
              "                    unbind_18 = torch.ops.aten.unbind.int(transpose_55, 2);  transpose_55 = None\n",
              "                    getitem_90: \"f32[1, 12, s53, 64]\" = unbind_18[0]\n",
              "                    getitem_91: \"f32[1, 12, s53, 64]\" = unbind_18[1]\n",
              "                    getitem_92: \"f32[1, 12, s53, 64]\" = unbind_18[2];  unbind_18 = None\n",
              "                    unsqueeze_99: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2865, 1);  mul_2865 = None\n",
              "                    unsqueeze_100: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_2872, 1);  mul_2872 = None\n",
              "                    mul_2896: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_90, unsqueeze_99)\n",
              "                    slice_94: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_90, 3, 0, 32)\n",
              "                    slice_95: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_90, 3, 32, 9223372036854775807);  getitem_90 = None\n",
              "                    neg_36: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_95);  slice_95 = None\n",
              "                    cat_55: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_36, slice_94], -1);  neg_36 = slice_94 = None\n",
              "                    mul_2913: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_55, unsqueeze_100);  cat_55 = None\n",
              "                    add_2884: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2896, mul_2913);  mul_2896 = mul_2913 = None\n",
              "                    mul_2921: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_91, unsqueeze_99);  unsqueeze_99 = None\n",
              "                    slice_96: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_91, 3, 0, 32)\n",
              "                    slice_97: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_91, 3, 32, 9223372036854775807);  getitem_91 = None\n",
              "                    neg_37: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_97);  slice_97 = None\n",
              "                    cat_56: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_37, slice_96], -1);  neg_37 = slice_96 = None\n",
              "                    mul_2938: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_56, unsqueeze_100);  cat_56 = unsqueeze_100 = None\n",
              "                    add_2908: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_2921, mul_2938);  mul_2921 = mul_2938 = None\n",
              "                    scaled_dot_product_attention_18: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_2884, add_2908, getitem_92, masked_fill);  add_2884 = add_2908 = getitem_92 = None\n",
              "                    transpose_56: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_18, 1, 2);  scaled_dot_product_attention_18 = None\n",
              "                    view_37: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_56, [sym_size_int_118, -1, 768]);  transpose_56 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_73: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_37, p_model_layers_18_attn_wo_weight);  view_37 = p_model_layers_18_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_2925: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2804, linear_73);  add_2804 = linear_73 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_37: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2925, [768], p_model_layers_18_mlp_norm_weight);  p_model_layers_18_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_74: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_37, p_model_layers_18_mlp_wi_weight);  layer_norm_37 = p_model_layers_18_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_18 = torch.ops.aten.split.Tensor(linear_74, 1152, -1);  linear_74 = None\n",
              "                    getitem_93: \"f32[1, s53, 1152]\" = split_18[0]\n",
              "                    getitem_94: \"f32[1, s53, 1152]\" = split_18[1];  split_18 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_18: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_93);  getitem_93 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_2976: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_18, getitem_94);  gelu_18 = getitem_94 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_20: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_2976);  mul_2976 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_75: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_20, p_model_layers_18_mlp_wo_weight);  clone_20 = p_model_layers_18_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_2953: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2925, linear_75);  add_2925 = linear_75 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_38: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_2953, [768], p_model_layers_19_attn_norm_weight);  p_model_layers_19_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_76: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_38, p_model_layers_19_attn_wqkv_weight);  layer_norm_38 = p_model_layers_19_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_38: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_76, [sym_size_int_118, -1, 3, 12, 64]);  linear_76 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.690:5 in forward, code: unsqueeze_101 = torch.ops.aten.unsqueeze.default(b_model_layers_19_attn_rotary_emb_inv_freq, 0);  b_model_layers_19_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_101: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_19_attn_rotary_emb_inv_freq, 0);  b_model_layers_19_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.690:6 in forward, code: unsqueeze_102 = torch.ops.aten.unsqueeze.default(unsqueeze_101, 2);  unsqueeze_101 = None\n",
              "                    unsqueeze_102: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_101, 2);  unsqueeze_101 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.690:9 in forward, code: expand_20 = torch.ops.aten.expand.default(to_136, [1, -1, 1]);  to_136 = None\n",
              "                    expand_20: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_102, [1, -1, 1]);  unsqueeze_102 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.690:12 in forward, code: unsqueeze_103 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_103: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.690:13 in forward, code: slice_98 = torch.ops.aten.slice.Tensor(unsqueeze_103, 2, 0, 9223372036854775807);  unsqueeze_103 = None\n",
              "                    slice_98: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_103, 2, 0, 9223372036854775807);  unsqueeze_103 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.690:15 in forward, code: to_138 = torch.ops.aten.to.dtype(slice_98, torch.float32);  slice_98 = None\n",
              "                    _to_copy_21: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_98, dtype = torch.float32);  slice_98 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.648:9 in forward, code: matmul_19 = torch.ops.aten.matmul.default(to_139, to_140);  to_139 = to_140 = None\n",
              "                    matmul_19: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_20, _to_copy_21);  expand_20 = _to_copy_21 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.648:10 in forward, code: transpose_57 = torch.ops.aten.transpose.int(matmul_19, 1, 2);  matmul_19 = None\n",
              "                    transpose_57: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_19, 1, 2);  matmul_19 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.648:11 in forward, code: cat_57 = torch.ops.aten.cat.default([transpose_57, transpose_57], -1);  transpose_57 = None\n",
              "                    cat_57: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_57, transpose_57], -1);  transpose_57 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.648:12 in forward, code: cos_19 = torch.ops.aten.cos.default(cat_57)\n",
              "                    cos_19: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_57)\n",
              "            \n",
              "                     # File: <eval_with_key>.648:13 in forward, code: mul_145 = torch.ops.aten.mul.Tensor(cos_19, 1.0);  cos_19 = None\n",
              "                    mul_3019: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_19, 1.0);  cos_19 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.648:14 in forward, code: sin_19 = torch.ops.aten.sin.default(cat_57);  cat_57 = None\n",
              "                    sin_19: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_57);  cat_57 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.648:15 in forward, code: mul_146 = torch.ops.aten.mul.Tensor(sin_19, 1.0);  sin_19 = None\n",
              "                    mul_3026: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_19, 1.0);  sin_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_58: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_38, 3, 1);  view_38 = None\n",
              "                    unbind_19 = torch.ops.aten.unbind.int(transpose_58, 2);  transpose_58 = None\n",
              "                    getitem_95: \"f32[1, 12, s53, 64]\" = unbind_19[0]\n",
              "                    getitem_96: \"f32[1, 12, s53, 64]\" = unbind_19[1]\n",
              "                    getitem_97: \"f32[1, 12, s53, 64]\" = unbind_19[2];  unbind_19 = None\n",
              "                    unsqueeze_104: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_3019, 1);  mul_3019 = None\n",
              "                    unsqueeze_105: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_3026, 1);  mul_3026 = None\n",
              "                    mul_3050: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_95, unsqueeze_104)\n",
              "                    slice_99: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_95, 3, 0, 32)\n",
              "                    slice_100: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_95, 3, 32, 9223372036854775807);  getitem_95 = None\n",
              "                    neg_38: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_100);  slice_100 = None\n",
              "                    cat_58: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_38, slice_99], -1);  neg_38 = slice_99 = None\n",
              "                    mul_3067: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_58, unsqueeze_105);  cat_58 = None\n",
              "                    add_3033: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_3050, mul_3067);  mul_3050 = mul_3067 = None\n",
              "                    mul_3075: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_96, unsqueeze_104);  unsqueeze_104 = None\n",
              "                    slice_101: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_96, 3, 0, 32)\n",
              "                    slice_102: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_96, 3, 32, 9223372036854775807);  getitem_96 = None\n",
              "                    neg_39: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_102);  slice_102 = None\n",
              "                    cat_59: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_39, slice_101], -1);  neg_39 = slice_101 = None\n",
              "                    mul_3092: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_59, unsqueeze_105);  cat_59 = unsqueeze_105 = None\n",
              "                    add_3057: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_3075, mul_3092);  mul_3075 = mul_3092 = None\n",
              "                    scaled_dot_product_attention_19: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_3033, add_3057, getitem_97, masked_fill_1);  add_3033 = add_3057 = getitem_97 = None\n",
              "                    transpose_59: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_19, 1, 2);  scaled_dot_product_attention_19 = None\n",
              "                    view_39: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_59, [sym_size_int_118, -1, 768]);  transpose_59 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_77: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_39, p_model_layers_19_attn_wo_weight);  view_39 = p_model_layers_19_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_3074: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_2953, linear_77);  add_2953 = linear_77 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_39: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_3074, [768], p_model_layers_19_mlp_norm_weight);  p_model_layers_19_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_78: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_39, p_model_layers_19_mlp_wi_weight);  layer_norm_39 = p_model_layers_19_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_19 = torch.ops.aten.split.Tensor(linear_78, 1152, -1);  linear_78 = None\n",
              "                    getitem_98: \"f32[1, s53, 1152]\" = split_19[0]\n",
              "                    getitem_99: \"f32[1, s53, 1152]\" = split_19[1];  split_19 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_19: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_98);  getitem_98 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_3130: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_19, getitem_99);  gelu_19 = getitem_99 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_21: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_3130);  mul_3130 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_79: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_21, p_model_layers_19_mlp_wo_weight);  clone_21 = p_model_layers_19_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_3102: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_3074, linear_79);  add_3074 = linear_79 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_40: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_3102, [768], p_model_layers_20_attn_norm_weight);  p_model_layers_20_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_80: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_40, p_model_layers_20_attn_wqkv_weight);  layer_norm_40 = p_model_layers_20_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_40: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_80, [sym_size_int_118, -1, 3, 12, 64]);  linear_80 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.691:5 in forward, code: unsqueeze_106 = torch.ops.aten.unsqueeze.default(b_model_layers_20_attn_rotary_emb_inv_freq, 0);  b_model_layers_20_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_106: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_20_attn_rotary_emb_inv_freq, 0);  b_model_layers_20_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.691:6 in forward, code: unsqueeze_107 = torch.ops.aten.unsqueeze.default(unsqueeze_106, 2);  unsqueeze_106 = None\n",
              "                    unsqueeze_107: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_106, 2);  unsqueeze_106 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.691:9 in forward, code: expand_21 = torch.ops.aten.expand.default(to_143, [1, -1, 1]);  to_143 = None\n",
              "                    expand_21: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_107, [1, -1, 1]);  unsqueeze_107 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.691:12 in forward, code: unsqueeze_108 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_108: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1)\n",
              "            \n",
              "                     # File: <eval_with_key>.691:13 in forward, code: slice_103 = torch.ops.aten.slice.Tensor(unsqueeze_108, 2, 0, 9223372036854775807);  unsqueeze_108 = None\n",
              "                    slice_103: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_108, 2, 0, 9223372036854775807);  unsqueeze_108 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.691:15 in forward, code: to_145 = torch.ops.aten.to.dtype(slice_103, torch.float32);  slice_103 = None\n",
              "                    _to_copy_22: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_103, dtype = torch.float32);  slice_103 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.658:9 in forward, code: matmul_20 = torch.ops.aten.matmul.default(to_146, to_147);  to_146 = to_147 = None\n",
              "                    matmul_20: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_21, _to_copy_22);  expand_21 = _to_copy_22 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.658:10 in forward, code: transpose_60 = torch.ops.aten.transpose.int(matmul_20, 1, 2);  matmul_20 = None\n",
              "                    transpose_60: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_20, 1, 2);  matmul_20 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.658:11 in forward, code: cat_60 = torch.ops.aten.cat.default([transpose_60, transpose_60], -1);  transpose_60 = None\n",
              "                    cat_60: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_60, transpose_60], -1);  transpose_60 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.658:12 in forward, code: cos_20 = torch.ops.aten.cos.default(cat_60)\n",
              "                    cos_20: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_60)\n",
              "            \n",
              "                     # File: <eval_with_key>.658:13 in forward, code: mul_152 = torch.ops.aten.mul.Tensor(cos_20, 1.0);  cos_20 = None\n",
              "                    mul_3173: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_20, 1.0);  cos_20 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.658:14 in forward, code: sin_20 = torch.ops.aten.sin.default(cat_60);  cat_60 = None\n",
              "                    sin_20: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_60);  cat_60 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.658:15 in forward, code: mul_153 = torch.ops.aten.mul.Tensor(sin_20, 1.0);  sin_20 = None\n",
              "                    mul_3180: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_20, 1.0);  sin_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_61: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_40, 3, 1);  view_40 = None\n",
              "                    unbind_20 = torch.ops.aten.unbind.int(transpose_61, 2);  transpose_61 = None\n",
              "                    getitem_100: \"f32[1, 12, s53, 64]\" = unbind_20[0]\n",
              "                    getitem_101: \"f32[1, 12, s53, 64]\" = unbind_20[1]\n",
              "                    getitem_102: \"f32[1, 12, s53, 64]\" = unbind_20[2];  unbind_20 = None\n",
              "                    unsqueeze_109: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_3173, 1);  mul_3173 = None\n",
              "                    unsqueeze_110: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_3180, 1);  mul_3180 = None\n",
              "                    mul_3204: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_100, unsqueeze_109)\n",
              "                    slice_104: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_100, 3, 0, 32)\n",
              "                    slice_105: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_100, 3, 32, 9223372036854775807);  getitem_100 = None\n",
              "                    neg_40: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_105);  slice_105 = None\n",
              "                    cat_61: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_40, slice_104], -1);  neg_40 = slice_104 = None\n",
              "                    mul_3221: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_61, unsqueeze_110);  cat_61 = None\n",
              "                    add_3182: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_3204, mul_3221);  mul_3204 = mul_3221 = None\n",
              "                    mul_3229: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_101, unsqueeze_109);  unsqueeze_109 = None\n",
              "                    slice_106: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_101, 3, 0, 32)\n",
              "                    slice_107: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_101, 3, 32, 9223372036854775807);  getitem_101 = None\n",
              "                    neg_41: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_107);  slice_107 = None\n",
              "                    cat_62: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_41, slice_106], -1);  neg_41 = slice_106 = None\n",
              "                    mul_3246: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_62, unsqueeze_110);  cat_62 = unsqueeze_110 = None\n",
              "                    add_3206: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_3229, mul_3246);  mul_3229 = mul_3246 = None\n",
              "                    scaled_dot_product_attention_20: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_3182, add_3206, getitem_102, masked_fill_1);  add_3182 = add_3206 = getitem_102 = masked_fill_1 = None\n",
              "                    transpose_62: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_20, 1, 2);  scaled_dot_product_attention_20 = None\n",
              "                    view_41: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_62, [sym_size_int_118, -1, 768]);  transpose_62 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_81: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_41, p_model_layers_20_attn_wo_weight);  view_41 = p_model_layers_20_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_3223: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_3102, linear_81);  add_3102 = linear_81 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_41: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_3223, [768], p_model_layers_20_mlp_norm_weight);  p_model_layers_20_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_82: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_41, p_model_layers_20_mlp_wi_weight);  layer_norm_41 = p_model_layers_20_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_20 = torch.ops.aten.split.Tensor(linear_82, 1152, -1);  linear_82 = None\n",
              "                    getitem_103: \"f32[1, s53, 1152]\" = split_20[0]\n",
              "                    getitem_104: \"f32[1, s53, 1152]\" = split_20[1];  split_20 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_20: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_103);  getitem_103 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_3284: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_20, getitem_104);  gelu_20 = getitem_104 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_22: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_3284);  mul_3284 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_83: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_22, p_model_layers_20_mlp_wo_weight);  clone_22 = p_model_layers_20_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_3251: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_3223, linear_83);  add_3223 = linear_83 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_42: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_3251, [768], p_model_layers_21_attn_norm_weight);  p_model_layers_21_attn_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_84: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_42, p_model_layers_21_attn_wqkv_weight);  layer_norm_42 = p_model_layers_21_attn_wqkv_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:498 in forward, code: qkv = qkv.view(bs, -1, 3, self.num_heads, self.head_dim)\n",
              "                    view_42: \"f32[1, s53, 3, 12, 64]\" = torch.ops.aten.view.default(linear_84, [sym_size_int_118, -1, 3, 12, 64]);  linear_84 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.692:5 in forward, code: unsqueeze_111 = torch.ops.aten.unsqueeze.default(b_model_layers_21_attn_rotary_emb_inv_freq, 0);  b_model_layers_21_attn_rotary_emb_inv_freq = None\n",
              "                    unsqueeze_111: \"f32[1, 32]\" = torch.ops.aten.unsqueeze.default(b_model_layers_21_attn_rotary_emb_inv_freq, 0);  b_model_layers_21_attn_rotary_emb_inv_freq = None\n",
              "            \n",
              "                     # File: <eval_with_key>.692:6 in forward, code: unsqueeze_112 = torch.ops.aten.unsqueeze.default(unsqueeze_111, 2);  unsqueeze_111 = None\n",
              "                    unsqueeze_112: \"f32[1, 32, 1]\" = torch.ops.aten.unsqueeze.default(unsqueeze_111, 2);  unsqueeze_111 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.692:9 in forward, code: expand_22 = torch.ops.aten.expand.default(to_150, [1, -1, 1]);  to_150 = None\n",
              "                    expand_22: \"f32[1, 32, 1]\" = torch.ops.aten.expand.default(unsqueeze_112, [1, -1, 1]);  unsqueeze_112 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.692:12 in forward, code: unsqueeze_113 = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "                    unsqueeze_113: \"i64[1, 1, s53]\" = torch.ops.aten.unsqueeze.default(unsqueeze, 1);  unsqueeze = None\n",
              "            \n",
              "                     # File: <eval_with_key>.692:13 in forward, code: slice_108 = torch.ops.aten.slice.Tensor(unsqueeze_113, 2, 0, 9223372036854775807);  unsqueeze_113 = None\n",
              "                    slice_108: \"i64[1, 1, s53]\" = torch.ops.aten.slice.Tensor(unsqueeze_113, 2, 0, 9223372036854775807);  unsqueeze_113 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.692:15 in forward, code: to_152 = torch.ops.aten.to.dtype(slice_108, torch.float32);  slice_108 = None\n",
              "                    _to_copy_23: \"f32[1, 1, s53]\" = torch.ops.aten._to_copy.default(slice_108, dtype = torch.float32);  slice_108 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.668:9 in forward, code: matmul_21 = torch.ops.aten.matmul.default(to_153, to_154);  to_153 = to_154 = None\n",
              "                    matmul_21: \"f32[1, 32, s53]\" = torch.ops.aten.matmul.default(expand_22, _to_copy_23);  expand_22 = _to_copy_23 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.668:10 in forward, code: transpose_63 = torch.ops.aten.transpose.int(matmul_21, 1, 2);  matmul_21 = None\n",
              "                    transpose_63: \"f32[1, s53, 32]\" = torch.ops.aten.transpose.int(matmul_21, 1, 2);  matmul_21 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.668:11 in forward, code: cat_63 = torch.ops.aten.cat.default([transpose_63, transpose_63], -1);  transpose_63 = None\n",
              "                    cat_63: \"f32[1, s53, 64]\" = torch.ops.aten.cat.default([transpose_63, transpose_63], -1);  transpose_63 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.668:12 in forward, code: cos_21 = torch.ops.aten.cos.default(cat_63)\n",
              "                    cos_21: \"f32[1, s53, 64]\" = torch.ops.aten.cos.default(cat_63)\n",
              "            \n",
              "                     # File: <eval_with_key>.668:13 in forward, code: mul_159 = torch.ops.aten.mul.Tensor(cos_21, 1.0);  cos_21 = None\n",
              "                    mul_3327: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(cos_21, 1.0);  cos_21 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.668:14 in forward, code: sin_21 = torch.ops.aten.sin.default(cat_63);  cat_63 = None\n",
              "                    sin_21: \"f32[1, s53, 64]\" = torch.ops.aten.sin.default(cat_63);  cat_63 = None\n",
              "            \n",
              "                     # File: <eval_with_key>.668:15 in forward, code: mul_160 = torch.ops.aten.mul.Tensor(sin_21, 1.0);  sin_21 = None\n",
              "                    mul_3334: \"f32[1, s53, 64]\" = torch.ops.aten.mul.Tensor(sin_21, 1.0);  sin_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:500 in forward, code: attn_outputs = MODERNBERT_ATTENTION_FUNCTION[self.config._attn_implementation](\n",
              "                    transpose_64: \"f32[1, 12, 3, s53, 64]\" = torch.ops.aten.transpose.int(view_42, 3, 1);  view_42 = None\n",
              "                    unbind_21 = torch.ops.aten.unbind.int(transpose_64, 2);  transpose_64 = None\n",
              "                    getitem_105: \"f32[1, 12, s53, 64]\" = unbind_21[0]\n",
              "                    getitem_106: \"f32[1, 12, s53, 64]\" = unbind_21[1]\n",
              "                    getitem_107: \"f32[1, 12, s53, 64]\" = unbind_21[2];  unbind_21 = None\n",
              "                    unsqueeze_114: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_3327, 1);  mul_3327 = None\n",
              "                    unsqueeze_115: \"f32[1, 1, s53, 64]\" = torch.ops.aten.unsqueeze.default(mul_3334, 1);  mul_3334 = None\n",
              "                    mul_3358: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_105, unsqueeze_114)\n",
              "                    slice_109: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_105, 3, 0, 32)\n",
              "                    slice_110: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_105, 3, 32, 9223372036854775807);  getitem_105 = None\n",
              "                    neg_42: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_110);  slice_110 = None\n",
              "                    cat_64: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_42, slice_109], -1);  neg_42 = slice_109 = None\n",
              "                    mul_3375: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_64, unsqueeze_115);  cat_64 = None\n",
              "                    add_3331: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_3358, mul_3375);  mul_3358 = mul_3375 = None\n",
              "                    mul_3383: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(getitem_106, unsqueeze_114);  unsqueeze_114 = None\n",
              "                    slice_111: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_106, 3, 0, 32)\n",
              "                    slice_112: \"f32[1, 12, s53, 32]\" = torch.ops.aten.slice.Tensor(getitem_106, 3, 32, 9223372036854775807);  getitem_106 = None\n",
              "                    neg_43: \"f32[1, 12, s53, 32]\" = torch.ops.aten.neg.default(slice_112);  slice_112 = None\n",
              "                    cat_65: \"f32[1, 12, s53, 64]\" = torch.ops.aten.cat.default([neg_43, slice_111], -1);  neg_43 = slice_111 = None\n",
              "                    mul_3400: \"f32[1, 12, s53, 64]\" = torch.ops.aten.mul.Tensor(cat_65, unsqueeze_115);  cat_65 = unsqueeze_115 = None\n",
              "                    add_3355: \"f32[1, 12, s53, 64]\" = torch.ops.aten.add.Tensor(mul_3383, mul_3400);  mul_3383 = mul_3400 = None\n",
              "                    scaled_dot_product_attention_21: \"f32[1, 12, s53, 64]\" = torch.ops.aten.scaled_dot_product_attention.default(add_3331, add_3355, getitem_107, masked_fill);  add_3331 = add_3355 = getitem_107 = masked_fill = None\n",
              "                    transpose_65: \"f32[1, s53, 12, 64]\" = torch.ops.aten.transpose.int(scaled_dot_product_attention_21, 1, 2);  scaled_dot_product_attention_21 = None\n",
              "                    view_43: \"f32[1, s53, 768]\" = torch.ops.aten.view.default(transpose_65, [sym_size_int_118, -1, 768]);  transpose_65 = sym_size_int_118 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_85: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(view_43, p_model_layers_21_attn_wo_weight);  view_43 = p_model_layers_21_attn_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:551 in forward, code: hidden_states = hidden_states + attn_outputs[0]\n",
              "                    add_3372: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_3251, linear_85);  add_3251 = linear_85 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_43: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_3372, [768], p_model_layers_21_mlp_norm_weight);  p_model_layers_21_mlp_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_86: \"f32[1, s53, 2304]\" = torch.ops.aten.linear.default(layer_norm_43, p_model_layers_21_mlp_wi_weight);  layer_norm_43 = p_model_layers_21_mlp_wi_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:241 in forward, code: input, gate = self.Wi(hidden_states).chunk(2, dim=-1)\n",
              "                    split_21 = torch.ops.aten.split.Tensor(linear_86, 1152, -1);  linear_86 = None\n",
              "                    getitem_108: \"f32[1, s53, 1152]\" = split_21[0]\n",
              "                    getitem_109: \"f32[1, s53, 1152]\" = split_21[1];  split_21 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_21: \"f32[1, s53, 1152]\" = torch.ops.aten.gelu.default(getitem_108);  getitem_108 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:242 in forward, code: return self.Wo(self.drop(self.act(input) * gate))\n",
              "                    mul_3438: \"f32[1, s53, 1152]\" = torch.ops.aten.mul.Tensor(gelu_21, getitem_109);  gelu_21 = getitem_109 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_23: \"f32[1, s53, 1152]\" = torch.ops.aten.clone.default(mul_3438);  mul_3438 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_87: \"f32[1, s53, 768]\" = torch.ops.aten.linear.default(clone_23, p_model_layers_21_mlp_wo_weight);  clone_23 = p_model_layers_21_mlp_wo_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:557 in forward, code: hidden_states = hidden_states + mlp_output\n",
              "                    add_3400: \"f32[1, s53, 768]\" = torch.ops.aten.add.Tensor(add_3372, linear_87);  add_3372 = linear_87 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_44: \"f32[1, s53, 768]\" = torch.ops.aten.layer_norm.default(add_3400, [768], p_model_final_norm_weight);  add_3400 = p_model_final_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/models/modernbert/modeling_modernbert.py:1207 in forward, code: last_hidden_state = (last_hidden_state * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(\n",
              "                    unsqueeze_116: \"i64[s43, s53, 1]\" = torch.ops.aten.unsqueeze.default(attention_mask, -1)\n",
              "                    convert_element_type_default: \"f32[s43, s53, 1]\" = torch.ops.prims.convert_element_type.default(unsqueeze_116, dtype = torch.float32);  unsqueeze_116 = None\n",
              "                    mul_3456: \"f32[s43, s53, 768]\" = torch.ops.aten.mul.Tensor(layer_norm_44, convert_element_type_default);  layer_norm_44 = convert_element_type_default = None\n",
              "                    sum_1: \"f32[s43, 768]\" = torch.ops.aten.sum.dim_IntList(mul_3456, [1]);  mul_3456 = None\n",
              "                    sum_2: \"i64[s43, 1]\" = torch.ops.aten.sum.dim_IntList(attention_mask, [1], True);  attention_mask = None\n",
              "                    convert_element_type_default_1: \"f32[s43, 1]\" = torch.ops.prims.convert_element_type.default(sum_2, dtype = torch.float32);  sum_2 = None\n",
              "                    div: \"f32[s43, 768]\" = torch.ops.aten.div.Tensor(sum_1, convert_element_type_default_1);  sum_1 = convert_element_type_default_1 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_88: \"f32[s43, 768]\" = torch.ops.aten.linear.default(div, p_head_dense_weight);  div = p_head_dense_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/transformers/activations.py:85 in forward, code: return self.act(input)\n",
              "                    gelu_22: \"f32[1, 768]\" = torch.ops.aten.gelu.default(linear_88);  linear_88 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
              "                    layer_norm_45: \"f32[1, 768]\" = torch.ops.aten.layer_norm.default(gelu_22, [768], p_head_norm_weight);  gelu_22 = p_head_norm_weight = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/dropout.py:73 in forward, code: return F.dropout(input, self.p, self.training, self.inplace)\n",
              "                    clone_24: \"f32[1, 768]\" = torch.ops.aten.clone.default(layer_norm_45);  layer_norm_45 = None\n",
              "            \n",
              "                     # File: /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
              "                    linear_89: \"f32[1, 83]\" = torch.ops.aten.linear.default(clone_24, p_classifier_weight, p_classifier_bias);  clone_24 = p_classifier_weight = p_classifier_bias = None\n",
              "                    return (linear_89,)\n",
              "            \n",
              "        Graph signature: \n",
              "            # inputs\n",
              "            p_model_embeddings_tok_embeddings_weight: PARAMETER target='model.embeddings.tok_embeddings.weight'\n",
              "            p_model_embeddings_norm_weight: PARAMETER target='model.embeddings.norm.weight'\n",
              "            p_model_layers_0_attn_wqkv_weight: PARAMETER target='model.layers.0.attn.Wqkv.weight'\n",
              "            p_model_layers_0_attn_wo_weight: PARAMETER target='model.layers.0.attn.Wo.weight'\n",
              "            p_model_layers_0_mlp_norm_weight: PARAMETER target='model.layers.0.mlp_norm.weight'\n",
              "            p_model_layers_0_mlp_wi_weight: PARAMETER target='model.layers.0.mlp.Wi.weight'\n",
              "            p_model_layers_0_mlp_wo_weight: PARAMETER target='model.layers.0.mlp.Wo.weight'\n",
              "            p_model_layers_1_attn_norm_weight: PARAMETER target='model.layers.1.attn_norm.weight'\n",
              "            p_model_layers_1_attn_wqkv_weight: PARAMETER target='model.layers.1.attn.Wqkv.weight'\n",
              "            p_model_layers_1_attn_wo_weight: PARAMETER target='model.layers.1.attn.Wo.weight'\n",
              "            p_model_layers_1_mlp_norm_weight: PARAMETER target='model.layers.1.mlp_norm.weight'\n",
              "            p_model_layers_1_mlp_wi_weight: PARAMETER target='model.layers.1.mlp.Wi.weight'\n",
              "            p_model_layers_1_mlp_wo_weight: PARAMETER target='model.layers.1.mlp.Wo.weight'\n",
              "            p_model_layers_2_attn_norm_weight: PARAMETER target='model.layers.2.attn_norm.weight'\n",
              "            p_model_layers_2_attn_wqkv_weight: PARAMETER target='model.layers.2.attn.Wqkv.weight'\n",
              "            p_model_layers_2_attn_wo_weight: PARAMETER target='model.layers.2.attn.Wo.weight'\n",
              "            p_model_layers_2_mlp_norm_weight: PARAMETER target='model.layers.2.mlp_norm.weight'\n",
              "            p_model_layers_2_mlp_wi_weight: PARAMETER target='model.layers.2.mlp.Wi.weight'\n",
              "            p_model_layers_2_mlp_wo_weight: PARAMETER target='model.layers.2.mlp.Wo.weight'\n",
              "            p_model_layers_3_attn_norm_weight: PARAMETER target='model.layers.3.attn_norm.weight'\n",
              "            p_model_layers_3_attn_wqkv_weight: PARAMETER target='model.layers.3.attn.Wqkv.weight'\n",
              "            p_model_layers_3_attn_wo_weight: PARAMETER target='model.layers.3.attn.Wo.weight'\n",
              "            p_model_layers_3_mlp_norm_weight: PARAMETER target='model.layers.3.mlp_norm.weight'\n",
              "            p_model_layers_3_mlp_wi_weight: PARAMETER target='model.layers.3.mlp.Wi.weight'\n",
              "            p_model_layers_3_mlp_wo_weight: PARAMETER target='model.layers.3.mlp.Wo.weight'\n",
              "            p_model_layers_4_attn_norm_weight: PARAMETER target='model.layers.4.attn_norm.weight'\n",
              "            p_model_layers_4_attn_wqkv_weight: PARAMETER target='model.layers.4.attn.Wqkv.weight'\n",
              "            p_model_layers_4_attn_wo_weight: PARAMETER target='model.layers.4.attn.Wo.weight'\n",
              "            p_model_layers_4_mlp_norm_weight: PARAMETER target='model.layers.4.mlp_norm.weight'\n",
              "            p_model_layers_4_mlp_wi_weight: PARAMETER target='model.layers.4.mlp.Wi.weight'\n",
              "            p_model_layers_4_mlp_wo_weight: PARAMETER target='model.layers.4.mlp.Wo.weight'\n",
              "            p_model_layers_5_attn_norm_weight: PARAMETER target='model.layers.5.attn_norm.weight'\n",
              "            p_model_layers_5_attn_wqkv_weight: PARAMETER target='model.layers.5.attn.Wqkv.weight'\n",
              "            p_model_layers_5_attn_wo_weight: PARAMETER target='model.layers.5.attn.Wo.weight'\n",
              "            p_model_layers_5_mlp_norm_weight: PARAMETER target='model.layers.5.mlp_norm.weight'\n",
              "            p_model_layers_5_mlp_wi_weight: PARAMETER target='model.layers.5.mlp.Wi.weight'\n",
              "            p_model_layers_5_mlp_wo_weight: PARAMETER target='model.layers.5.mlp.Wo.weight'\n",
              "            p_model_layers_6_attn_norm_weight: PARAMETER target='model.layers.6.attn_norm.weight'\n",
              "            p_model_layers_6_attn_wqkv_weight: PARAMETER target='model.layers.6.attn.Wqkv.weight'\n",
              "            p_model_layers_6_attn_wo_weight: PARAMETER target='model.layers.6.attn.Wo.weight'\n",
              "            p_model_layers_6_mlp_norm_weight: PARAMETER target='model.layers.6.mlp_norm.weight'\n",
              "            p_model_layers_6_mlp_wi_weight: PARAMETER target='model.layers.6.mlp.Wi.weight'\n",
              "            p_model_layers_6_mlp_wo_weight: PARAMETER target='model.layers.6.mlp.Wo.weight'\n",
              "            p_model_layers_7_attn_norm_weight: PARAMETER target='model.layers.7.attn_norm.weight'\n",
              "            p_model_layers_7_attn_wqkv_weight: PARAMETER target='model.layers.7.attn.Wqkv.weight'\n",
              "            p_model_layers_7_attn_wo_weight: PARAMETER target='model.layers.7.attn.Wo.weight'\n",
              "            p_model_layers_7_mlp_norm_weight: PARAMETER target='model.layers.7.mlp_norm.weight'\n",
              "            p_model_layers_7_mlp_wi_weight: PARAMETER target='model.layers.7.mlp.Wi.weight'\n",
              "            p_model_layers_7_mlp_wo_weight: PARAMETER target='model.layers.7.mlp.Wo.weight'\n",
              "            p_model_layers_8_attn_norm_weight: PARAMETER target='model.layers.8.attn_norm.weight'\n",
              "            p_model_layers_8_attn_wqkv_weight: PARAMETER target='model.layers.8.attn.Wqkv.weight'\n",
              "            p_model_layers_8_attn_wo_weight: PARAMETER target='model.layers.8.attn.Wo.weight'\n",
              "            p_model_layers_8_mlp_norm_weight: PARAMETER target='model.layers.8.mlp_norm.weight'\n",
              "            p_model_layers_8_mlp_wi_weight: PARAMETER target='model.layers.8.mlp.Wi.weight'\n",
              "            p_model_layers_8_mlp_wo_weight: PARAMETER target='model.layers.8.mlp.Wo.weight'\n",
              "            p_model_layers_9_attn_norm_weight: PARAMETER target='model.layers.9.attn_norm.weight'\n",
              "            p_model_layers_9_attn_wqkv_weight: PARAMETER target='model.layers.9.attn.Wqkv.weight'\n",
              "            p_model_layers_9_attn_wo_weight: PARAMETER target='model.layers.9.attn.Wo.weight'\n",
              "            p_model_layers_9_mlp_norm_weight: PARAMETER target='model.layers.9.mlp_norm.weight'\n",
              "            p_model_layers_9_mlp_wi_weight: PARAMETER target='model.layers.9.mlp.Wi.weight'\n",
              "            p_model_layers_9_mlp_wo_weight: PARAMETER target='model.layers.9.mlp.Wo.weight'\n",
              "            p_model_layers_10_attn_norm_weight: PARAMETER target='model.layers.10.attn_norm.weight'\n",
              "            p_model_layers_10_attn_wqkv_weight: PARAMETER target='model.layers.10.attn.Wqkv.weight'\n",
              "            p_model_layers_10_attn_wo_weight: PARAMETER target='model.layers.10.attn.Wo.weight'\n",
              "            p_model_layers_10_mlp_norm_weight: PARAMETER target='model.layers.10.mlp_norm.weight'\n",
              "            p_model_layers_10_mlp_wi_weight: PARAMETER target='model.layers.10.mlp.Wi.weight'\n",
              "            p_model_layers_10_mlp_wo_weight: PARAMETER target='model.layers.10.mlp.Wo.weight'\n",
              "            p_model_layers_11_attn_norm_weight: PARAMETER target='model.layers.11.attn_norm.weight'\n",
              "            p_model_layers_11_attn_wqkv_weight: PARAMETER target='model.layers.11.attn.Wqkv.weight'\n",
              "            p_model_layers_11_attn_wo_weight: PARAMETER target='model.layers.11.attn.Wo.weight'\n",
              "            p_model_layers_11_mlp_norm_weight: PARAMETER target='model.layers.11.mlp_norm.weight'\n",
              "            p_model_layers_11_mlp_wi_weight: PARAMETER target='model.layers.11.mlp.Wi.weight'\n",
              "            p_model_layers_11_mlp_wo_weight: PARAMETER target='model.layers.11.mlp.Wo.weight'\n",
              "            p_model_layers_12_attn_norm_weight: PARAMETER target='model.layers.12.attn_norm.weight'\n",
              "            p_model_layers_12_attn_wqkv_weight: PARAMETER target='model.layers.12.attn.Wqkv.weight'\n",
              "            p_model_layers_12_attn_wo_weight: PARAMETER target='model.layers.12.attn.Wo.weight'\n",
              "            p_model_layers_12_mlp_norm_weight: PARAMETER target='model.layers.12.mlp_norm.weight'\n",
              "            p_model_layers_12_mlp_wi_weight: PARAMETER target='model.layers.12.mlp.Wi.weight'\n",
              "            p_model_layers_12_mlp_wo_weight: PARAMETER target='model.layers.12.mlp.Wo.weight'\n",
              "            p_model_layers_13_attn_norm_weight: PARAMETER target='model.layers.13.attn_norm.weight'\n",
              "            p_model_layers_13_attn_wqkv_weight: PARAMETER target='model.layers.13.attn.Wqkv.weight'\n",
              "            p_model_layers_13_attn_wo_weight: PARAMETER target='model.layers.13.attn.Wo.weight'\n",
              "            p_model_layers_13_mlp_norm_weight: PARAMETER target='model.layers.13.mlp_norm.weight'\n",
              "            p_model_layers_13_mlp_wi_weight: PARAMETER target='model.layers.13.mlp.Wi.weight'\n",
              "            p_model_layers_13_mlp_wo_weight: PARAMETER target='model.layers.13.mlp.Wo.weight'\n",
              "            p_model_layers_14_attn_norm_weight: PARAMETER target='model.layers.14.attn_norm.weight'\n",
              "            p_model_layers_14_attn_wqkv_weight: PARAMETER target='model.layers.14.attn.Wqkv.weight'\n",
              "            p_model_layers_14_attn_wo_weight: PARAMETER target='model.layers.14.attn.Wo.weight'\n",
              "            p_model_layers_14_mlp_norm_weight: PARAMETER target='model.layers.14.mlp_norm.weight'\n",
              "            p_model_layers_14_mlp_wi_weight: PARAMETER target='model.layers.14.mlp.Wi.weight'\n",
              "            p_model_layers_14_mlp_wo_weight: PARAMETER target='model.layers.14.mlp.Wo.weight'\n",
              "            p_model_layers_15_attn_norm_weight: PARAMETER target='model.layers.15.attn_norm.weight'\n",
              "            p_model_layers_15_attn_wqkv_weight: PARAMETER target='model.layers.15.attn.Wqkv.weight'\n",
              "            p_model_layers_15_attn_wo_weight: PARAMETER target='model.layers.15.attn.Wo.weight'\n",
              "            p_model_layers_15_mlp_norm_weight: PARAMETER target='model.layers.15.mlp_norm.weight'\n",
              "            p_model_layers_15_mlp_wi_weight: PARAMETER target='model.layers.15.mlp.Wi.weight'\n",
              "            p_model_layers_15_mlp_wo_weight: PARAMETER target='model.layers.15.mlp.Wo.weight'\n",
              "            p_model_layers_16_attn_norm_weight: PARAMETER target='model.layers.16.attn_norm.weight'\n",
              "            p_model_layers_16_attn_wqkv_weight: PARAMETER target='model.layers.16.attn.Wqkv.weight'\n",
              "            p_model_layers_16_attn_wo_weight: PARAMETER target='model.layers.16.attn.Wo.weight'\n",
              "            p_model_layers_16_mlp_norm_weight: PARAMETER target='model.layers.16.mlp_norm.weight'\n",
              "            p_model_layers_16_mlp_wi_weight: PARAMETER target='model.layers.16.mlp.Wi.weight'\n",
              "            p_model_layers_16_mlp_wo_weight: PARAMETER target='model.layers.16.mlp.Wo.weight'\n",
              "            p_model_layers_17_attn_norm_weight: PARAMETER target='model.layers.17.attn_norm.weight'\n",
              "            p_model_layers_17_attn_wqkv_weight: PARAMETER target='model.layers.17.attn.Wqkv.weight'\n",
              "            p_model_layers_17_attn_wo_weight: PARAMETER target='model.layers.17.attn.Wo.weight'\n",
              "            p_model_layers_17_mlp_norm_weight: PARAMETER target='model.layers.17.mlp_norm.weight'\n",
              "            p_model_layers_17_mlp_wi_weight: PARAMETER target='model.layers.17.mlp.Wi.weight'\n",
              "            p_model_layers_17_mlp_wo_weight: PARAMETER target='model.layers.17.mlp.Wo.weight'\n",
              "            p_model_layers_18_attn_norm_weight: PARAMETER target='model.layers.18.attn_norm.weight'\n",
              "            p_model_layers_18_attn_wqkv_weight: PARAMETER target='model.layers.18.attn.Wqkv.weight'\n",
              "            p_model_layers_18_attn_wo_weight: PARAMETER target='model.layers.18.attn.Wo.weight'\n",
              "            p_model_layers_18_mlp_norm_weight: PARAMETER target='model.layers.18.mlp_norm.weight'\n",
              "            p_model_layers_18_mlp_wi_weight: PARAMETER target='model.layers.18.mlp.Wi.weight'\n",
              "            p_model_layers_18_mlp_wo_weight: PARAMETER target='model.layers.18.mlp.Wo.weight'\n",
              "            p_model_layers_19_attn_norm_weight: PARAMETER target='model.layers.19.attn_norm.weight'\n",
              "            p_model_layers_19_attn_wqkv_weight: PARAMETER target='model.layers.19.attn.Wqkv.weight'\n",
              "            p_model_layers_19_attn_wo_weight: PARAMETER target='model.layers.19.attn.Wo.weight'\n",
              "            p_model_layers_19_mlp_norm_weight: PARAMETER target='model.layers.19.mlp_norm.weight'\n",
              "            p_model_layers_19_mlp_wi_weight: PARAMETER target='model.layers.19.mlp.Wi.weight'\n",
              "            p_model_layers_19_mlp_wo_weight: PARAMETER target='model.layers.19.mlp.Wo.weight'\n",
              "            p_model_layers_20_attn_norm_weight: PARAMETER target='model.layers.20.attn_norm.weight'\n",
              "            p_model_layers_20_attn_wqkv_weight: PARAMETER target='model.layers.20.attn.Wqkv.weight'\n",
              "            p_model_layers_20_attn_wo_weight: PARAMETER target='model.layers.20.attn.Wo.weight'\n",
              "            p_model_layers_20_mlp_norm_weight: PARAMETER target='model.layers.20.mlp_norm.weight'\n",
              "            p_model_layers_20_mlp_wi_weight: PARAMETER target='model.layers.20.mlp.Wi.weight'\n",
              "            p_model_layers_20_mlp_wo_weight: PARAMETER target='model.layers.20.mlp.Wo.weight'\n",
              "            p_model_layers_21_attn_norm_weight: PARAMETER target='model.layers.21.attn_norm.weight'\n",
              "            p_model_layers_21_attn_wqkv_weight: PARAMETER target='model.layers.21.attn.Wqkv.weight'\n",
              "            p_model_layers_21_attn_wo_weight: PARAMETER target='model.layers.21.attn.Wo.weight'\n",
              "            p_model_layers_21_mlp_norm_weight: PARAMETER target='model.layers.21.mlp_norm.weight'\n",
              "            p_model_layers_21_mlp_wi_weight: PARAMETER target='model.layers.21.mlp.Wi.weight'\n",
              "            p_model_layers_21_mlp_wo_weight: PARAMETER target='model.layers.21.mlp.Wo.weight'\n",
              "            p_model_final_norm_weight: PARAMETER target='model.final_norm.weight'\n",
              "            p_head_dense_weight: PARAMETER target='head.dense.weight'\n",
              "            p_head_norm_weight: PARAMETER target='head.norm.weight'\n",
              "            p_classifier_weight: PARAMETER target='classifier.weight'\n",
              "            p_classifier_bias: PARAMETER target='classifier.bias'\n",
              "            c_model_lifted_tensor_0: CONSTANT_TENSOR target='model.lifted_tensor_0'\n",
              "            b_model_layers_0_attn_rotary_emb_inv_freq: BUFFER target='model.layers.0.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_1_attn_rotary_emb_inv_freq: BUFFER target='model.layers.1.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_2_attn_rotary_emb_inv_freq: BUFFER target='model.layers.2.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_3_attn_rotary_emb_inv_freq: BUFFER target='model.layers.3.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_4_attn_rotary_emb_inv_freq: BUFFER target='model.layers.4.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_5_attn_rotary_emb_inv_freq: BUFFER target='model.layers.5.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_6_attn_rotary_emb_inv_freq: BUFFER target='model.layers.6.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_7_attn_rotary_emb_inv_freq: BUFFER target='model.layers.7.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_8_attn_rotary_emb_inv_freq: BUFFER target='model.layers.8.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_9_attn_rotary_emb_inv_freq: BUFFER target='model.layers.9.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_10_attn_rotary_emb_inv_freq: BUFFER target='model.layers.10.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_11_attn_rotary_emb_inv_freq: BUFFER target='model.layers.11.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_12_attn_rotary_emb_inv_freq: BUFFER target='model.layers.12.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_13_attn_rotary_emb_inv_freq: BUFFER target='model.layers.13.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_14_attn_rotary_emb_inv_freq: BUFFER target='model.layers.14.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_15_attn_rotary_emb_inv_freq: BUFFER target='model.layers.15.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_16_attn_rotary_emb_inv_freq: BUFFER target='model.layers.16.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_17_attn_rotary_emb_inv_freq: BUFFER target='model.layers.17.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_18_attn_rotary_emb_inv_freq: BUFFER target='model.layers.18.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_19_attn_rotary_emb_inv_freq: BUFFER target='model.layers.19.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_20_attn_rotary_emb_inv_freq: BUFFER target='model.layers.20.attn.rotary_emb.inv_freq' persistent=False\n",
              "            b_model_layers_21_attn_rotary_emb_inv_freq: BUFFER target='model.layers.21.attn.rotary_emb.inv_freq' persistent=False\n",
              "            input_ids: USER_INPUT\n",
              "            attention_mask: USER_INPUT\n",
              "    \n",
              "            # outputs\n",
              "            linear_89: USER_OUTPUT\n",
              "    \n",
              "        Range constraints: {s72: VR[0, int_oo], s53: VR[0, int_oo], s43: VR[1, 2]}\n",
              "\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "!pip install onnxscript\n",
        "\n",
        "classifier = learner_inf.model.hf_model.eval()\n",
        "\n",
        "# Creating dummy input\n",
        "\n",
        "dummy_input_ids = torch.ones(1,512, dtype=torch.long)\n",
        "dummy_attention_mask = torch.ones(1,512, dtype=torch.long)\n",
        "\n",
        "torch.onnx.export(\n",
        "    classifier,\n",
        "    (dummy_input_ids, dummy_attention_mask),\n",
        "    '/content/drive/MyDrive/Data Science/CP3_Skill Classifier/models/skill-classifier-modernbert.onnx',\n",
        "    verbose=True,\n",
        "    input_names=['input_ids','attention_mask'],\n",
        "    output_names=['logits'],\n",
        "    opset_version=18,\n",
        "    dynamic_axes={\n",
        "        \"input_ids\":       {0: \"batch\", 1: \"sequence\"},\n",
        "        \"attention_mask\":  {0: \"batch\", 1: \"sequence\"},\n",
        "        \"logits\":          {0: \"batch\"}\n",
        "    },\n",
        "    do_constant_folding=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dPH9L16Xb4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "2038c3c887224198993f63eed399ad71",
            "9a70bff99ef840a6b29bc46a867b1b70",
            "57b6a379f0714c42bf1efd1be220d083",
            "c32a47cc1e2d426e9e53f0b8cc150850",
            "25ed2b0f89c74e7d92888a53568d55f5",
            "c4268f2b99d744baa6019755e56ad581",
            "bf332984343b4bd096ea6f19bb6aae00",
            "007a4c99c5ec464d9ab528a0740e1f36",
            "988bc974a6234671bf86b232cc7173c1",
            "553894e9f7dd4557b8317048343d0f73",
            "51ad6567f4174550ad5b5e00e921a9a0",
            "de06b193669d4bd18f8fe53e750cda0e",
            "4739836a19be42f4b7e612f6adf46d31",
            "eb5c1fd6f2294ba5a17be17790ee7a1e",
            "859411ca6c3c465bbeeee9210300e5f9",
            "41c10cd5ec414bfb9baf15a467e5d1ef",
            "6dd7ef1670c546f0880e7ad1b48d6e3e",
            "fd35abd3c42d461897229131fc1c7830",
            "9ca7c3a3941f492691123a99bf13f468",
            "24b6543b09da4239b4982d20f10aeae4",
            "eca2f093ad25418aaa113009bfdbc4b9",
            "6309efce690340c585e7eb08f1a92c2a",
            "a1a1e1490a8f4cbca0a71bc1c33ab1f9",
            "cdf2f72223564bba837843f0227c3e35",
            "24e6078e650d480e8f524c8ce2f28236",
            "d6d52f308bb540cb885efcce529ab5c5",
            "5a28e1057f4a40af800f0d238c73fffb",
            "e06186f05ebc44439b8e14525a04d114",
            "b0442a1f63d843a38c42353aadbff519",
            "58aa636a5b364c9482a74e61c247ffd2",
            "9d38b9f1c848435db895f1a16b6e074a",
            "eb2cd4d8181849caa809a9056819b921",
            "95de334e634b4adf81e9c65903b3fdec",
            "2bc89c8afb954124b9c840da71f57da8",
            "c1fd827a91fb4376a274891e363177d4",
            "4a33c6a9490a4024a97e21b5256d178c",
            "75bd03b8265e49a5885edcc944202a21",
            "e5a08d79cc654ccd8b1a9914a3ee985e",
            "e314bce97d4f412fa352711248260f62",
            "2016e26a62d94848b1a4ed5cf39b16d0",
            "eaae81dedc3242d488320687deb50a59",
            "5ddd35cbf648444687390a3c84e4f92f",
            "9d8b4a773cc248638ae3716ec0bb57a6",
            "2ab5c636a29046619f91ecee22cb3c8b",
            "8cc6d484a4454844ab6cb0c5c3317e6a",
            "c87c181aa4ea4f4dab6bee4b792f1850",
            "bd5e5cfbfd974e2981ad8ffa069b875f",
            "e668b88c7b1c44e797efc761fe2a786a",
            "6ac931ad8a0f4e86b4a5419e64dd31a4",
            "fb28ab7ca8744449ad618f1617834b90",
            "bdb8fc9bdb814ee18ed55c35774faa16",
            "42194dc416084edc9f536857e00cfa8f",
            "09c7ae63f53a44df836b8063f4934369",
            "f47f9321e71845f7a45880c00cc15f84",
            "f441a9c6dc1b430b93476ec08fea9960"
          ]
        },
        "outputId": "d35b65bc-8ce5-4f3f-9514-607ada3d2e47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2038c3c887224198993f63eed399ad71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de06b193669d4bd18f8fe53e750cda0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1a1e1490a8f4cbca0a71bc1c33ab1f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bc89c8afb954124b9c840da71f57da8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cc6d484a4454844ab6cb0c5c3317e6a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import onnxruntime as rt\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "\n",
        "class_labels = skills\n",
        "\n",
        "inf_session = rt.InferenceSession('/content/drive/MyDrive/Data Science/CP3_Skill Classifier/models/skill-classifier-modernbert.onnx')\n",
        "input_name = inf_session.get_inputs()[0].name\n",
        "output_name = inf_session.get_outputs()[0].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01xkrzK0YlEN",
        "outputId": "8cfd2ac8-fb43-4950-e767-3ead7b5e0e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1924/1924 [19:35<00:00,  1.64it/s]\n"
          ]
        }
      ],
      "source": [
        "preds = []\n",
        "\n",
        "for text in tqdm(valid_df['job_description']):\n",
        "    encoded_input = tokenizer(text, padding='max_length', truncation=True,\n",
        "                    max_length=512, return_tensors='np')\n",
        "    logits = inf_session.run(None, dict(encoded_input))[0]\n",
        "    logits = logits[0] if isinstance(logits, list) else logits\n",
        "\n",
        "    pred = (torch.sigmoid(torch.from_numpy(logits)) >= 0.5).int()[0].tolist()\n",
        "    preds.append(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ea84c0b",
        "outputId": "119c6ab3-9cb2-4a3f-eecb-1bcefe142384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Samples: 0.9451\n",
            "F1-Macro:   0.9250\n",
            "F1-Micro:   0.9503\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "preds_binary_np = np.array(preds)\n",
        "targs_binary_np = valid_df[class_labels].values\n",
        "\n",
        "\n",
        "print(f\"F1-Samples: {f1_score(targs_binary_np, preds_binary_np, average='samples'):.4f}\")\n",
        "print(f\"F1-Macro:   {f1_score(targs_binary_np, preds_binary_np, average='macro'):.4f}\")\n",
        "print(f\"F1-Micro:   {f1_score(targs_binary_np, preds_binary_np, average='micro'):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be0e392b",
        "outputId": "a25c701f-3898-4a29-b571-d8fbaeed7745",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Description: \n",
            "### **Job Title: Junior Software Engineer**\n",
            "\n",
            "**Location:** Dhaka, Bangladesh\n",
            "**Employment Type:** Full-Time\n",
            "**Experience Level:** Entry to Mid-Level\n",
            "\n",
            "---\n",
            "\n",
            "### **Job Overview**\n",
            "\n",
            "We are looking for a motivated and detail-oriented **Junior Software Engineer** to join our growing technology team. The ideal candidate will contribute to the design, development, testing, and maintenance of scalable software solutions while collaborating with cross-functional teams to deliver high-quality products.\n",
            "\n",
            "---\n",
            "\n",
            "### **Key Responsibilities**\n",
            "\n",
            "* Design, develop, and maintain web and backend applications\n",
            "* Write clean, efficient, and well-documented code\n",
            "* Debug, troubleshoot, and optimize application performance\n",
            "* Collaborate with product managers and designers to implement new features\n",
            "* Participate in code reviews and continuous improvement initiatives\n",
            "* Assist in software testing, deployment, and maintenance activities\n",
            "* Learn and adapt to new technologies as required\n",
            "\n",
            "---\n",
            "\n",
            "### **Required Skills & Qualifications**\n",
            "\n",
            "* Proficiency in at least one programming language (Python, Java, JavaScript, C++, etc.)\n",
            "* Basic understanding of data structures and algorithms\n",
            "* Familiarity with databases (MySQL, PostgreSQL, MongoDB)\n",
            "* Understanding of RESTful APIs and web services\n",
            "* Knowledge of version control systems such as Git\n",
            "* Strong problem-solving and analytical skills\n",
            "* Good communication and teamwork abilities\n",
            "\n",
            "---\n",
            "\n",
            "### **Preferred Qualifications**\n",
            "\n",
            "* Experience with frameworks such as Django, Flask, Spring Boot, or React\n",
            "* Exposure to cloud platforms (AWS, Azure, GCP)\n",
            "* Basic understanding of software development lifecycle (SDLC)\n",
            "* Internship or project experience in software development\n",
            "\n",
            "---\n",
            "\n",
            "### **Benefits**\n",
            "\n",
            "* Competitive salary package\n",
            "* Performance-based bonuses\n",
            "* Flexible working hours\n",
            "* Learning and development opportunities\n",
            "* Friendly and collaborative work environment\n",
            "\n",
            "Predicted Skills: ['Python', 'Java', 'SQL', 'Back End Development', 'Cloud Computing', 'Software Testing', 'API Development', 'Git Version Control', 'JavaScript', 'Git', 'AWS', 'Azure', 'GCP', 'React', 'Communication', 'Problem Solving', 'Adaptability', 'Attention to Detail', 'Collaboration', 'Flexibility']\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime as rt\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "test_job_description = \"\"\"\n",
        "### **Job Title: Junior Software Engineer**\n",
        "\n",
        "**Location:** Dhaka, Bangladesh\n",
        "**Employment Type:** Full-Time\n",
        "**Experience Level:** Entry to Mid-Level\n",
        "\n",
        "---\n",
        "\n",
        "### **Job Overview**\n",
        "\n",
        "We are looking for a motivated and detail-oriented **Junior Software Engineer** to join our growing technology team. The ideal candidate will contribute to the design, development, testing, and maintenance of scalable software solutions while collaborating with cross-functional teams to deliver high-quality products.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Responsibilities**\n",
        "\n",
        "* Design, develop, and maintain web and backend applications\n",
        "* Write clean, efficient, and well-documented code\n",
        "* Debug, troubleshoot, and optimize application performance\n",
        "* Collaborate with product managers and designers to implement new features\n",
        "* Participate in code reviews and continuous improvement initiatives\n",
        "* Assist in software testing, deployment, and maintenance activities\n",
        "* Learn and adapt to new technologies as required\n",
        "\n",
        "---\n",
        "\n",
        "### **Required Skills & Qualifications**\n",
        "\n",
        "* Proficiency in at least one programming language (Python, Java, JavaScript, C++, etc.)\n",
        "* Basic understanding of data structures and algorithms\n",
        "* Familiarity with databases (MySQL, PostgreSQL, MongoDB)\n",
        "* Understanding of RESTful APIs and web services\n",
        "* Knowledge of version control systems such as Git\n",
        "* Strong problem-solving and analytical skills\n",
        "* Good communication and teamwork abilities\n",
        "\n",
        "---\n",
        "\n",
        "### **Preferred Qualifications**\n",
        "\n",
        "* Experience with frameworks such as Django, Flask, Spring Boot, or React\n",
        "* Exposure to cloud platforms (AWS, Azure, GCP)\n",
        "* Basic understanding of software development lifecycle (SDLC)\n",
        "* Internship or project experience in software development\n",
        "\n",
        "---\n",
        "\n",
        "### **Benefits**\n",
        "\n",
        "* Competitive salary package\n",
        "* Performance-based bonuses\n",
        "* Flexible working hours\n",
        "* Learning and development opportunities\n",
        "* Friendly and collaborative work environment\"\"\"\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "onnx_model_path_updated = '/content/drive/MyDrive/Data Science/CP3_Skill Classifier/models/skill-classifier.onnx'\n",
        "\n",
        "\n",
        "inf_session = rt.InferenceSession(onnx_model_path_updated)\n",
        "input_name_0 = inf_session.get_inputs()[0].name\n",
        "input_name_1 = inf_session.get_inputs()[1].name\n",
        "output_name_new = inf_session.get_outputs()[0].name\n",
        "\n",
        "\n",
        "encoded_input = tokenizer(test_job_description, return_tensors='np', padding='max_length', truncation=True, max_length=512)\n",
        "input_ids_test = encoded_input['input_ids']\n",
        "attention_mask_test = encoded_input['attention_mask']\n",
        "\n",
        "\n",
        "onnx_output = inf_session.run(\n",
        "    [output_name_new],\n",
        "    {input_name_0: input_ids_test, input_name_1: attention_mask_test}\n",
        ")[0]\n",
        "\n",
        "\n",
        "probs = torch.sigmoid(torch.FloatTensor(onnx_output))\n",
        "\n",
        "prediction_threshold = 0.5\n",
        "\n",
        "predicted_skills_indices = (probs >= prediction_threshold).nonzero(as_tuple=True)[1]\n",
        "predicted_skill_names = [class_labels[i] for i in predicted_skills_indices]\n",
        "\n",
        "print(f\"Job Description: {test_job_description}\")\n",
        "print(f\"\\nPredicted Skills: {predicted_skill_names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Jb6LSIkVVnpt",
        "outputId": "f48f19f5-1ad4-4ce2-adb0-b59f8870e75c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_99c0dd74-adbc-4205-94ca-b6305ea4f1f0\", \"requirements.txt\", 14684)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip freeze > requirements.txt\n",
        "from google.colab import files\n",
        "files.download('requirements.txt')"
      ]
    }
  ]
}